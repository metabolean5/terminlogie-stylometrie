Dans les applications de commandes en langue naturelle, l'utilisation d'un analyseur syntaxique  basé sur des règles grammaticale fortes de la langue pose des problèmes d'efficacité (Milward, 2000; Sabouret & Mazuel, 2005). En effet, les utilisateurs emploient plus régulièrement des mots clés plutôt que des phrases bien structurées (e.g. « drop object low » ou « take blue »). De plus, dans le cadre d'applications réelles, la complexité, la difficulté d'écriture de règles nonspécifiques et de maintenances rendent ces types d'approches complexes à mettre en oeuvre et lourdes à utiliser (Sabah, 2006). D'un autre coté, l'utilisation d'un modèle « sac de mots » est insuffisante, générant des problèmes de modélisation impossible à interpréter par la suite (par exemple, « go from London to Boston » et « go from Boston to London » sont représentées par le même sac de mots). C'est pourquoi la majorité des travaux actuels (Hobbs et al., 1997;  Eliasson, 2007) cherchent à effectuer une analyse partielle (ou de surface), afin de réduire le coût  de développement, augmenter la portée utilitaire et éviter les écueils des deux modélisations extrêmes précédemment décrites.  Les méthodes actuelles d'analyse de surface s'orientent ainsi vers une modélisation basée sur la  logique du premier ou second ordre (Shapiro, 2000; Milward, 2000). Cette modélisation permet à la fois de s'affranchir d'une analyse syntaxique lourde et de conserver suffisamment d'information pour être applicable facilement au moment de l'analyse sémantique. Néanmoins, le défaut de ces systèmes réside dans la définition de ces prédicats, qui doit souvent se faire dans un langage contraint dépendant d'un ensemble d'axiomes logiques spécifiques (Shapiro, 2000; Sadek et al., 1997). Au contraire, l'utilisation d'ontologies dans les systèmes de dialogue a pour objectif de rendre les systèmes plus indépendants de l'application. Elles sont utilisées par exemple pour l'interprétation sémantique d'une commande pour le système (Milward & Beveridge, 2003; Flycht-Eriksson, 2003) et avant cette interprétation pour désambiguïser les termes d'une commande (Porzel et al., 2003; Resnik, 1995). Nous pensons qu'il est aussi possible d'exploiter le contenu de l'ontologie pour construire la représentation structurelle logique de la commande, ce qui permet de s'affranchir de la définition de règles dans un langage spécifique.  Dans cet article, nous proposons de définir une méthode d'analyse structurelle de surface pour  construire une modélisation logique de la commande basée sur l'étude des concepts et des relations définis dans l'ontologie de l'agent. Notre analyse s'appuie sur un ancrage des termes de la commande dans l'ontologie (nous nous plaçons dans le cadre de l'hypothèse de connectivité sémantique de Sadek (Sadek et al., 1997), qui suppose que tous les concepts de toutes commandes apparaissent dans l'ontologie). En fonction des rôles des termes dans l'ontologie (relation ou classe), nous construisons une représentation de la commande sous forme de prédicats (correspondant aux relations) et d'arguments (instances de classes).  La section suivante présente brièvement notre système d'interprétation de commandes en langue  naturel. Nous décrivons l'architecture principale et l'articulation entre les différents composants. La section 3 décrit plus précisément l'ancrage des termes utilisateurs à l'ontologie, l'algorithme de construction logique de la commande et l'interprétation sémantique.  Notre architecture est basée sur le modèle classique des « modules réseaux communicants »  (Allen et al., 2000; Seneff, 2002). Cette structure permet le backtrack entre les différents composants ainsi que les réponses anticipées en fonction de l'état du dialogue (figure 1). Nous donnons dans cette section les grandes lignes des modules de l'architecture, en gardant les détails de l'analyse logique et l'interprétation sémantique (comme illustration de l'utilisation de notre analyse) pour la section 3.  Notre module morphologique et lexical est basé sur la bibliothèque d'outils OpenNLP  . Nous utilisons les modules Maximum-Entropy Tokenizer et Chunker, l'étiqueteur et le lemmatiseur basé sur WordNet. L'étiqueteur, le tokenizer et le chunker sont entraînés sur des données anglaises du Wall Street Journal et du corpus Brown. Le dernier modèle proposé est annoncé à 96% d'étiquetage correct sur des données hors base d'apprentissage. Une étude comparative avec le TreeTagger sur quelques exemples tirés de notre application n'a pas montré de pertes très significatives. Le lemmatiseur basé sur WordNet permet la découverte des mots composés de la commande, dans la mesure où le terme existe en tant qu'un des mots d'un synset (e.g. « dark red », « extra large »). Nous n'avons pas utilisé le module de résolution d'anaphore de OpenNLP, car elles n'apparaissent que très rarement dans une commande (à la différence de textes longs ou de dialogues).  Notre système de compréhension des commandes en langue naturelle repose sur une approche  ascendante (i.e. bottom-up) comme il est possible d'en voir dans (Paraiso & Barthès, 2004). Cette approche utilise une liste préétablie de compétences (formelles) et essaye de relier la commande en LN à (au moins) une compétence. Cependant, elles présentent des problèmes d'efficacité en pratique (e.g. écriture des compétences, difficulté d'évolution, etc.) qui font que nous utilisons actuellement une version ascendante générative basée sur une analyse du code de notre agent (Mazuel & Sabouret, 2006). Notre modèle agent, appelé VDL, permet en effet un accès à l'exécution à l'ensemble du code et de son état courant (Sabouret & Sansonnet, 2001). L'algorithme de génération des commandes formelles est inspiré des travaux sur la validation de logiciel par l'analyse des préconditions d'activation d'une action. Le principe général de l'approche ascendante générative est d'apparier les termes de la commande utilisateur avec les commandes formelles (i.e. notées évènements en VDL) générées, qui correspondent aux commandes que l'agent est capable de traiter. Cet appariement est le résultat  de l'interprétation sémantique, dont nous parlerons brièvement en section 3.4. A l'issue de cette  interprétation sémantique, chaque évènement est associé à un score d'appariement évaluant la proximité de l'événement avec la commande de l'utilisateur. L'objectif de cet article n'est pas de présenter l'algorithme de calcul de ce score (le lecteur intéressé le trouvera dans (Mazuel & Sabouret, 2006)), mais de présenter l'analyse structurelle de surface qui le rend possible. A l'issue de l'interprétation sémantique le gestionnaire de dialogue utilise le score d'appariement pour déterminer la stratégie de dialogue. Nous utilisons pour cela un système de seuil inspiré de celui proposé par Patty Maes (Maes, 1994) qui permet de faire la différence entre les commandes parfaitement comprises, les commandes incertaines et les commandes noncomprises. Nous avons en plus pris en compte le cas des commandes possibles ou impossibles dans l'état courant de l'agent (Mazuel & Sabouret, 2006).  Pour répondre à l'utilisateur, le gestionnaire de dialogue utilise un générateur d'anglais qui  transforme une réponse formalisée en VDL en une phrase anglaise. L'algorithme actuel est très simple et ne produit pas des réponses grammaticalement correctes, mais donne suffisamment d'informations (i.e. de mots clefs) pour aider l'utilisateur à reformuler sa commande. Notre objectif à long terme est d'utiliser un générateur performant basé sur XML et les ontologies.  Par exemple, dans le cas d'une ambiguïté, le gestionnaire de dialogue propose à l'utilisateur  l'ensemble des commandes possibles dans le contexte courant et utilise le générateur d'anglais pour transformer les commandes formalisées :  Nous décrivons dans cette section comment nous construisons un modèle de la commande de  l'utilisateur sous la forme d'un ensemble de prédicats. Nous décrirons d'abord le modèle d'ontologie utilisé, l'algorithme d'ancrage d'un mot dans l'ontologie, puis enfin la construction complète de la modélisation logique de la commande.  Dans la suite de l'article, nous noterons St l'ensemble des chaînes de caractères et pour tout  ensemble E, nous noterons P(E) l'ensemble des sous-ensembles de l'ensemble E.  Dans notre modèle, l'ontologie d'un agent  est un couple O = C, R dans lequel :  - C est l'ensemble des concepts (ou classes). Un concept représente un ensemble d'objets réuni  par les mêmes propriétés. Tout concept c  C est caractérisé par un label l (nous nous  limiterons à un unique label pour simplifier, mais il peut y en avoir plusieurs dans le cas de  synonymie, à la manière des synsets de WordNet). - R est un ensemble de relations binaires. Chaque relation r  Rest caractérisée par un label de relation l et un ensemble de couples E  C .  Par soucis de simplification, nous identifierons l  et l respectivement au concept c et à la relation r , et nous noterons ainsi abusivement C et R les ensembles de labels de concepts et de relations. Nous noterons L = C  R. Enfin, nous noterons c , r, c  O lorsque les concepts c et c sont reliés par la relation r.  Soulignons que l'ontologie de domaine d'un agent contiendra non seulement les relations usuelles  d'hyperonymie (isa) et de meronymie (partof), mais aussi des relations plus spécifique du domaine comme isLargerT han ou leftOf.  Soit W l'ensemble ordonné w  , ..., w des mots utilisés dans la commande. L'ancrage dans l'ontologie consiste à trouver le label l ou l « le plus proche » pour chaque mot w . Notre algorithme se décompose en trois étapes :  1. La simplification morphologique.  2. La recherche des « approximations sémantiques ». 3. L'ancrage proprement dit.  La simplification morphologique consiste à unifier l'écriture des mots ou des groupes de mots  (accents, minuscule/majuscule, remplacement des espaces par « _ », etc). Par exemple, le terme bigger de la commande peut correspondre aux labels bigger-than, is-bigger encore biggerThan selon la notation adoptée dans l'ontologie. Nous ne détaillerons pas le calcul de cette fonction que nous noterons app :St  P(L). Elle prend en entrée un terme de la commande et renvoie la liste de candidats morphologiquement proche parmi les labels présent dans l'ontologie.  La recherche des « approximations sémantiques ».consiste à trouver l'ensemble des termes de  l'ontologie les plus proches sémantiquement d'un mot de la commande, en utilisant des mesures de similarité sémantique comme décrites dans (Budanitsky & Hirst, 2006). Nous ne faisons pas ici d'interprétation sémantique de la commande dans le contexte de l'application (nous ne sommes pour l'instant que dans l'analyse structurelle), mais nous cherchons les concepts représentant le mieux les mots utilisés par l'utilisateur. Cette démarche est équivalente aux travaux visant à désambiguïser l'ensemble des concepts reconnus pour un mot d'une commande pour ne choisir que le plus représentatif du contexte de la phrase (Porzel et al., 2003; Resnik, 1995). Par un exemple, dans la commande « buy a place for the Pink Floyd show at the cheapest price », le terme « cheapest » est proche du label de relation lowerThan et le le terme « show » du label de concept concert .  Pour cette recherche, nous avons choisi d'utiliser la formule de Jiang & Conrath (Jiang &  Conrath, 1997) appliquée aux calculs de probabilités définies par N. Seco (Seco et al., 2004). Cette formule calcule sur WordNet un score de similarité sémantique compris entre [0, 1]. Nous ne détaillerons pas cette formule ici car ce n'est pas l'objectif de cet article. Elle a été plusieurs fois évalué et présente les meilleurs résultats actuels en la matière (Budanitsky & Hirst, 2006). Nous noterons sim (w , w ) le score de similarité sémantique entre les mots w  St et w  St.  Nous noterons app  : St  P(L) la fonction calculant l'ensemble des labels les plus proches du terme de l'utilisateur. Nous la définissons de la façon suivante :  app  (w) =    si max < t {l  L tq sim (l, w) = max } sinon  avec t   [0, 1] le seuil d'acceptabilité et la similarité maximum max = max sim (l, w) .  Le seuil d'acceptabilité t  permet de décider si l'appariement est acceptable ou non . La similarité max est le score maximal obtenu pour le mot w lors du calcul de similarité sur l'ontologie. Autrement dit, app (w) donne l'ensemble des concepts de l'ontologie de similarité maximale avec w.  Ainsi, nous pouvons définir l'ancrage A  St × L des mots w  , ..., w dans l'ontologie O :  A =  w, l Si app (w) =  w, l Sinon  Soulignons qu'un même terme peut être ancré à plusieurs labels de l'ontologie, donc à plusieurs  concepts et/ou relations.  Soulignons aussi que l'interprétation sémantique (cf. section 3.4) utilise les scores calculés à  cet étape par sim pour déterminer l'imprécision globale de la commande. Cette imprécision est ensuite utilisée par le gestionnaire de dialogue pour déterminer la meilleure stratégie de dialogue.  Notre objectif est de définir une modélisation logique qui capture la structure fonctionnelle de  la phrase, c'est-à-dire de construire un ensemble de prédicats représentant les relations entre les concepts (au sens de l'ontologie O) tels qu'ils sont exprimées dans la commande. Par exemple, dans « the big object next to the book », l'utilisateur exprime une relation « next-to » entre « big object » et « book ».  Pour cela, chaque terme est considéré du point de vue de son ancrage dans l'ontologie : si c'est  une relation, nous la modéliserons sous la forme d'un prédicat et nous devons rechercher ses arguments dans la commande parmi les autres termes/concepts. En adoptant une représentation  arborescente des prédicats, les noeuds des arbres sont les termes de la commande. Les termes  qui sont des labels de concepts sont représentés par des feuilles. Les termes qui sont des labels de relations sont représentés par des noeuds dont les fils sont les arguments de la relation dans la commande de l'utilisateur. Par exemple, dans la phrase « drop on the lowest line, left of the largest cube », « drop », « line », « red » et « cube » sont des feuilles, « lowest » aura comme fils « line ». Nous obtenons alors le résultat présenté dans sur figure 2.  Toute la difficulté de cette construction réside dans la capacité à déterminer quel terme est un  argument de quelle relation. Idéalement, nous devrions nous appuyer sur l'analyse sémantique de la phrase et sur les définitions des relations dans l'ontologie pour identifier les instances correspondant à des arguments de l'agent, en utilisant du backtrack pour rechercher toutes les permutations possibles.  Mais dans un premier temps, par soucis d'efficacité, nous utiliserons l'heuristique suivante, tirée  de nos observations sur les relations dans la langue anglaise : Les arguments d'une relation sont soit l'ensemble des termes restant dans le syntagme nominal de la relation, soit dans l'ensemble des termes du syntagme immédiatement suivant.  La force de cette heuristique est qu'elle prend aussi en compte le traitement des comparatifs et  des superlatifs :  1. Si un superlatif apparaît, il l'est alors à titre d'adjectif descriptif de l'objet. Les termes de  la commande reliés appartiennent donc au même syntagme (e.g. « the biggest square », « the darkest big object », etc.).  2. Si un comparatif apparaît, l'objet de la comparaison est séparé par l'utilisation d'une  conjonction (« than », etc.) et donc dans le syntagme suivant (e.g. « higher than the cube », « left to the current position », etc.).  Formellement, soit S l'ensemble ordonné {c  , c , ..., c } composé de n chunks tel que i  [1, n], c = {s , s , ..., s } où les s sont les termes de la commande utilisateur, regroupés en chunks . La fonction  : S  S construit l'ensemble d'arbres S à partir de la modélisation de la commande chunkée S. Les éléments de S seront représentés en utilisant une notation prédicat/valeurs (chaque prédicat représentant un noeud, et ses valeurs les fils du noeud).  La fonction  est définie récursivement par : (S) =  {s ( ( {{s , ...s }}))}  ({c , ..., c }) si (k > 1)  (c  R. s , c  A) {s ( ( {c }))}  ({c , ..., c }) si (k = 1)  (c  R. s , c  A) {s }  ({{s , ...s }, c , ..., c }) sinon  avec () = ({}) = . Autrement dit, l'arbre S  est obtenu en transformant chaque relation de la commande en noeud dont les fils sont les termes restant du chunk (lorsque k > 1 ) ou les éléments du chunk immédiatement suivant lorsque la relation est le dernier élément du chunk (k = 1 ). Les concepts sont systématiquement transformés en feuilles. Pour mieux comprendre cette opération, considérons l'exemple suivant : « drop on the lowest line, left of the largest red cube » est chunkée en :  [VP Drop :VB ] [PP on :IN ] [NP the :DT lowest :JJS line :NN ] [ ? ? , :, ] [NP  left :NN ] [PP of :IN ] [NP the :DT largest :JJS red :JJ cube :NN ]  Après filtrage des termes non- significatifs, nous obtenons l'ensemble d'ensembles :   S =  {{drop}, {lowest, line}, {leftof}, {largest, red, cube}}  Nous obtenons alors (S) = {drop, lowest(line), leftof(largest(red, cube))}, représenté sous  forme d'arbre sur la figure 2.  L'analyse fonctionnelle décrite précédemment (cf. figure 3) permet :   1. La construction d'un ensemble d'arbres représentant la commande ;  2. L'ancrage de cet arbre, par l'ancrage de chacun de ses termes, sur l'ontologie.  Ces deux propriétés sont à la base de notre modèle d'analyse sémantique. En effet, de manière  similaire, nous ancrons semi-automatiquement le code de l'agent VDL sur l'ontologie au moment de l'écriture de l'agent. Ainsi, les évènements formels construits par notre algorithme ascendant génératif, utilisant des termes issus du code VDL, sont déjà ancrées dans l'ontologie (chaque commande générée ayant un ancrage diffèrent). Nous nous retrouvons alors dans une situation proche d'un problème d'appariement d'ontologies selon une ontologie de référence (e.g. (Aleksovski et al., 2006)). L'objectif est alors d'évaluer comparativement ses deux ancrages, afin de pouvoir décider quelles sont les commandes générées les plus proches de la commande en langue naturelle de l'utilisateur.  C'est l'ancrage des termes de la commande dans l'ontologie qui permet de se ramener à un  problème (non trivial) d'alignement d'ontologies. En effet, il nous est alors possible de calculer l'alignement demandant le moins « d'effort » d'approximation entre les deux ensembles de termes ancrés et donc d'en déduire quel couple (évènement/structure de commande) est le meilleur candidat comme résultat à cette interprétation sémantique.  La modélisation logique structurée de la commande utilisateur est ensuite utilisée au moment de  l'interprétation sémantique pour calculer la fermeture transitive de la relation dans le contexte courant de l'agent. Par exemple, si l'utilisateur parle d'un objet « à côté du livre », notre interprétation sémantique donne l'ensemble des positions correspondant à « à côté du livre » en fonction de la position du livre dans l'état courant.  Dans cet article, nous proposons un algorithme de modélisation d'une commande sous la forme  d'un ensemble de propositions logiques qui s'appuie sur l'utilisation de l'ontologie de l'agent. Les symboles de prédicats utilisés sont directement extrait à partir des termes de la commande en fonction de leur proximité avec les concepts de l'ontologie. Les rôles de prédicats ou arguments pour chaque terme sont choisis à partir de leur définition dans l'ontologie. Ce mécanisme ne nécessite donc pas l'utilisation d'un formalisme particulier pour définir les règles d'analyse syntaxique. La modélisation obtenue est simple à interpréter et à utiliser, en particulier pour l'interprétation sémantique de la commande. La plupart des systèmes de dialogues actuelles étant basés sur l'utilisation d'ontologies pour l'interprétation sémantique, l'approche est applicable à large échelle sur des systèmes d'implémentation diverses.  La méthode d'ancrage des termes de la commande dans l'ontologie (c'est-à-dire la recherche  du concept de l'ontologie le plus proche sémantiquement d'un terme donné) que nous avons présenté repose sur un algorithme de similarité sémantique basé sur WordNet. L'évaluation préliminaire de notre système actuellement en court présente des résultats encourageants. Cependant, nous voudrions la valider sur d'autres agents et ontologies que celles que nous avons utilisées jusqu'à présent, afin de montrer la généricité de notre approche.  
