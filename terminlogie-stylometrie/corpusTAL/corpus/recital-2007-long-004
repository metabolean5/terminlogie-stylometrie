Nous souhaitons disposer d'une correspondance directe entre les articles d'une encyclopédie   et les entrées d'un lexique sémantique de référence. Deux cas de figure se rencontrent alors ;   quand une entrée de lexique correspond déjà à un article, nous établissons la correspondance   entre  les  deux ;  sinon,  nous  enrichissons  le  lexique,  en  créant  une  nouvelle  entrée  et  en  la  rattachant (via une relation d'hyperonymie/hyponymie) au meilleur « ancêtre » existant.   En réitérant ce processus sur plusieurs encyclopédies, nous obtenons un corpus monolingue   de paires d'articles traitant d'un même sujet, propice à la découverte de paraphrases. Nous  pouvons alors déterminer, par exemple, que « la rivière Alabama serpente jusqu'à Selma »  est  une  paraphrase  de  « la  rivière  Alabama  coule  vers  Selma ».  Nous  représentons  les  paraphrases  sous  forme  de  triplets  (sujet,  verbe,  complément).  La  désambiguïsation  des  entités  nommées  permet  d'établir  que  «    serpente  (préposition)   »  est  une  paraphrase de «   coule (préposition)   ». (L'indice   indique le sens du mot  dans le lexique.) L'utilisation d'une mesure de similarité entre les deux verbes permet enfin  de déterminer les sens de « serpenter » et « couler » dans le contexte. Nous obtenons, au final,  l'équivalence entre deux cadres de sous-catégorisation, dont les éléments sont désambiguïsés  par rapport au lexique :   ( , ) ~   ( , ).  Ces opérations constituent les deux premières étapes du projet ISIDORE  , qui vise à extraire  des  connaissances  d'une  encyclopédie  en  langue  anglaise.  Pour  faciliter  la  lecture,  les  exemples cités ici ont été traduits en français.   Figure 1 : architecture d'ensemble du projet ISIDORE    Notre lexique de référence est WordNet (Miller, 1995) version 2.1. Ce projet, mené depuis   1985 à Princeton, offre un réseau sémantique très complet de la langue anglaise. S'il n'est pas  exempt de critiques (granularité très fine, absence de relations paradigmatiques...), WordNet  n'en reste pas moins l'une des ressources de TAL  les plus populaires.   Les noeuds sont constitués par des ensembles de synonymes (ou synsets), correspondant au   sens d'un ou plusieurs lemmes. Un synset est défini d'une façon différentielle par les relations  qu'il  entretient  avec  les  sens  voisins.  Par  exemple,  des  relations  d'hyperonymie  et  d'hyponymie relient les « ancêtres » des noms et des verbes avec leurs « spécialisations ». La  version 2.1 a de plus introduit la notion d' « instance hyponyme », qui désigne une instance   (typiquement une entité nommée) d'un synset, et non une sous-classe. Ainsi, le nom    a  , , ... pour hyponymes, et  comme instance hyponyme.   L'encyclopédie en ligne Wikipedia possède une vingtaine d'articles dont le titre contient (au   moins partiellement) « Abraham Lincoln » :  1. « Abraham Lincoln » : l'homme politique, 16   Président des Etats-Unis.  2. « Abraham Lincoln assassination » : l'assassinat de l'homme politique.  3. « Abraham Lincoln (Pullman car) » : le plus ancien wagon de passagers des Etats-Unis.  4. Sans oublier deux films biographiques, trois lieux géographiques, plusieurs écoles, deux  vaisseaux militaires... également nommés en mémoire de l'homme politique.   Nous constatons donc qu'une similarité entre le titre d'un article et un lemme (ou groupe de   mots) désignant un synset de WordNet ne suffit pas à déduire qu'ils traitent du même sujet.   Nous cherchons à identifier le (ou les) synset de WordNet auquel un article se rattache. Pour   ce  faire,  nous  commençons  par  extraire  de  WordNet  les  « synsets  candidats  »  pouvant  correspondre au titre de l'article. Cette étape ne pose pas de difficulté particulière. Pour les  personnes, par exemple, chaque article possède un ou plusieurs titres normalisés (de la forme  « Prénom  Nom »  ou  « Nom,  Prénom »).  Il  suffit  de  rechercher  les  synsets  correspondants  dans  WordNet.  Pour  un  nom  commun,  il  est  nécessaire  de  tenir  compte  d'éventuelles  variantes morphologiques et de retrouver la forme de base du mot. Nous appliquons alors un  ensemble  d'heuristiques   pour  retenir  le  meilleur  candidat.  S'il  n'en  existe pas,  nous  commençons par chercher le synset correspondant le mieux au thème de l'article (décrit-il une  rivière,  un  président... ?)  Ensuite,  nous  créons  un  nouveau  synset,  rattaché  (en  tant  qu'hyponyme ou instance hyponyme) au synset du thème de l'article.   Dans l'univers du traitement automatisé des encyclopédies, la Wikipedia pose un problème   particulier. Pouvant être modifiée par tout internaute, elle voit depuis plusieurs années une  progression  exponentielle  de  son  nombre  d'entrées  :  certain  articles  ne  sont  que  des  biographies auto-promotionnelles, d'autres des comptes-rendus de films ou de jeux vidéo...  Notre  choix  est  de  ne  retenir  que  les  entrées  correspondant  à  un  consensus  en  termes  de  connaissances encyclopédiques. Nous travaillons donc sur un sous-ensemble des articles de la  Wikipedia recoupant (sur la base du titre) ceux d'une autre encyclopédie de référence.   (Ruiz-Casado, Alfonseca, Castells, 2005) présentent l'implémentation d'un algorithme rapide   permettant de réaliser la correspondance entre un article de la Simple Wikipedia  et le synset  correspondant  de  WordNet .  Si  aucun  synset  n'a  de  lemme  en  commun  avec  le  titre  de  l'article, ce dernier est ignoré. Si un seul synset de WordNet a un lemme égal au titre, l'article  y  est  lié  sans  autre  analyse.  En  cas  d'ambiguïté,  l'article  fait  l'objet  d'un  étiquetage  morphosyntaxique (après un filtrage des marqueurs syntaxiques spécifiques à la Wikipedia), pour  ne  conserver  que  les  noms,  verbes  et  adjectifs.  Le  système  analyse  les  définitions  de  WordNet, et construit pour chacune d'entre elles un vecteur booléen (contenant « 1 » pour  chaque  terme  en  commun  avec  l'article  et  «  0  »  pour  chaque  mot  en  disjonction).  L'algorithme calcule alors une mesure de type cosinus entre les vecteurs, et retient le meilleur  article, au sens de cette mesure de similarité.   Notre approche améliore celle présentée ci-dessus, avec deux différences. D'une part, nous   avons  ajouté  plusieurs  heuristiques,  afin  d'augmenter  la  précision.  D'autre  part,  nous  appliquons ces heuristiques même dans le cas où un seul synset de WordNet a un lemme égal  au  titre  de  l'article.  Comme  nous  l'avons  vu,  la  Wikipedia  ne  contient  pas  moins  de  vingt  articles sur « Abraham Lincoln » ; cette décision permet d'éviter des appariements erronés.   Les  heuristiques  utilisées  sont  indépendantes  les  unes  des  autres ;  elles  peuvent  donc  être   appliquées dans n'importe quel ordre. Au départ, tous les synsets candidats partent avec un  même indice de confiance, qui est modifié durant l'application des heuristiques. Après cette  étape,  les  synsets  candidats  qui  disposent  d'un  poids  manifestement  trop  faible  pour  correspondre  à  l'article  sont  supprimés  de  la  liste.  Dans  notre  cas,  nous  avons  déterminé  expérimentalement un poids minimal de 0,6. Ensuite, on conserve les synsets dont l'indice de  confiance vaut au moins 40% de celui du synset le mieux classé. Ceci permet de supprimer  les synsets non significatifs.   2.2.1 Distance vectorielle sur les mots    Cette heuristique est identique à celle décrite dans (Ruiz-Casado, Alfonseca, Castells, 2005).    2.2.2 Comparaisons des contextes (domaines implicites et noms propres)    Nous  extrayons  du  texte  les  domaines  (« biologie»,  « sport »...)  éventuellement  associés  à   chaque  mot ,  ainsi  que  les  noms  propres.  Nous  comparons  la  liste  d'éléments  extraits  de  l'article avec celle de chaque synset candidat, également à l'aide d'une mesure vectorielle.   2.2.3 Comparaison des domaines cités explicitement dans le texte    Cette  heuristique  recherche,  dans  une  définition,  des  patrons  de  la  forme  « en  mathématiques », « utilisé en géologie »... à l'aide d'expressions régulières. Si un patron de  ce type est repéré, son domaine d'application est extrait (« mathématiques » ou « géologie »  par exemple). Si le synset candidat (ou l'un de ses hyperonymes) appartient à ce domaine, son  indice de confiance est augmenté.   Cette heuristique a pour but de déterminer l'hyperonyme du sujet de l'article, en étudiant sa   définition. En voici quelques exemples, où les hyperonymes sont soulignés :    Abraham Lincoln : 16  Président des Etats-Unis.  Australie : un pays et le continent le plus petit.   chat : mammifère félin ayant une épaisse fourrure douce et incapable de rugir.   Le  ou  les  hyperonymes  du  sujet  de  l'article  sont  comparés  aux  hyperonymes  des  synsets   candidats. S'ils sont suffisamment proches (au sens d'une mesure de similarité), l'indice de  confiance est fortement augmenté. Cette heuristique est essentielle en termes d'amélioration  de la précision de l'appariement ; c'est pourquoi elle est détaillée ici.   2.3.1 Analyse syntaxique de la définition    Notre  but  est  d'extraire  l'hyperonyme  d'une  définition.  Prenons  l'exemple  précédent  du   « chat » ; notre but est d'extraire « mammifère » (ou éventuellement « mammifère félin », si  ce terme existe dans le lexique de référence) .  Nous effectuons pour cela une analyse syntaxique en profondeur de la définition, en utilisant   le Stanford Parser  (Manning, Klein, 2002). Cet analyseur statistique fournit une sortie sous  forme de dépendances syntaxiques.    Nous supposons que l'hyperonyme se situe dans la 1  phrase de l'article, qui tient le plus  souvent  lieu  de  définition ;  nous  ne  traitons  donc  que  celle-ci.  Comme  une  définition  se  résume  souvent  à  un  groupe  nominal,  il  convient  de  la  modifier  pour  la  rendre  « grammaticalement correcte ». Notre expérience montre que c'est indispensable dans le cas  d'un  analyseur  basé  sur  des  règles  comme  le  Link  Grammar  Parser  (Sleator,  Temperley,  1991)  et  souhaitable  dans  le  cas  d'un  analyseur  statistique  tel  que  le  Stanford  Parser.  La  première passe consiste donc en un étiquetage morphosyntaxique de la définition ; ensuite, en  fonction  de  la  partie  du  discours  (adjectif,  nom,  verbe,  etc.)  du  premier  mot,  l'algorithme  préfixe éventuellement la définition par « c'est » ou « c'est un ».   Figure 2 : Analyse syntaxique de la définition (en anglais) du nom « chat »    2.3.2 Recherche de l'hyperonyme    L'analyse  syntaxique  de  la  définition  est  alors  disponible  sous  forme  d'un  graphe  de   dépendances.  Nous  le  transformons  en  clauses  Prolog,  à  partir  desquelles  nous  pouvons  identifier des schémas (Chaumartin, 2006).   Le processus tient compte des conjonctions de coordination, afin d'extraire correctement les   hyperonymes multiples comme dans « l'Australie est un pays et le continent le plus petit ».  Dans une construction comme « une espèce de... » ou « un membre du groupe de... », nous  remontons d'une façon récursive le long des constituants de l'amas nominal, en passant au  constituant imbriqué suivant.   2.3.3 Création de nouveaux synsets    Si aucun synset de WordNet ne correspond à l'article considéré, on en crée un nouveau, dont   la  définition  sera  la  première  phrase  de  l'article.  Ensuite  on  le  relie  au  synset  représentant  l'hyperonyme  de  l'article  étudié.  On  est  confronté  ici  à  une  problématique  de  désambiguïsation lexicale, pour identifier le sens correct. Par exemple, si l'hyperonyme est  « empereur », il faut choisir entre les sens « dirigeant mâle d'un empire »,  « raisin rouge de  Californie » ou « grand papillon richement coloré ».  Les hyponymes du meilleur ancêtre se situent au même niveau que le sujet de l'article dans la   hiérarchie  de  WordNet.  Nous  cherchons  donc  des  points  communs  entre  l'article  et  ses  « cousins » potentiels. Nous commençons par relever les similarités au niveau du vocabulaire  employé  entre  l'article  et  chacun  des  hyponymes  de  ses  ancêtres  possibles ;  en  effet,  des  articles ayant le même hyperonyme ont une forte probabilité de traiter de sujets voisins, et  donc de partager un champ lexical.   Pour  finir,  nous  appliquons  deux  heuristiques  supplémentaires.  Tout  hyperonyme  candidat   d'une entité nommée (personne, lieu, etc.) voit son indice de confiance augmenté si :    Il en découle des relations de type « instance hyponyme ».    Il hérite d'un groupe social (« entreprise », « organisation », « mouvement »...).    La  version  de  mars  2006  de  la  Wikipedia  en  anglais  (1  005 682  articles)  a  été  filtrée  pour   retenir 15 847 articles, dont le titre était également présent dans une autre encyclopédie de   référence.  Ces  articles  ont  été  appariés  automatiquement  sur  WordNet.  Pour  évaluer  la   précision de l'appariement, nous avons examiné manuellement le résultat sur 800 articles :   505 ont été associés à un synset existant déjà dans WordNet ; l'appariement a été   fait correctement dans 465 cas (soit une précision de 92%).   295 nouveaux synset ont été crées ; l'hyperonyme a été correctement identifié dans   251 cas (soit une précision de 85%).   En  répétant  le  processus  précédent  sur  plusieurs  sources  encyclopédiques,  nous  pouvons   rattacher plusieurs articles à un même synset, et obtenir un corpus d'articles comparables.   Figure 3 : Trois articles en anglais portant sur la rivière Alabama ; les entités nommées sont   surlignées dans une même couleur (un module de résolution d'anaphores a été appliqué)   L'apprentissage  automatique  de  paraphrases  peut  se  faire  sur  la  base  de  textes  alignés  ou   comparables. (Ibrahim, Katz, Lin, 2003) décrivent ainsi l'utilisation de plusieurs traductions  différentes,  en  anglais,  d'oeuvres  littéraires  (par  exemple  20 000  lieues  sous  les  mers),  et  améliore l'approche de (Lin, Pantel, 2001) traitant de corpus comparables. L'algorithme mis  en oeuvre consiste à effectuer une analyse syntaxique de deux textes, et à identifier le plus  court chemin, dans chaque graphe de dépendance, entre deux ancres (des entités nommées).   Nous  appliquons  une  technique  voisine  sur  des  paires  d'articles  portant  sur  le  même  sujet.   Notre objectif est de constituer un catalogue de paraphrases dont les éléments sont totalement  désambiguïsés par rapport à WordNet.   Notre  algorithme  commence  par  traiter  chaque  article  séparément,  avec  les  étapes   suivantes  :   Analyse syntaxique profonde du texte. Nous obtenons un ensemble de dépendances où   les constructions de syntaxe de surface (sujet inversé...) sont gommées.   Résolution des anaphores pronominales (notre expérience montre que dans le cas de   textes encyclopédiques, elles concernent généralement le sujet de l'article).   Identification des entités nommées, autres que le sujet de l'article, et citées une seule   fois (donc sans reprise anaphorique). Pour chacune de ces entités nommées :   o Désambiguïsation lexicale (par rapport à WordNet).    o Recherche du (ou des) chemin(s) la reliant au sujet de l'article, dans le graphe   de syntaxe profonde.   En partant de l'article de la Wikipedia sur la rivière Alabama, nous obtenons ainsi des triplets   de la forme (sujet, verbe, complément), où le sujet et le complément sont déjà désambiguïsés :  ( C ,  former,  A ),  ( T ,  former,  A ),  ( A ,  couler,  S ),  ( A ,  unir,  T ), ( A , former,  M )...  De  même,  un  article  d'une  autre  encyclopédie,  traitant  également  de  la  rivière  Alabama,   fournit : ( T , former,  A ), ( C , former,  A ),  ( A ,  serpenter,  S ),  ( T ,  rejoindre, A ), ( A , former,  M )...  Nous  pouvons  rapprocher  ces  informations.  Sans  les  triplets  identiques,  il  reste  (  A , couler,  S ) ~ ( A , serpenter,  S ) et ( A , unir,  T ) ~ ( T , rejoindre, A ). Les  entités  nommées  sont  déjà  désambiguïsées ;  connaissant  leurs  hyperonymes,  nous  pouvons donc réécrire ces paraphrases au niveau des classes plutôt que des instances :   (   riv1, couler,   v1) ~ (  riv1, serpenter,   v1)   (   riv1, unir,   riv2) ~ (  riv2, rejoindre,  riv1).   Il nous reste à déterminer le sens de chacun des deux verbes dans la paire de triplets. Nous   utilisons pour cela une mesure de similarité, qui exploite la hiérarchie de verbes de WordNet.  Partant de l'hypothèse que les deux verbes doivent avoir un sens proche l'un de l'autre, nous   cherchons la combinaison de sens qui minimise leur distance, au sens d'une telle mesure. De   nombreux  auteurs  ont  proposé  des  définitions  de  mesures  de  similarité,  et  plusieurs  implémentations  basées  sur  WordNet  sont  disponibles .  Par  exemple,  (Lin,  1998)  définit  comme mesure de similarité entre deux synsets s1 et s2 : sim(s1, s2) = (2 . log P(s)) / (log P(s1) + log P(s2))    où s est  le  synset  le  plus  spécifique  subsumant  les  synset  s1 et s2 dans  la  hiérarchie  de   WordNet,  et  où  P(s)  représente  la  fréquence  du  synset  s obtenue  à  partir  d'un  corpus  de  référence (le SemCor en l'occurrence).   Nous avons implémenté une mesure de ce type, en introduisant deux niveaux supplémentaires   en  plus  de  la  hiérarchie  de  WordNet.  En  effet,  la  qualité  de  la  mesure  de  similarité  est  fonction de la finesse de la hiérarchie. De façon à rendre tous les verbes comparables, nous  avons  créé  un  pseudo-synset  qui  sert  de  racine  commune  à  tous  les  verbes.  Nous  avons  également  intercalé,  entre  cette  racine  et  les  verbes,  des  pseudo-synsets  regroupant  les  catégories lexicales (verbes de mouvement, verbes d'état, verbes de changement...).   Nous appliquons cette mesure de similarité à toutes les combinaisons de sens de « couler » et   « serpenter »,  d'une  part,  et  d' « unir »  et  « rejoindre »,  d'autre  part.  Nous  obtenons  alors,  comme combinaison minimisant la distance entre les paires de verbes :   (   riv1,  ,  v1) ~ (  riv1,  ,  v1)   (   riv1,  ,  riv2) ~ (  riv2,  ,  riv1).   Ce processus permet d'obtenir automatiquement des paires de cadres de sous-catégorisation,   dont  les  éléments  sont  totalement  désambiguïsés  par  rapport  à  WordNet.  Nos  premières  évaluations  préliminaires  (effectuées  sur  une  dizaine  d'articles)  montrent  une  précision  de  l'ordre de 70% dans la détection de paraphrases pertinentes.  Une  première  passe,  sur  l'ensemble  des  articles  de  l'encyclopédie  portant  sur  une  même   catégorie, permet de compter la fréquence de chaque construction particulière.   Il  est  alors  possible  de  fixer  un  seuil  minimal  en  dessous-duquel  la  construction  n'est  pas   retenue ; ce mécanisme est important pour compenser les erreurs ayant pu subvenir lors de  l'application  de  la  chaîne  de  traitement  (durant  les  phases  d'analyse  syntaxique,  de  désambiguïsation lexicale des entités nommées ou de résolution d'anaphores). Si une même  construction se retrouve un grand nombre de fois, elle est probablement correcte.   Ces  cadres  de  sous-catégorisations  fournissent  par  la  suite,  lors  d'une  seconde  passe  de   traitement, de puissants indices de désambiguïsation lexicale et syntaxique.   Cet article montre qu'il est possible d'enrichir automatiquement WordNet à partir d'une ou   plusieurs  encyclopédies.  Nous  projetons  d'utiliser  le  même  mécanisme  pour  importer  des  dictionnaires  spécialisés  (en  informatique,  en  droit  et  en  médecine).  Le  fait  de  disposer  de  plusieurs  textes,  portant  sur  un  même  sujet,  permet  d'extraire  automatiquement  des  paraphrases ; leurs constituants sont complètement identifiés, ce qui permet, dans une seconde  passe, d'améliorer la désambiguïsation lexicale des textes. Dans le cadre du projet en cours  ISIDORE,  il  reste  à  mettre  en  oeuvre  ces  mécanismes  sur  un  volume  significatif  d'articles,  pour affiner notre jugement sur la validité de cette approche.   Je  remercie  Sylvain  Kahane  (Paris  10)  pour  ses  conseils,  et  Benjamin  Surma  et  Ricardo   Minhoto pour leur participation au projet dans le cadre de leur mémoire d'ingénieur ENSIIE.   
