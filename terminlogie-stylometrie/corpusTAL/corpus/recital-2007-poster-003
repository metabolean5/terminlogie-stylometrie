Le développement de l'informatique pour le grand public a entraîné une forte augmentation du  nombre d'usagers novices en informatique en contact régulier avec celle-ci. Ces usagers novices n'ont bien souvent ni le temps ni l'envie d'utiliser des manuels papiers ou des FAQ (Foires Aux Questions) de logiciels de plus en plus complexes (en dépit des progrès ergonomiques) dont par ailleurs ils ne maîtrisent pas le vocabulaire spécifique. Des systèmes d'aides contextuelles (ou CHS en anglais, pour Contextual Help Systems (Jansen, 2005)) ont été développées pour mieux s'adapter aux besoins de ces nouveaux utilisateurs, mais ceux-ci semblent toujours préférer faire appel à un ami expert lorsqu'ils souhaitent réaliser une tâche particulière dans une application (Capobianco & Carbonell, 2002). Parallèlement, les agents conversationnels animés dotés de capacités de dialogue et de raisonnement de niveaux variés (Sadek et al., 1997) développés récemment ont mis en évidence les nombreux avantages potentiels d'une présence (même virtuelle) pour faciliter l'interaction hommemachine (Lester et al., 1997).  Pour répondre à ce besoin d'assistance des usagers novices, le projet DAFT développé au  LIMSI-CNRS (Sansonnet et al., 2005) se propose donc de développer des Agents Conversationnels Assistants (ACA), capables d'analyser des requêtes en langue naturelle écrite non contrainte provenant d'usagers novices en situation réelle d'utilisation d'applications de complexités diverses (applets simples, pages web, traitement de texte). Pour répondre à ce type de requêtes, le système d'assistance raisonne sur la structure et le fonctionnement des applications à l'aide d'un modèle de celles-ci, construit de manière semi-automatique. Cette méthodologie a pour objectif de fournir une assistance pertinente en contexte à la manière des CHS, avec en plus tous les bénéfices liés à la présence d'agents conversationnels animés.  Afin d'identifier précisément les propriétés et les besoins propres à la Fonction d'Assistance,  nous avons été amenés à constituer un corpus de requêtes, auquel on se référera sous le nom de corpus DAFT. Ce corpus illustre les actes de dialogues réalisés par des sujets en situation d'assistance et a été étudié lors d'un stage de M2R (Bouchet, 2006) afin de pouvoir réaliser les spécifications d'un langage de requêtes formelles adapté au domaine d'étude . Dans cet article, nous détaillons dans un premier temps le processus de constitution du corpus employé, en justifiant en particulier la nécessité des choix effectués et en vérifiant que le corpus ainsi obtenu est viable pour répondre à nos besoins. Dans un second temps, nous nous proposons de comparer ce corpus avec d'autres corpus de domaines proches pour en dégager les spécificités. Enfin, nous analysons les différentes activités couvertes par les requêtes recueillies et tentons de les caractériser par des paramètres d'ordre linguistique.  Au moment de l'étude, le corpus DAFT se composait d'environ 5 000 requêtes isolées (cf.  §2.3) recueillies entre juin 2004 et juin 2006. Pour le constituer, nous avons eu recours à deux méthodes complémentaires garantissant à la fois l'empirisme et la bonne couverture du corpus :  1. Recueillir des requêtes réelles produites par des utilisateurs placés devant des applications  intégrant un ACA de type LEA (2/3 du corpus final). 2. Utiliser des structures dialogiques génériques issues de classifications de thésaurus anglais (600 structures (Molinsky & Bliss, 1994)) ou bilingues (300 structures (Atkins & Lewis, 1996)). Ces structures ont été adaptées pour les employer dans des requêtes d'assistance formulées dans le contexte des applications mentionnées dans le point précédent, afin d'assurer une certaine homogénéité lexicale du corpus (1/3 du corpus final). Ainsi, la structure "ça te dirait de. . ." utilisée conjointement avec une phrase recueillie comme "peux-tu jouer à ma place ?" donne "ça te dirait de jouer à ma place ?".  L'utilisation de la seconde méthode nous permet de compenser la difficulté à obtenir un corpus  de taille supérieure avec le panel réduit de sujets dont nous disposions . Il y a recouvrement partiel avec les phrases recueillies par la première méthode, mais ce choix, discutable dans l'absolu, doit être mis en relation avec l'objectif de ce corpus qui est de fournir une base pour la constitution d'un agent rationnel : la couverture prime donc sur l'exactitude de la fréquence des phénomènes linguistiques. Le corpus ainsi construit sature donc mieux le domaine d'étude, même si cela induit fatalement un biais en sur-représentant des phénomènes linguistiques rares (les structures employées ne seraient apparues "naturellement" que sur un corpus plus grand).  Les phrases recueillies l'ont été au sein de deux types d'applications :   1. deux applications de type Java (Le Guern, 2004) : un simple compteur temps réel (thread  Java) dont l'utilisateur contrôle le démarrage et la vitesse, et un jeu de tours de Hanoi fonctionnant de manière modale (ie n'évoluant que si l'utilisateur agit).  2. deux sites web : une version active du site du groupe AMI du LIMSI permettant l'édition  de contenu, et le site du GT ACA (cf. figure 1) en libre accès sur internet aux utilisateurs effectifs du site.  Dans la mesure où l'agent assistant que nous souhaitons réaliser doit disposer d'une certaine  généricité (indépendance par rapport aux applications assistées), ces différentes origines ne posent pas de problème concernant l'homogénéité de notre corpus. L'emploi d'un vocabulaire très spécifique à une application particulière permet parfois de retrouver a posteriori l'origine de certaines requêtes, mais la formulation générale des requêtes n'est elle pas affectée (par exemple, la phrase &#34;comment faire pour arrêter le compteur ?&#34; a une structure globale identique à &#34;comment faire pour s'inscrire au GT ACA ?&#34;).  La table 1 expose un extrait du corpus DAFT, faisant apparaître certaines de ses caractéristiques :  - beaucoup de phrases sont bruitées (expressions orales, fautes d'orthographe, de syntaxe et de grammaire, langage SMS. . .), et certaines erreurs sont non triviales à traiter avec des outils classiques de TALN. - il ne se présente pas comme une succession de dialogues homme-machine, mais plutôt comme une liste de phrases employées par les usagers (questions, ordres ou remarques à l'agent. . .). En effet, on constate que dans le cadre de la Fonction d'Assistance, les interactions dialogiques se limitent essentiellement à un seul et unique tour de parole (commandeaction, question-réponse. . .), et peuvent donc être traitées de manière isolée .  Bien qu'il n'y ait pas de corpus d'assistance similaires aisément disponibles en français, on est  en droit de s'interroger sur la nécessité de constituer un nouveau corpus : est-ce qu'un corpus dans un domaine connexe tel que le dialogue homme-machine orienté tâche n'aurait pas été suffisamment proche pour nous convenir ?  Pour répondre à cette question, et ainsi justifier la nécessité d'un corpus particulier, on peut  suivre la méthode de comparaison statistique de corpus présentée dans (Ripoche, 2006) pour comparer le corpus DAFT à plusieurs corpus de dialogues homme-homme orientés tâche par l'étude de leurs profils interactionnels. On appelle profil interactionnel d'un corpus une représentation sous forme d'histogrammes de la répartition des différents actes de dialogue (au sens de (Searle, 1969)) au sein de celui-ci (cf. fig. 2). Les trois corpus de référence choisis pour effectuer cette comparaison sont Switchboard (Jurafsky et al., 1998) (200 000 énoncés de conversations téléphoniques orientées tâche annotés manuellement), MapTask (Carletta et al., 1996) (128 dialogues visant à reconstruire une carte par placement de points de repère) et Bugzilla (Ripoche, 2006) (1 200 000 commentaires issus de 128 000 rapports de défauts établis lors du développement de la suite logicielle de la Fondation Mozilla).  standards (ajouter, modifier, déplacer. . .).  - les structures de phrases, particulièrement dans les sous-corpus d'assistance, sont assez prototypiques et très différentes de ce que l'on trouve dans la langue naturelle générale . Lors de la phase de recueil du corpus, les sujets humains ont été informés qu'ils devaient réaliser certaines tâches, en faisant appel si nécessaire à un agent (non humain) présent dans l'application pour les assister. Les sujets pouvaient néanmoins agir et s'exprimer de manière non contrainte, et divers comportements ont pu être observés, l'utilisateur se détournant parfois complètement de sa tâche initiale. Finalement, il apparaît donc que de nombreuses phrases recueillies ne relèvent pas vraiment du domaine de l'assistance (cf. table 1). Nous nous sommes par conséquent intéressés à identifier les différentes activités conversationnelles réellement présentes dans le corpus.  Pour cela, nous avons extrait aléatoirement des phrases du corpus de manière à former deux  sous-ensembles de taille égale au dixième de la taille totale du corpus. Dans le premier sousensemble, les phrases ont été regroupées manuellement par activités similaires, en s'intéressant notamment au thème des requêtes (application, agent, utilisateur. . .) et à leur nature (ordre, question, compliment. . .). On a finalement obtenu ainsi quatre grandes catégories de tailles inégales (cf. fig. 3). Ensuite, connaissant ces quatre activités principales, on a traité le deuxième sousensemble en classifiant manuellement les phrases de celui-ci dans une des activités définies précédemment. La répartition ainsi déterminée était très proche de celle trouvée sur le premier sous-ensemble, ce qui nous laisse penser qu'on peut raisonnablement généraliser ce résultat à l'ensemble du corpus (la figure 3 présente les résultats obtenus en faisant la moyenne des deux répartitions trouvées). On peut par conséquent considérer que notre corpus est divisible en quatre "sous-corpus", correspondant chacun à des types d'activités distinctes (les phrases données en exemples sont celles de la table 1) : 1. activité de contrôle : corpus constitué de commandes, afin que l'agent agisse lui-même sur l'application (phrases 1-3). 2. activité d'assistance directe : regroupant des demandes d'aide explicitement formulées comme telles par l'utilisateur (phrases 4-6).  Sous-corpus Contrôle Assist. directe Assist. indirecte Clavardage  Moyenne 5,44 8,01 9,90 6,01 Écart-type 3,36 3,54 3,30 3,62  3.  activité d'assistance indirecte : corpus formé d'opinions sur l'application qui constituent des demandes d'aide sous-entendues, probablement perceptibles uniquement au niveau pragmatique (phrases 7-9). 4. activité de clavardage : réunissant le reste des interactions essentiellement centrées sur l'agent ainsi que des expressions métalinguistiques, phatiques et de backchanneling (phrases 10-14). L'existence des sous-corpus de contrôle et de clavardage démontre que l'utilisateur attend non seulement d'un ACA qu'il l'aide à utiliser une application, mais aussi qu'il soit capable d'agir lui-même sur celle-ci, ainsi que de répondre à des commentaires annexes indépendants de la tâche à accomplir où l'agent devient lui-même le centre d'intérêt de l'utilisateur (ce phénomène s'expliquant essentiellement par la présence d'une représentation visuelle de l'agent). Les quatre sous-corpus ont été catégorisés précédemment uniquement par une annotation manuelle, mais il serait souhaitable de pouvoir automatiser cette classification afin d'analyser spécifiquement les activités propres à chaque sous-corpus. On envisage alors trois méthodes de caractérisation possibles de ceux-ci : - une étude de la distribution de la longueur des phrases des sous-corpus. - une étude des profils interactionnels des sous-corpus, tels que définis en 2.4. - une étude de la sémantique des phrases par analyse de leur retranscription sous forme de requêtes formelles.  3.2.1 Caractérisation par la longueur des phrases   On observe une certaine disparité de longueur des requêtes, les requêtes de contrôle semblant  globalement assez courtes comparées aux requêtes d'assistance (cf. table 2), et on peut approximer les répartitions des sous-corpus de contrôle et d'assistance indirecte par une loi normale (test de  avec un seuil de tolérance de 1%). Néanmoins, les écart-types trop importants (  3, 5) disqualifient en pratique cette méthode de classification.  3.2.2 Caractérisation par l'analyse des profils interactionnels   On distingue sur la figure 4 certaines différences de profils interactionnels assez nettes entre  les sous-corpus et par rapport au profil générique du corpus DAFT (rappelé en gris foncé), notamment pour distinguer l'assistance directe (avec une forte majorité de directifs et quelques expressifs) de l'assistance indirecte (une majorité d'assertifs et des expressifs). En revanche, les  profils interactionnels des sous-corpus de contrôle et d'assistance directe sont assez similaires.  Cette méthode présente donc un certain intérêt mais ne peut être utilisée de manière unique. En outre, automatiser la détection de ces actes de dialogue n'est pas non plus trivial.  3.2.3 Caractérisation par analyse des requêtes formalisées   Notre principale motivation pour constituer ce corpus était de pouvoir s'en servir comme base  pour la définition d'un langage formel adapté pour exprimer la sémantique des requêtes langagières. La syntaxe de ce langage, présentée en détails dans (Bouchet, 2006), distingue des modalités (la possibilité, l'obligation, le savoir. . .), des prédicats d'actions (modifier, déplacer, actionner. . .) et des références (le tableau, le petit bouton rouge. . .) qui peuvent s'imbriquer entre elles sous la forme :  M  (. . . M (c = P (c' = R , . . ., c' = R ), . . ., c = P (. . .)) . . .)  Expression dans laquelle :  M - M sont des modalités, P - P sont des prédicats, c - c & c' - c' sont des intitulés de champs typés (par exemple : objet, personne, lieu. . .), R - R sont des références issues de la requête langagière.  Exemple : La phrase 6 de la table 1 pourra ainsi s'écrire sous la forme :  CHECK(NEG(DIFFERENCE(between=&#34;le bouton 'fermer'&#34;, and=&#34;le bouton 'quitter'&#34;, is=&#34;fonctionnement&#34;))) Si l'on s'intéresse alors au nombre de modalités ou de prédicats présents dans chacun des souscorpus, on constate des différences assez nettes (cf. figure 5) : - le contrôle possède un nombre élevé de prédicats par phrase (0.97) et peu de modalités (0.22). - l'assistance directe contient beaucoup de modalités (2.41) ainsi qu'un nombre moyen de prédicats (0.54). - l'assistance indirecte diffère peu de l'assistance directe avec 0.59 prédicats par phrase et légèrement moins de modalités (2.22), avec toutefois une part plus forte de phrases à modalité unique (18% contre 5%). - le clavardage (limité aux phatiques pour cette étude) est extrêmement pauvre en prédicats (0.08) et assez peu de modalités (0.86).  3.2.4 Conclusion de l'étude  Parmi les trois méthodes testées, aucune ne permet d'identifier parfaitement l'activité correspondant à une requête. On constate en effet que : - la longueur des phrases n'apporte pas d'informations discriminantes, - la comparaison des profils interactionnels permet une discrimination efficace des deux formes d'assistance (directe et indirecte) qui nous intéressent dans le cadre du projet DAFT, - la comparaison des requêtes mises sous forme formelle permet de distinguer le contrôle, l'assistance et le clavardage. Pour classifier automatiquement les requêtes dans un des sous-corpus, on pourra donc envisager de combiner ces deux dernières méthodes.  La Fonction d'Assistance, dans le cadre des CHS, constitue un registre de langue particulier, et  se distingue d'activités connexes comme le dialogue homme-homme orienté tâche. Nous avons constitué un corpus composé de requêtes d'assistance recueillies dans le cadre de diverses applications et d'autres requêtes construites en situation, ce qui nous a permis d'avoir un ensemble globalement représentatif de l'assistance. Nous avons montré que ce corpus recouvre en réalité quatre activités distinctes, identifiables par une combinaison de méthodes statistiques classiques et d'une analyse nécessitant la transcription des requêtes dans un langage formel. Depuis la réalisation de cette étude, le corpus DAFT a été complété, notamment afin de renforcer la proportion de requêtes d'assistance (qui ne représentait ici que 45% du corpus total) en incluant des requêtes relevées face à une application de nature plus complexe (Word). Il compte  ainsi désormais un peu plus de 11 000 phrases, qui nous servent actuellement de base solide  pour la construction de la chaîne de traitement des requêtes langagières (analyses grammaticale et sémantique). Un large extrait sous forme brute ainsi que des phrases analysées par notre système sont disponibles en libre accès .  
