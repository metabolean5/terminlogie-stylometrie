Dans cet article nous présentons une évaluation et une analyse des résultats d'une  méthode de réordonnancement de réponses pour un système de questions-réponses. Cette méthode propose une sélection des réponses candidates à une question en calculant un coût par transformation d'arbres. Nous présentons une analyse des résultats obtenus sur le corpus Clef 2004-2005 et nos conclusions sur les voies d'amélioration possibles pour notre système. This paper describes an evaluation and an analysis of the results of an answers reranking method for a question-answering system. Candidate answers to a question are reordered by computing a tree transform cost. We discuss the results of our evaluation on the Clef 2004-2005 corpus and describe possible improvements to the system. Recherche d'information, Traitement Automatique des Langues, systèmes de questions-réponses. Information Retrieval, Natural Language Processing, Question-Answering systems.  Il est fréquent que l'information recherchée pour répondre à une question soit exprimée en des  termes différents de ceux de la question. Les techniques de recherche d'information traditionnelles sont ainsi souvent pénalisées lorsqu'il s'agit de détecter les variations linguistiques telles que la paraphrase (Ligozat, 2006). Notre objectif est de répondre à cette problématique en proposant une méthode de réordonnancement des réponses candidates à une question en utilisant des arbres représentant la question et un texte contenant potentiellement la bonne réponse (Bernard, 2008). Un coût de transformation est calculé entre ces deux arbres. D'autre méthodes se sont déjà appuyées sur des représentations des textes sous forme d'arbres pour identifier la réponse à une question (par exemple (Ligozat, 2005)), qui se basent sur la structure et les dépendances d'arbres syntaxiques.  L'objectif de cet article est de présenter une analyse de cette méthode. Nous présentons le  contexte d'application de notre approche, le système Ritel, puis nous décrivons brièvement le fonctionnement de notre méthode. En nous appuyant sur les résultats obtenus lors d'une évaluation précédente, nous proposons une analyse de notre méthode et les conclusions que nous en avons tiré. Le projet Ritel (Rosset et al., 2006) du LIMSI sert de contexte pour notre travail. L'un des objectifs de Ritel est de réunir les fonctionnalités d'un système de questions-réponses et d'un système de dialogue oral. Dans cet article nous nous concentrons sur le composant questions-réponses de Ritel. Deux modules du système sont directement liés à notre travail : le module d'analyse des documents et des questions, qui transforme les textes de notre corpus et les requêtes de l'utilisateur en arbres textuels, et le module de recherche d'information.  L'analyse produite par Ritel est non contextuelle (Villaneau et al., 2007). Concrètement, nous  n'utilisons aucune information sur le dialogue pour typer nos textes, et chaque phrase des documents est traitée séparement. Le but est de typer les mots ou groupes de mots en procédant à des regroupements selon le sens de ces mots. Les types des noeuds peuvent appartenir à différentes catégories : entités nommées (une personne, un lieu, etc.), entités grammaticales (des verbes, des prépositions), ou entités spécifiques (par exemple des couleurs, comme "rouge"). Plus généralement, les informations contenues dans les noeuds de nos arbres sont plus d'ordre sémantique que syntaxique. L'analyse est faite de façon hiérarchique : un groupe de mots sera décomposé en plusieurs sous-noeuds typés, et l'ensemble de ces sous-noeuds sera typé par un noeud global. La structure des arbres textuels résultant de l'analyse est plutôt étendue (plus large que profonde). Les arbres ont en moyenne 3 à 4 niveaux de profondeur. Nous donnons dans la figure 1 un exemple de l'arbre textuel. On peut voir que les informations contenues dans les noeuds sont sémantiques (pers_fonct) et syntaxiques (prep). Les noeuds sont cependant plus souvent typés sémantiquement que syntaxiquement. Par ailleurs, le découpage d'un noeud en sous-noeud est basé sur des structures sémantiques.  Le système RI/QA (Rosset et al., 2007) de Ritel est composé de trois modules : la sélection des  documents intéressants, la sélection des passages de texte contenant potentiellement la réponse à la question traitée, et la sélection des réponses candidates. Au début de la recherche, la question est analysée pour déterminer le type de réponse attendu et le système génère un Descripteur De Recherche (DDR) qui permet de guider la recherche de la réponse. Les DDRs représentent les éléments critiques et secondaires de la question ainsi que le type attendu de réponse. Les éléments critiques correspondent aux noeuds importants de la question, et les éléments secondaires aux noeuds dont la présence est plus optionnelle. Dans la figure 1, les éléments critiques seraient "ministre russe" et "atomique", et "énergie" serait un élément secondaire. Chacune de ces trois étapes utilise les informations fournies par le DDR. Le premier module calcule un score pour chaque document selon les différentes entités du DDR et retourne une liste de documents. Le système sélectionne alors les passages des documents pouvant contenir la réponse et retourne  une liste de passages ordonnée. Enfin, à partir de cette liste de passages, le système retourne une  liste de réponses courtes extraites de ces passages. Les réponses sont ordonnées selon un score.  Pour qu'un extrait de texte soit identifié comme pouvant contenir la réponse à la question, il  doit contenir les éléments critiques du DDR. S'il contient les éléments secondaires, le score global du passage sera plus élevé. Cette méthode est comparable à une approche par sacs de mots typés et transformables. Les scores calculés par le système sont proches des scores de compacités (Gillard et al., 2007). Une des limitations des DDRs est qu'ils ne conservent pas toutes les informations. Ainsi, les éléments critiques et secondaires sont conservés, mais pas les prépositions par exemple. Cependant, le problème principal des DDRs reste la perte de la structure de la question : les mots sont classés par importance (critique ou secondaire) et il n'y a pas de gestion du contexte de chaque mot ou de relation avec les autres éléments. Dans l'exemple suivant, les réponses évaluées sont &#34;2005&#34; et &#34;1992&#34;. Le système actuel pourrait donner &#34;2005&#34; comme bonne réponse car elle est proche de l'élément critique &#34;ouragan Andrew&#34; et que &#34;2005&#34; est fréquent dans les différents documents du corpus. Or, avec une gestion des relations entre les différents éléments du texte, on peut déduire que le pronom interrogatif &#34;qui&#34; est lié à &#34;ouragan Andrew&#34; et que la bonne réponse est 1992. Notre objectif est de proposer une méthode pouvant répondre à ces problèmes. Notre méthode intervient en sortie du système RI/QR. Nous récupérons en entrée la question posée par l'utilisateur sous la forme d'un arbre typé, la liste des réponses candidates ordonnée selon un score et la liste des passages du texte d'où les réponses ont été extraites.  Plusieurs systèmes de questions-réponses utilisent des approches à base d'arbres syntaxiques  pour répondre aux questions. Les documents et les questions posées par l'utilisateur sont ainsi transformés en arbres structurés. Les noeuds des arbres peuvent être enrichis avec des informations sémantiques, voire des relations sémantiques avec d'autres noeuds de l'arbre. Ces méthodes ont l'avantage de faciliter la comparaison entre un texte et une question et de repérer les mots ou groupes de mots en relation dans les deux arbres. On parle généralement de points d'ancrage. Par ailleurs, ce type d'approche a l'avantage de faciliter la manipulation des textes, par le biais de la manipulation des noeuds des arbres (Magnini & Kouylekov, 2006). Ces méthodes sont de ce fait adaptées pour générer des paraphrases (Braz et al., 2005). Notre méthode est basée sur le calcul du coût d'une transformation entre l'arbre de la question et l'arbre du passage contenant la réponse. Nous comparons les deux arbres pour trouver la suite d'opérations permettant de transformer l'arbre du texte en l'arbre de la question avec le plus faible coût. Les extraits des documents étant souvent très longs, nous avons décidé d'extraire le segment contenant la réponse candidate. Pour le moment, nous nous servons de la ponctuation pour délimiter ce segment. Nous procédons également à des modifications sur l'arbre de la question. Pour chaque réponse avec le score le plus fort, le passage du texte d'où elle a été extraite est connu. On supprime alors de l'arbre de la question les noeuds correspondant aux pronoms interrogatifs («qui», «comment», etc.) et on ajoute un noeud avec la réponse à évaluer. Des opérateurs de manipulation d'arbres sont utilisés. Cette approche est similaire à celle présentée par (Magnini & Kouylekov, 2006), avec deux différences fondamentales, concernant les opérateurs de transformation et les fonctions de coût associées aux opérateurs. Nous utilisons quatre opérateurs de transformation : suppression d'un noeud, insertion d'un noeud et substitution d'un noeud par un autre, déjà utilisés par Magnini et Kouylekov, auxquels nous ajoutons l'opérateur de déplacement, notre objectif étant de couvrir davantage de phénomènes linguistiques. Le passage d'une phrase en forme active à la forme passive peut être mieux couvert par l'opérateur de déplacement. Nous déterminons les éléments à supprimer en identifiant les relations entre les noeuds du texte et de la question : équivalence pour des noeuds identiques, équivalence de lemmes si la forme lemmatisée des deux noeuds est identique et de synonymie . A chacun des opérateurs de transformation est associée une fonction de coût. Magnini et Kouylekov utilisent des arbres syntaxiques pour représenter leurs textes, qui ont la caractéristique d'être très structurés. Leurs fonctions de coût sont basées sur cette structure. Les arbres typés retournés par l'analyseur de Ritel sont moins profonds et fournissent des informations plus sémantiques que syntaxiques. Nous avons choisi d'avoir une approche basée sur le contexte global de nos arbres. Nous voulons tenir compte de l'ensemble du sens de la phrase lors de l'application d'une opération. Notre objectif est d'avoir un coût dépendant du contexte et du changement linguistique impliqué par l'opération. Dans l'exemple suivant, il serait coûteux de supprimer &#34;vice&#34; car cela change complètement le sens de l'extrait du texte : Les fonctions de coût sont pour le moment assez simples. Le contexte d'une opération est représenté par le type des noeuds voisins gauche et droite. La structure générale de nos fonctions est identique : une suite de conditions portant sur le type du noeud sur lequel est appliqué l'opérateur, le coût de chaque branche étant déterminé par le contexte du noeud.  La figure 2 illustre le fonctionnement de notre approche. Dans un souci de lisibilité, les arbres  sont représentés dans une forme simplifiée (pas de sous-noeuds et de noeud racine). Dans le contexte de l'exemple, on compare le texte Le corps du gourou de la secte Luc Jouret a été retrouvé au Canada avec la question Où le cadavre de Luc Jouret a t'il été identifié ?. La réponse à évaluer est &#34;Canada&#34;, que l'on a insérée à la place de &#34;Où&#34;, qui est un pronom locatif. Les  points numérotés sur la figure 2 représentent les points d'ancrage entre les deux arbres. Ainsi,  les points 1, 2, 4, 5 et 6 sont des relations de noeuds identiques, tandis que les points 3 et 7 sont des relations de synonymie. À partir de ces points d'ancrage, notre système peut calculer les suites d'opérations pour transformer l'arbre du texte en l'arbre de la question. Les fonctions de coût associées à chaque opérateur permettent de déterminer la suite d'opérations la moins coûteuse. Dans le cas présent, une suite d'opération possible est :  1) Suppression des noeuds du, gourou de la secte et au.   2) Déplacement de Canada avant le noeud le.   3) Substitution synonymique du noeud corps par le noeud cadavre.   4) Substitution synonymique du noeud retrouvé par identifié.   5) Insertion du noeud de avant le noeud Luc Jouret et du noeud t'il avant le noeud été.   Méthode proposée  Système Ritel Type de la réponse #questions Acc MRR Acc MRR Rappel raison 15 21.4% 0.24 21.4% 0.27 50.0% couleur 1 0.0% 0.33 0.0% 0.33 100.0% lieu 57 29.1% 0.4 54.5% 0.60 72.7% nombre 42 24.8% 0.35 50.0% 0.57 72.5% organisation 31 18.4% 0.27 47.4% 0.51 60.5% personne 62 25.8% 0.35 36.4% 0.42 63.6% définition d'une organisation 30 30.0% 0.44 46.7% 0.6 86.7% définition d'une personne 41 17.6% 0.32 47.1% 0.55 73.5% inconnu 49 17.1% 0.22 26.8% 0.31 53.7% date 50 37.1% 0.40 47.9% 0.57 72.9% divers 16 0.0% 0.15 18.7% 0.25 50.0% total 395 24.0% 0.34 41.5% 0.48 65.8%  Nous avons évalué notre méthode sur les corpus de questions et de documents des campagnes  Clef 2004 et Clef 2005 (395 questions au total). Trois mesures ont été utilisées pour évaluer notre approche : l'Accuracy, le MRR et le Rappel. L'Accuracy correspond au pourcentage de questions où la réponse retournée en première position est la bonne réponse. Le MRR (Mean Reciprocal Rank) permet d'évaluer la position moyenne des bonnes réponses. Il est calculé en faisant la moyenne des rangs réciproques de chaque question, ce dernier étant obtenu en calculant l'inverse du rang de la bonne réponse à la question. Par exemple, si la bonne réponse à une question est au rang 4, son rang réciproque est de 1/4. Le Rappel correspond au pourcentage de questions dont la liste des réponses retournées contient la bonne réponse. Pour cette évaluation nous avons fixé le nombre maximum de réponses retournées à 10. Nous séparons nos résultats selon le type de la réponse attendue à une question. Cette classification est déterminée automatiquement lors de la génération du DDR. Nous présentons ces résultats dans le tableau 1.  Nous avons fait une deuxième évaluation de notre approche, que nous ne présentons pas ici, où  le nombre maximum de réponses retournées a été fixé à 50 : l'Accuracy moyenne régresse. On peut en déduire que le trop grand nombre de réponses candidates perturbe notre approche. Une évaluation a été réalisée sur la méthode présentée précédemment de Magnini et Kouylekov à Clef 2005 (Tanez et al., 2005). Le système présenté a été testé sur des tâches monolingues pour l'italien et le bulgare. Dans le cas de l'italien, deux évaluations ont été faites pour tester différents paramètres. Avec cette approche, ils obtiennent en tâche monolingue sur le bulgare une Accuracy de 27.5%, le meilleur système ayant obtenu 32.03% . Nous comptons faire prochainement une adaptation de notre système pour le faire fonctionner sur la tâche RTE à laquelle Magnini et Kouylekov ont participé. Leurs résultats se situaient dans la moyenne générale. Nous pourrons ainsi comparer notre approche qui est basée sur une analyse sémantique.  Le tableau 1 montre que notre méthode dégrade les résultats obtenus par Ritel quelle que soit  la catégorie de questions, avec une baisse moyenne de 17%. L'origine de ces résultats peut être expliquée par l'état élémentaire des fonctions de coût associées aux opérateurs. Les principaux défauts sont le manque de précision du calcul du coût linguistique de chaque opération et la mauvaise gestion du contexte d'application d'une opération qui est limitée aux noeuds voisins et non à l'ensemble de l'arbre. L'analyse que nous avons conduit porte sur l'origine des résultats obtenus par notre approche. Certaines catégories semblent mieux adaptées à notre approche, où l'on peut noter une baisse des résultats moindres : &#34;personne&#34; et &#34;date&#34; (baisse d'environ 10%) .  Après avoir analysé les résultats obtenus par notre système lors de l'évaluation, et émis un  certain nombre d'hypothèses sur les origines des scores obtenus (Bernard, 2008), nous avons décidé de procéder à une étude approfondie des résultats obtenus. Nous nous sommes concentrés sur les catégories de question qui nous semblaient les plus pertinentes, et pour chacune des questions, nous avons analysé les causes du réordonnancement produit par notre méthode. Nous en avons déduit des voies d'amélioration pour notre approche.  Nous nous sommes concentrés sur les catégories les plus importantes en nombre de questions :  &#34;date&#34;, &#34;nombre&#34;, &#34;personne&#34; et &#34;lieu&#34;. De plus, ces catégories semblent appropriées à notre approche, car elles semblent être plus sujettes à des problèmes de proximité syntaxique. La catégorie des organisations n'a pas été étudiée car la version de l'analyseur disponible pour cette étude ne détectait pas leurs frontières de manière fiable. On arrive donc à un ensemble de questions étudiées de 211 pour &#34;date&#34;, &#34;nombre&#34;, &#34;personne&#34; et &#34;lieu&#34;. Sur ces 211 questions, 59 ont été mises de côté car la bonne réponse n'est pas contenue dans la liste des réponses candidates, ce qui porte le nombre de questions étudiées à 152.  Nous avons travaillé par catégorie de question pour essayer de déterminer les phénomènes  propres à certaines classes de questions et les phénomènes plus généraux. Pour chaque question, nous avions la liste des réponses ordonnées par Ritel et la liste des réponses réordonnancées par notre approche. À partir des passages de texte d'où étaient extraites les réponses, nous pouvions alors déterminer les causes de nos résultats, aussi bien pour un réordonnancement positif que négatif. Nous avions aussi comme informations les suites d'opérations utilisées lors des transformations des arbres pour réordonner les réponses.  Plus généralement, nous avons analysé les points suivants pour chacune des questions :  - Identification des correspondances entre la question et la phrase contenant la réponse : - recherche des équivalences entre un groupe de mots et un autre ; - identification de la pertinence d'une synonymie (selon le contexte d'une phrase, deux mots ne sont pas forcément synonymes) ; - identification des regroupements entre mots pouvant apporter de l'information ; - Implémentation de mécanismes spécifiques selon le type de la question ; - Informations perdues lors de l'extraction de la phrase contenant la réponse : - pertinence de l'information perdue ; - proximité de l'information par rapport à la phrase contenant la réponse que l'on a extraite ; - présence d'anaphores ; - apport du contexte global du document d'où a été extraite la phrase pour les transformations d'arbre.  5.3.1  Problèmes liés aux sous-noeuds Lorsque nous avons commencé à concevoir notre méthode, l'analyseur de Ritel produisait des arbres très peu profonds. Désormais, il y a une meilleure définition des types et de leur hiérarchie, et nous avons en moyenne une profondeur de 4 niveaux. Notre méthode n'est pour le moment pas adaptée pour traiter ce type d'arbres. L'un de nos problèmes est la non-prise en compte des relations d'équivalences et de synonymies entre les sous-noeuds des arbres : un noeud du texte peut très bien contenir un sous-noeud en rapport avec un noeud de la question mais ils ne seront pas mis en correspondance. Dans l'exemple ci-dessous, &#34;prix Nobel&#34; contenu dans l'arbre de la question n'est pas mis en relation avec celui de la phrase car ce dernier est un sous-noeud.  De même, on peut étendre ce problème aux relations synonymiques dans les sous-noeuds. Dans  l'exemple suivant, la relation de synonymie entre les sous-noeuds &#34;cyclone Andrew&#34; et &#34;ouragan Andrew&#34; n'est par exemple pas détectée. Les types sont identiques, mais la synonymie ne fonctionne pas car elle est faite à un niveau global. Il faut donc descendre dans les noeuds pour valider la relation.  Une première approche pour traiter les sous-noeuds serait de prendre en compte le sous-arbre  sur lequel est appliquée l'opération. Ainsi, on ne substituerait plus un noeud mais un sousarbre par un autre sous-arbre. On identifierait d'abord les opérations élémentaires au niveau des  feuilles des sous-arbres du texte, puis on remonterait dans l'arbre en générant des opérations  plus globales. Si les feuilles d'un sous-arbre du texte sont en relation avec le même sous-arbre de la question, on procéderait alors à la substitution. Le coût serait donc calculé en fonction de l'équivalence entre les structures des deux arbres : type sémantique des différents noeuds proche ou équivalent, peu de noeud pour lesquels on ne trouve pas de relations ...  5.3.2  Perte d'information liée à l'extraction de la phrase  Un deuxième problème souvent observé est l'extraction de la phrase contenant la réponse et la  perte d'informations essentielles qui en résulte. Ce problème est directement lié à notre fonction de coût de suppression, qui pour le moment est élémentaire et ne pénalise pas suffisamment les textes contenant la mauvaise réponse, et la gestion du contexte.  Pour le moment, l'impact de la suppression sur l'ensemble du calcul du coût est délibérément  minoré car cela faussait trop les résultats : les passages du texte comportaient souvent un grand nombre de noeuds et la suppression prenait plus d'importance que les autres opérations. La fonction de coût associée se doit donc d'être bien plus fine. En fixant certaines limites dans l'ensemble de l'extrait du texte (selon la ponctuation mais aussi certaines conjonctions comme &#34;et&#34;, &#34;que&#34;, etc.), il serait possible d'avoir des bornes pour la suppression. Dans l'exemple ci dessous nous avons procédé à une segmentation manuelle. Le texte en entier est illustré, et non pas la phrase extraite par notre méthode, qui correspondrait alors au tout dernier segment. Si l'on identifie l'ensemble des relations entre le texte et la question, on détecte l'existence d'une relation d'équivalence sur les noeuds &#34;World Trade Center&#34; et &#34;attentat&#34; entre la question et le segment 5 qui disparait si on ne traite que la phrase avec la réponse. Les segments traités dans ce cas là sont le cinquième et le huitième.  Dans le cas présent, les bornes de suppression seraient insérées avant le segment 5 et après le  segment 7. Tous les noeuds non compris entre ces bornes seront supprimés. Cette méthode permet donc d'identifier les segments contenant l'information utile. Il est cependant clair que plus un noeud est éloigné des bornes, plus la suppression doit être pénalisante : un noeud contenant un élément critique de la question ne valide pas forcément la réponse évaluée s'il est éloigné du noeud contenant la réponse. Une première idée serait d'avoir une gestion plus poussée du contexte en incluant des relations entre segments pour déterminer le coût des suppressions. On pourrait ainsi modéliser plus précisement l'impact des opérations. Par exemple, le segment 5 décrit la cible d'un attentat, et il est en relation avec le segment 7 qui décrit les conséquences de cet attentat. Le segment 7 est en relation avec les segments 5 et 6 car il contient la date de l'attentat. L'utilisation de relations sémantiques telles qu'elles sont décrites dans (Rosset et al., 2007) serait une possibilité pour traiter ce type de problème.  5.3.3  Ajout de relations entre les noeuds  Au cours de notre analyse, il est souvent apparu nécessaire d'ajouter des relations anaphoriques  ou sémantiques entre nos différents noeuds. Les problèmes concernant les anaphores semblent plus fréquents dans les questions de type &#34;personne&#34; que dans les autres catégories. La nature de ces problèmes est assez diverse : pronoms personnels (&#34;il&#34;) faisant référence à une personne,  ou des références plus complexes. Dans l'exemple suivant, La phrase contenant la réponse à la  question ne contient pas d'informations sur &#34;Jacques Delors&#34;. Par contre la phrase suivante parle de &#34;Jacques Delors&#34; comme étant le "prédécesseur" de Jacques Santer (&#34;son prédécesseur&#34;). Il faudrait pouvoir identifier l'adjectif passif &#34;son&#34; comme faisant référence à &#34;Jacques Santer&#34;. De plus, il faut mettre en relation &#34;Jacques Delors&#34; avec &#34;prédécesseur&#34;. Il faut identifier la relation d'antonymie entre &#34;succéda&#34; et &#34;prédécesseur&#34; qui permet enfin de confirmer que &#34;Jacques Santer&#34; est le successeur de &#34;Jacques Delors&#34;.  Il faudrait donc à la fois disposer d'un module de traitement des anaphores  , avec notamment des règles d'inférences pour déterminer les relations entre les différents noeuds, mais aussi enrichir notre dictionnaire de synonymes en prenant en compte la nature des noeuds.  L'ajout de relations sémantiques se révèle nécessaire, particulièrement pour des relations de type  "géographique". L'obtention de bons résultats dans les questions de type "lieu" semblent particulièrement dépendante de ces relations. Dans l'exemple suivant, la mauvaise réponse &#34;Russie&#34; sera invalidée étant donné que &#34;participe&#34; n'implique pas que Halifax se trouve en Russie. Plus loin, &#34;en nouvelle Ecosse&#34; permet de déterminer où se trouve vraiment &#34;Halifax&#34;. Cette approche requiert à la fois de créer des relations sur les verbes (relation ternaire dans ce cas entre &#34;Russie&#34;, &#34;participera&#34; et &#34;au sommet de Juin&#34;) ainsi qu'une gestion des prépositions de lieu comme &#34;à&#34; ou &#34;en&#34;. Nous avons présenté une méthode ayant pour objectif d'améliorer la sélection des réponses candidates. Cette approche est fondée sur un calcul du coût de transformation entre arbres issus de l'analyse et représentant la question et un texte pouvant contenir la réponse. Nous avons évalué cette méthode sur les corpus Clef 2004 et 2005 et analysé les résultats. Notre approche donne pour le moment de mauvais résultats, principalement à cause du fonctionnement élémentaire de nos fonctions de coûts. Nous avons donc mené une analyse en étudiant les résultats obtenus dans les catégories de questions les plus pertinentes. Nous avons décrit des améliorations à apporter à notre système. L'analyse que nous avons conduite suggère différentes voies d'amélioration. La prise en compte de la profondeur de nos arbres et de leur structure est essentielle pour gérer nos relations d'équivalence et de synonymie entre arbres. Par ailleurs, une meilleure gestion de la synonymie semble nécessaire pour détecter les bonnes réponses. Le dictionnaire que nous utilisons actuellement ne contient pas assez d'informations, et nous étudions des méthodes pour l'enrichir automatiquement. Il s'agirait dans un premier temps d'ajouter des synonymes proches à chaque entrée du dictionnaire, comme "électeurs" et "élisent". Actuellement, le dictionnaire  ne modélise les synonymes qu'entre les mots du même type syntaxique. Une première approche  pour enrichir ce dictionnaire serait d'utiliser wiktionary.org et d'en extraire automatiquement les synonymes. L'extraction des phrases contenant la bonne réponse ne donne pas de bons résultats pour le moment, et nous perdons assez fréquemment des informations critiques. Ainsi, il semble important d'avoir une meilleure gestion du contexte de nos documents par le biais de la détection des relations entre les noeuds d'un arbre. Nous nous intéressons entre autre aux relations de type anaphorique (Vicedo & Ferrandez, 2000). Nos perspectives incluent également l'étude des techniques dites d'implication textuelle (textual entailment) pour améliorer nos résultats (Dagan et al., 2006). Enfin, nous comptons utiliser cette méthode pour améliorer l'interaction entre un utilisateur et un système interactif exploitant les opérations appliquées pour trouver une réponse.  
