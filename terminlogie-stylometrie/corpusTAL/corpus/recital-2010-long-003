La segmentation en mots est une première étape possible  dans le traitement automatique de la  langue chinoise. Les systèmes de segmentation se sont beaucoup développés depuis le premier apparu dans  les années 1980. Il n'existe cependant aucun outil standard aujourd'hui. L'objectif de ce travail est de faire  une comparaison des différents outils de segmentation en s'appuyant sur une analyse statistique. Le but est de définir pour quel type de texte chacun d'eux est le plus performant. Quatre outils de segmentation et deux  corpus avec des thèmes distincts ont été choisis pour cette étude. À l'aide des outils textométriques Lexico3 et mkAlign, nous avons centré notre analyse sur le nombre de syllabes du chinois. Les données quantitatives  ont  permis  d'objectiver  des  différences  entre  les  outils.  Le  système  Hylanda  s'avère  performant  dans  la segmentation des termes spécialisés et le système Stanford est plus indiqué pour les textes généraux. L'étude  de  la  comparaison  des  outils  de  segmentation  montre  le  statut  incontournable  de  l'analyse  textométrique  aujourd'hui, celle-ci permettant d'avoir accès rapidement à la recherche d'information. Chinese word segmentation is the first step in Chinese natural language processing. The system  of segmentation has considerably developed since the first automatic system of segmentation of the 1980's.  However,  till  today  there  are  no  standard  tools.  The  aim  of  this  paper  is  to  compare  various  tools  of  segmentation  by  through  statistical  analysis.  Our  goal  is  to  identify the  kind  of  texts  for  which  these  segmentation tools are the most effective. This study chose four segmentation tools and two corpora, marked  by  distinct  themes.  Using  two  textometric  toolboxes,  Lexico3  and  mkAlign,  we focused  on  the  number  of  syllables  in  Chinese.  The  quantitative  data  allowed  us  to  objectify disparities  between  tools.  The  Hylanda  system  turns  out  to  be  effective in  the  segmentation of  specialized  terms  and  the  Stanford  system  is  more  appropriate  for  general  texts.  The  comparative  study  of segmenters  shows  the  undeniable  status  of  textometrical analysis which is able to quickly access information retrieval. Textométrie, comparaison des segmenteurs chinois, nombre de syllabes Textometry, comparison of Chinese segmenters, number of syllables  Les méthodes d'analyse des textes sur ordinateur sont répandues depuis longtemps dans les travaux sur les   langues occidentales. Mais l'étude textométrique du chinois n'a commencé que dans les années 1980. Les  premières  études  quantitatives  concernaient  la  lexicologie  comme  par  exemple  la  production  du  Dictionnaire des fréquences des mots chinois contemporains (Modern Chinese Frequency Dictionary). De  nombreux travaux sur des livres spécifiques ont été publiés à la même époque, spécialement des ouvrages  sur le chinois classique. Dans la majorité des cas, les calculs de ces études ont été faits manuellement, les  chiffres statistiques ne seraient donc pas garantis sans erreur. C'est ainsi qu'a émergé la recherche sur les  textes qui a mené vers les études statistiques des textes chinois.  Notre  travail  a  pour  objectif  d'effectuer  une  comparaison  de  quatre  outils  de  segmentation,  également   appelés segmenteurs. L'étude est basée sur une analyse textométrique et nous nous sommes concentrée sur  le nombre de syllabes en chinois. La comparaison des segmenteurs a pour but  de définir les spécificités  pour chaque segmenteur en analysant les types de textes les plus adaptés.  L'étude textométrique  en  chinois  s'est  développée tardivement,  certainement à  cause de  facteurs liés  au   système  de  l'écriture  traditionnelle  chinoise.  L'informatisation  de  cette  langue  s'est  en  effet  révélée  beaucoup plus complexe que celle du système basé sur l'utilisation des alphabets latins. La mise en place  de technologies permettant la saisie et l'affichage des caractères chinois a permis de dépasser la complexité  de  ce  système  d'écriture.  La  norme  internationale  du  codage  de  caractère  Unicode  fournit  désormais  la  possibilité de représenter des textes dans toutes les langues, indépendamment du système informatique ou  des plates-formes.  Les progrès considérables des équipements informatiques nous apportent une très grande liberté d'accès à   l'information.  Les  applications  du  traitement  automatique  des  langues  sont  de  plus  en  plus  variées  :  la  traduction, le résumé de textes, la fouille de textes, l'extraction d'information, etc. Le chinois possède une  typographie différente des langues occidentales en raison de son système d'écriture. Un texte chinois est  représenté  par  une  chaîne  de  caractères  continue,  sans  blanc  typographique .  Pour  qu'un  ordinateur  effectue une analyse correcte, la première étape primordiale est de segmenter les textes en unités lexicales  (« tokenisation »,  découpage  d'un  texte  en  mots).  Or,  il  n'y  a  pas  de  consensus  entre  les  Chinois  et  différentes segmentations sont acceptées. Le premier système de segmentation automatique a été réalisé en  1983 par l'Institut aéronautique de Pékin. Par la suite, beaucoup d'outils de segmentation du chinois ont  été développés, mais il n'y a pas d'outil standard. Une même phrase peut être découpée de façon différente  selon l'outil utilisé. Il est donc crucial de choisir un outil de segmentation adéquat permettant l'accès direct  à l'information recherchée.  Étant donné que l'écriture chinoise crée des difficultés dans le traitement automatique des langues, il est   nécessaire d'avoir une norme de la segmentation des mots chinois. Une norme de segmentation du chinois comporte  en  général deux  parties :  segmentation  des  unités  lexicales  et  annotation  des  catégories  grammaticales. En 1993, la République populaire de Chine a conçu la norme de la segmentation des mots                                                   xiandai hanyu fenci guifan) pour le traitement automatique du chinois. Cette norme propose des principes  et des règles de segmentation des mots chinois, qui ne sont pas toujours opératoire et parfois difficiles à  appliquer.  Depuis,  de  nombreuses  normes  de  segmentation  du  chinois  ont  été  créées par  différents organismes  en  Chine  continentale  ou  en  dehors  du  territoire,  afin  d'avoir  des  règles  de  segmentation  améliorées. Elles sont soit appuyées sur cette norme d'État, soit créées par l'organisme en question. Deux  de ces segmenteurs que nous avons étudiés (ICTCLAS et SF_PKU, cf. 2.1) sont fondés sur la norme d'État  . Ils effectuent une segmentation similaire que notre analyse va mettre en évidence.  Nous  avons  utilisé  dans  notre  étude  les  quatre  segmenteurs  les  plus  connus  dans  la  segmentation  du   chinois.  1.  Hylanda Zhongwen zhineng fenci  Le  segmenteur  Hylanda  est  une  application  commerciale.  Il  utilise  des  méthodes  comme  le   nombre maximum antérieur de segments (forward maximum matching, FMM), nombre maximum  postérieur  de  segments  (backward  maximum  matching,  BMM),  etc.  (Liang,  1984).  Son  programme  annote  les  catégories  grammaticales  des  mots  segmentés .  La  caractéristique  de  Hylanda est de reconnaître des entités nommées :  des  noms  propres  de  personnes,  des  noms  de  lieux  géographiques,  des  noms  des  organismes,  etc.,  et  spécialement  des  noms  propres  dans  le  domaine de la mécanique.  2.  Chinese Lexical Analysis System  Le segmenteur ICTCLAS (Zhang et al., 2003) a été créé par la Chinese Academy of Science et a   été  mis  à  jour  plusieurs  fois .  Il  possède  des  fonctions  comme  l'annotation  lexicale,  la  reconnaissance d'entités nommées et  de  nouveaux  mots  et  leur  intégration dans  un  dictionnaire  défini par l'utilisateur. ICTCLAS s'appuie sur un grand lexique et utilise un modèle de Markov .  L'étiquetage grammatical  se  réfère principalement  au  corpus  annoté  du  Quotidien  du  peuple  de  l'Université de Pékin (Yu et al., 2000) car ce corpus est utilisé comme corpus d'apprentissage de  la segmentation.  3.  Stanford Chinese Word Segmenter                                                    été  produit  par  le  groupe  de  spécialistes  du  traitement  des  langues  naturelles  de  l'Université  Stanford.  Cet  outil  utilise  le  modèle  des  champs  aléatoires  conditionnels  pour  étiqueter  les  données  (Tseng  et  al.,  2005).  Il  propose  deux  modèles  de  segmentation  sans  annotation  des  catégories lexicales, l'une s'appuyant sur la norme du corpus annoté de l'Université de Pékin, ou  SF_PKU et l'autre s'appuyant sur celle de Penn Chinese Treebank , ou SF_CTB.  Afin d'initier cette étude de la segmentation en textométrie, deux  échantillons de test contenant un petit  nombre d'unités lexicales ont été choisis. Nous avons utilisé deux corpus de différents domaines possédant  un nombre de caractères similaires correspondant à 16 000 sinogrammes : le corpus de la Constitution de  la  République  Populaire  de  Chine , désormais  Constitution,  et  le  corpus  des  conférences  de  presse  du  Ministère des Affaires Étrangères de Chine , désormais Presse. La taille totale des deux corpus segmentés  par les outils étudiés est entre 8 300 et 9 800 occurrences, ce qui correspond à approximativement entre  1 000 et 1 600 formes différentes (cf. 3.2 pour plus de détails). Pour chaque corpus, nous obtenons quatre  segmentations  différentes  du  même  texte  au  moyen  des  quatre  segmenteurs.  Les  textes  chinois  ont  été  sauvegardés  en  format  texte  brut  avec  le  jeu  de  caractères  GB2312,  qui  est  destiné  à  représenter  les  caractères simplifiés .  Dans un premier temps, les segmentations obtenues pour les deux corpus ont été alignées afin de faciliter   l'analyse.  Pour  cela,  nous  avons  eu  recours  à  l'outil  d'alignement  mkAlign ,  ce  qui  nous  a  permis  de comparer en lexicométrie  les deux  textes.  L'alignement a  permis  d'obtenir  des  textes  où  chaque groupe  aligné est signalé par le symbole dièse « # » comme séparateur. Les quatre textes ont été regroupés dans un  même fichier et séparés par des balises.                                                     Le  module  variation  de  mkAlign  (Fleury,  Zimina,  2009)  permet  de  repérer  toute  variation  d'un  texte  source par rapport à un texte cible ou dans deux types de segmentations d'un même texte, comme c'est le  cas ici. Les différences de segmentation sont mises en évidence au moyen de la coloration. Les numéros  des  paragraphes,  signalés  par  le  séparateur  #  (figure  1)  sont  notés  dans  la  première  colonne.  La visualisation du corpus nous permet d'avoir un aperçu des deux textes et d'examiner leurs différences et  leurs similitudes.  Figure 1 : Variations des textes de segmenteurs Hylanda et celles d'ICTCLAS   Nous  avons  calculé  le  nombre  de  formes  différentes  selon  les  quatre  segmentations.  Six  paires  de   comparaisons ont été faites en s'appuyant sur trois types de distinctions prédéfinies : l'ajout (case verte), la  modification (case bleue) et la suppression (case rouge). Le nombre le plus élevé (case bleue) de formes  différentes  segmentées pour  chaque  paire,  est  obtenu  avec  les  segmenteurs  Hylanda  et  SF_CTB  pour  Constitution.  Pour  Presse, il  est  obtenu  par  Hylanda  et  ICTCLAS.  On  en  déduit  qu'ils  possèdent  de  nombreuses  formes  de  segmentations  différentes.  Les  segmenteurs  ICTCLAS  et  SF_PKU  possèdent,  au  contraire,  le  moins  de  formes  de  segmentations  différentes.  Nous  faisons  l'hypothèse  que  ICTCLAS  et  SF_PKU sont les plus similaires dans la segmentation pour des textes de droit et des textes de presse.  L'étude  de  l'apparition  de  nouvelles  formes  graphiques  du  corpus  Constitution  confirme  les  différences   quantitatives entrevues entre les quatre types de segmentations. La courbe d'accroissement de vocabulaire  calculée simultanément pour les quatre volets du corpus (figure 2) montre que la croissance du vocabulaire  du segmenteur Hylanda augmente plus rapidement que celles des trois autres. L'interruption de la courbe  de  Hylanda  avant  les  autres indique  que  le  texte  comporte  moins  d'occurrences.  La  courbe  (rouge) correspondant à l'apparition de nouveaux mots chinois est située au-dessus de celles qui correspondent à  l'apparition des mots dans les textes segmentés par ICTCLAS, SF_CTB et SF_PKU. Ceci confirme que le  texte  segmenté  par  Hylanda  comprend  le  plus  grand  nombre  de  formes  graphiques.  La  courbe  (jaune)  située au-dessous témoigne que le texte segmenté par SF_CTB possède moins de formes graphiques. Les courbes d'ICTCLAS (verte) et de SF_PKU (bleue) se superposent quasiment. Nous supposons que leurs  segmentations sont similaires. Nous pourrions avancer l'argument que cela provient du fait que ICTCLAS  et  SF_PKU  utilisent  la  même  norme,  la  norme  de  l'État  de  Chine,  à  savoir  celle  fonctionnant  selon  le  corpus annoté de l'Université de Pékin.                                                    mis en rapport d'une courbe à l'autre. Au ralentissement qui survient sur la courbe du segmenteur SF_CTB  (abscisse  2  000)  correspond  un  ralentissement  sur  celle  du  segmenteur  ICTCLAS  et  SF_PKU  (abscisse  1 900) et sur celle de Hylanda (abscisse 1 800). À celui qui survient pour le texte de SF_CTB (abscisse  5 600) correspond également un ralentissement dans le texte de ICTCLAS et de SF_PKU (abscisse 5 000)  et celui de Hylanda (abscisse 4 500).  Quant au corpus Presse (figure 3), les courbes de l'accroissement de vocabulaire se superposent quasiment   dans les premières cinq cents occurrences. L'interruption de la courbe de Hylanda avant les trois  autres,  comme pour le corpus Constitution, confirme que le texte comporte moins d'occurrences. C'est également  le texte segmenté par SF_CTB qui possède le plus d'occurrences pour Presse. Comme le montre la figure  2, le nombre d'occurrences entre les quatre segmenteurs pour Presse est très proche.  La courbe d'ICTCLAS et celle de SF_PKU sont également très proches comme nous l'avons déjà vu dans   Constitution. Sur la figure 3, nous pouvons voir que les quatre courbes suivent la même progression avec  peu de décalage entre elles par comparaison aux  courbes de la figure 2. Cette similarité  indique que les  quatre  textes  de  Presse  sont  segmentés  de  façon  similaire  au  niveau  des  occurrences  et  au  niveau  des  formes graphiques, à l'inverse du corpus Constitution.  Grâce aux représentations graphiques, la distinction entre les segmenteurs apparaît clairement. De plus, le   genre du texte influence la segmentation. En effet, le texte de presse a été segmenté de façon semblable par  les  quatre  segmenteurs,  alors  que  nous  avons  mis  en  évidence  de  grandes  différences  dans  les  versions  segmentées du corpus de droit.  Figure  2 :  Accroissement  de  vocabulaire  dans  les   quatre volets de Constitution Figure  3 :  Accroissement  de  vocabulaire  dans  les  quatre volets de Presse  Le  chinois  est  une  langue  monosyllabique.  Cela  est  vrai  pour  le  chinois  ancien  ou  archaïque  dans  une   forme traditionnelle de la langue écrite du style noble (wenyan) avant l'apparition du chinois vernaculaire  (baihua).  Le  chinois  contemporain  a  tendance  à  passer  du  monosyllabisme  au  dissyllabisme,  voire  polysyllabisme  (Wang,  2000).  Les  deux  corpus  aux  thèmes  différents  (l'un  provient  d'un  domaine  spécialisé,  l'autre  d'un  domaine  général)  segmentés  par  les  quatre  outils,  nous  ont  poussée  à  faire  une  étude sur le nombre de syllabes. D'anciens travaux ont indiqué que le nombre de syllabes est influencé par  plusieurs  facteurs :  phénomènes  phonétiques,  sémantiques,  la  formation  des  mots,  la  communication  de  langue, développement de la société, etc. (Alleton, 1994 ; Huang, Yang, 1990).   Dans cette étude, nous nous sommes appuyée sur les cent premières formes les plus fréquentes de chaque   texte. Les monosyllabes et dissyllabes sont les plus nombreux au sein des deux corpus. Dans Constitution, les  dissyllabes  sont  plus  nombreux  que  les  monosyllabes  (figure  4).  Les  polysyllabes  (trois  syllabes  ou  plus) sont beaucoup moins nombreux. On note tout de même que les pentasyllabes sont particulièrement  remarquables dans Hylanda. Le segmenteur ST_CTB possède peu de quadrisyllabes et aucun pentasyllabe.   Dans le corpus Presse (figure 5), les monosyllabes sont plus nombreux que les dissyllabes par rapport au   texte Constitution. Mais ils sont dominants dans le corpus. Au contraire, les quadrisyllabes sont beaucoup  moins nombreux, un seul quadrisyllabe apparaît dans le segmenteur ICTCLAS et aucun de pentasyllabes.  Figure  4 :  Répartition  des  formes  par  segmenteur   sur  les  cent  premières  formes  les  plus  fréquentes de Constitution Figure  5 :  Répartition  des  formes  par  segmenteur  sur  les  cent  premières  formes  les  plus  fréquentes de Presse  3.3.2 Le nombre de syllabes   Afin de calculer le nombre de syllabes dans l'ensemble des corpus dans chaque segmenteur, nous avons eu   recours à la fonction « groupe de forme » de Lexico3 . Les groupes de formes sont des unités textuelles  définies par l'utilisateur à l'aide d'outils automatiques. Cela permet de regrouper les occurrences de formes  graphiques différentes mais liées par une propriété commune dans le texte, comme la flexion, la dérivation,  etc.  L'analyse  de  la  fréquence  des  mots  comprenant  plus  de  trois  syllabes  montre  que  plus  le  nombre  de   syllabes augmente plus la fréquence de ces mots-là diminue. Il existe donc un lien entre la fréquence d'un  mot et son nombre de syllabes. Zipf (1949) parle de « principe du moindre effort » qui est que le nombre  de syllabes tend à être inversement proportionnel à la fréquence d'utilisation d'un mot. Autrement dit, que  les mots les plus couramment utilisés sont les plus courts. Nous avons obtenu les deux graphes présentés  par les figures 6 et 7 selon ce principe du moindre effort. Les graphes montrent  que  la  répartition  de  la  longueur des mots correspond au principe de Zipf en faisant abstraction des dissyllabes, de plus  en plus  fréquents en chinois contemporain. Les quatre courbes de Presse sont très semblables : elles se présentent  comme un graphe harmonieux.  Rappelons que les monosyllabes sont  plus  nombreux  que les dissyllabes  (cf. figure 5), ce qui n'est pas le cas ici dans l'ensemble du corpus, nous avons examiné la liste des cents  premières formes les plus fréquentes, elles sont les mots grammaticaux «  de (de)   », «  le (particule                                                     conjonctions de coordination «  yu (et) », «  han (et) », les prépositions «  xiang (à, pour) », «  zai (à) », «  dui  (pour)  »,  les  pronoms «  wo  (je) », «  ni   (tu) »,  la  négation  adverbiale «  bu  (ne  ... pas) », etc. Ce sont des mots courants dans un texte général, mais plutôt rares dans un texte du domaine  spécialisé  comme  Constitution.  Dans  ce  dernier,  on  trouve  plutôt  des  mots  pleins  (des  dissyllabes  sont  majoritaires dans le chinois contemporain, cf. figure 4), au contraire, les mots vides y sont peu fréquents.  Les courbes de Constitution sont dissemblables (figure 6). Les plus grandes différences sont relevées entre   les  monosyllabes  et  les  dissyllabes  ainsi  qu'entre  les  trissyllabes  et  les  pentasyllabes.  Par  contre,  les  courbes d'ICTCLAS (rose) et de SF_PKU (bleu turquoise) se superposent quasiment, les fréquences des  mots pour un nombre de syllabes donné est quasi similaire.  Le  choix  de  deux  domaines  différents  pour  chacun  des  deux  corpus  a  permis  de  mettre  en  évidence   l'influence du type de texte d'une part sur la répartition des mots et d'autre part sur la variation du nombre  de  syllabes  des  mots.  Les  textes  du  domaine  spécifique  sont  plus  remarquables  en  ce  qui  concerne  la  différence entre le nombre de syllabes par rapport aux textes généraux comme Presse.  Figure 6 : Effectif des mots en fonction du nombre   de syllabes dans Constitution Figure 7 : Effectif des mots en fonction du nombre  de syllabes dans Presse  3.3.3 Analyse par syllabe   Nous proposons maintenant une étude plus approfondie des sous-parties du corpus. La fonction groupe de   formes de Lexico3 permet d'acquérir une chaîne de caractères contenant le nombre de syllabes à rechercher  au  moyen  d'une  expression  rationnelle .  La  figure  8  paramétrée  par  termes  de  spécificités permet  de  faire une synthèse de la ventilation du nombre de syllabes des mots découpés du corpus Constitution. La  spécificité de telle ou telle syllabe en fonction d'un segmenteur donné apparaît également dans cette figure  8.  Les  formes  de  plus  de  cinq  syllabes  sont  en  nombre  relativement  élevé  dans  le  texte  segmenté  par                                                     texte de SF_PKU et d'ICTCLAS arrivent en second. Les dissyllabes sont en grand nombre dans le texte de  SF_CTB, au contraire, il en existe un petit nombre dans le texte de Hylanda par rapport à SF_CTB. Les  monosyllabes sont relativement plus nombreux dans Hylanda.  Quant à Presse (figure 9), les formes possédant plus de quatre syllabes sont relativement importantes dans   Hylanda, spécialement pour les quadrisyllabes. Le segmenteur ICTCLAS est plus apte à détecter les formes  de cinq syllabes et plus. Elles sont au contraire moins nombreuses dans SF_CTB. Les  trisyllabes  sont  remarquables  dans  SF_CTB.  Quant  aux  dissyllabes,  ils  sont  plus  nombreux dans SF_PKU, mais la proportion de monosyllabes est relativement moins  importante.  Figure 8 : Ventilation des mots d'une syllabe à plus de   cinq syllabes dans Constitution Figure 9 : Ventilation des mots d'une syllabe à plus de  cinq syllabes dans Presse  3.3.4 Pentasyllabes   Hylanda montre une proportion très importante de polysyllabes (cinq syllabes et plus) dans les figures 8 et   9  classés  par  termes  de  spécificités.  Cela  nous  pousse  à  envisager  une  observation  plus  soigneuse.  La  concordance fournie par Lexico3 représente des termes spécialisés polysyllabiques pour le texte Hylanda  en  grand  nombre  dans  Constitution,  p.  ex.   zhonghua  renmin  gongheguo  (République  populaire de Chine) ;   quanguo renmin daibiao dahui (assemblée nationale populaire)  zuigao  renmin  fayuan (cour  suprême  de  justice) ;  quanguo  renmin  daibiao  dahui  changwu  weiyuanhui  (comité  permanent  de  l'assemblée  nationale  populaire).  Hylanda segmente de façon appropriée les termes spécialisés du corpus Constitution. Cela pourrait aider  spécifiquement à la recherche de la terminologie : Hylanda paraît donc plus performant dans ce domaine  que les trois autres segmenteurs.  Nous avons procédé selon la même méthode pour le segmenteur SF_CTB, étant donné qu'il a un taux très   bas  de  quadrisyllabes  et  de  pentasyllabes  en  opposition  à  un  fort  taux  de  dissyllabes.  Les  noms  propres  segmentés correctement par Hylanda sont ici découpés à l'intérieur de la chaîne de caractères en plusieurs  formes graphiques, p. ex. la forme  (République populaire de Chine) est découpée en trois  formes  comme  __ (Chine_peuple_république ). Les  formes  de  quatre  ou  cinq  syllabes                                                     littéralement, 1840 suivi du mot année) et les numérotations des articles de la Constitution, p. ex.    di yi bai ling yi (article 101, littéralement un préfixe servant à former les nombres ordinaux suivi du  nombre  101). Ce  ne  sont  pas  des  termes  spécifiques  du  corpus.  Par  ailleurs,  parmi  les  polysyllabes  segmenté par Hylanda, certains qui sont des termes non spécifiques du domaine ont attiré notre attention. Ce sont des collocations, c'est-à-dire la combinaison de deux termes ou plus qui sont fréquemment utilisés.  Par exemple,   buxing yunanzhe (des victimes) est composé de  buxing (malheur) et    yunanzhe (victime). Ce phénomène pourrait être abordé dans une étude subséquente.  D'après cette étude textométrique  de deux  corpus en quatre segmentations, Hylanda  apparaît comme  un   outil pertinent dans la segmentation des noms propres et plus particulièrement dans un domaine spécifique.  La segmentation de SF_CTB serait plutôt fine, c'est-à-dire que la longueur moyenne des segments est plus  limitée. Les deux autres segmenteurs peuvent être qualifiés d'intermédiaires, aucune spécificité n'ayant été  mise en évidence.  Notre  objectif  est  de  déterminer  quel  type  de  texte  est  le  plus  adapté  pour chaque  segmenteur.  Afin   d'évaluer  nos  analyses,  nous  avons  segmenté  manuellement  (étant  native  chinoise)  en  se  référant  au  Dictionnaire  du  Chinois  Moderne  (  xiandai  hanyu  cidian),  dictionnaire d'autorité  dans  la  langue chinoise. Ensuite, nous avons comparé cette segmentation manuelle avec les quatre segmentations  sur  les  deux  corpus.  De  plus,  nous  avons  comparé  les  noms  propres,  spécialement  les  noms  propres  de  personnes en  chinois  et  la  traduction  littérale  des  noms  étrangers  et  également  les  termes  spécialisés  du  domaine du corpus. Les formes segmentées par les outils qui sont présentes et identiques dans la version  manuelle sont  considérées comme pertinentes alors que les autres  sont  soit  une  segmentation différente,  effectuée selon les règles de l'outil, soit une segmentation erronée. La segmentation manuelle est basée sur  l'introspection de la personne native et sur sa connaissance de la langue, et privilégie le sens complet d'une  forme en tenant compte du domaine du texte. Par exemple, dans le corpus Constitution,   (République populaire de Chine) est segmenté comme une forme lexicale au lieu d'être découpée en trois  formes comme   __ (Chine_peuple_république).  Le  tableau  1  présente  la  précision  des  unités  lexicales  segmentées  par  les  segmenteurs  par  rapport  à  la   segmentation  manuelle. La  bonne  performance  doit  être  interprétée  en  fonction  du  contexte  et  de  la  segmentation manuelle effectuée. La proportion de formes segmentées pertinentes est plus importante dans  le corpus général que dans le corpus spécialisé. Dans les deux corpus, la segmentation de Hylanda est la  plus proche de la segmentation manuelle. SF_CTB est le plus éloigné du découpage manuel pour le corpus  spécialisé  Constitution.  Au  contraire,  il  atteint  une  performance  assez  bonne  de  segmentation  pour  le  corpus général Presse. ICTCLAS et SF_PKU sont intermédiaires et n'ont pas de trait distinctif. Ils ont une  précision assez proche pour les deux corpus.  Tableau 1 : Évaluation de la segmentation des segmenteurs pour les deux corpus (précision)   La segmentation des mots inconnus est toujours une tâche difficile dans le TAL. Nous avons également   évalué ces deux corpus en comptant les noms propres qui y sont présents (tableau 2). Étant donné les textes  de loi du pays comme Constitution, de nombreux termes d'institutions de l'État ou d'organisations ayant  des termes locaux sont apparus (88,3 % pour Hylanda, 42,2 % pour ICTCLAS, 0 % pour SF_CTB, 33 %  pour SF_PKU). Notons que ces termes spécialisés sont entre quatre et treize syllabes. Hylanda a une bonne  performance, alors que ICTCLAS et SF_PKU ont des résultats assez faibles. En revanche, SF_CTB n'est  pas du tout spécialisé dans la segmentation des textes de loi. Par contre, SF_CTB et ICTCLAS montrent un  très  bon  résultat  dans  Presse,  aussi  bien  pour  les  noms  propres  de  personnes  chinois  que  pour  la  translittération des noms étrangers . Au contraire, Hylanda est plutôt faible dans la segmentation des noms  propres  de  personne  dans  Presse.  Cette  évaluation  manuelle  met  en  évidence  l'utilité  de  l'étude  de  ces  segmenteurs.  Cette  expérience  de  petite  taille  sur  deux  corpus  révèle  un  trait  distinctif  entre  les  segmenteurs.  Il  serait  intéressant  d'étendre  notre  étude  à  d'autres  phénomènes  linguistiques  chinois  en  évaluant ces segmenteurs sur des corpus plus volumineux.  Tableau 2 : Nombre de noms propres segmentés dans les deux corpus                                                      Cette  comparaison  de  segmenteurs  sur  deux  corpus  de  thèmes  différents  parvient  à  une  bonne  qualité   d'analyse. Notre étude basée sur le nombre de syllabes du chinois a permis de distinguer un segmenteur plus performant pour les textes spécialisés, et un autre segmenteur plus pertinent pour les textes généraux.  Les deux autres segmenteurs sont apparus relativement similaires, ce qui est justifié étant donné qu'ils sont  fondés sur la norme de l'État de Chine. Leur performance est intermédiaire par rapport aux deux premiers.  L'évaluation de la comparaison de ces quatre segmenteurs au moyen de la segmentation manuelle affirme  que la méthodologie est pertinente dans le cadre de l'étude.  L'étude  sur  le  nombre  de  syllabes  en  chinois  ouvre  des  portes  dans  la  recherche  en  textométrie  sur  la   comparaison  des  outils  de  segmentation.  Une  étude  approfondie  sur  la  variation  du  nombre  de  syllabes  pourrait déterminer si celle-ci est liée à la linguistique chinoise.  L'exploration  textométrique  des  textes  chinois  a  déjà  franchi  certains  obstacles  dus  à  la  complexité  du   système  d'écriture  de  la  langue  chinoise.  Les  résultats  favorables  de  cette  étude  nous  amènent  à  approfondir le phénomène de collocation et d'entités nommées dans la segmentation et à nous demander si  la catégorie grammaticale est un trait pertinent dans la segmentation de la langue.  
