Avec le développement d'internet et des sites d'échanges (forums, blogs, sondages en ligne, ...), l'exploitation de nouvelles sources d'informations dans le but d'en extraire des opinions sur des sujets précis (film, commerce,...) devient possible. Dans ce papier, nous présentons une approche de fouille d'opinions à partir de textes courts. Nous expliquons notamment en quoi notre choix d'utilisation de regroupements autour des idées exprimées nous a conduit à opter pour une représentation implicite telle que la représentation vectorielle. Nous voyons également les différents traitements sémantiques intégrés à notre chaîne de traitement (traitement de la négation, lemmatisation, stemmatisation, synonymie ou même polysémie des mots) et discutons leur impact sur la qualité des regroupements obtenus. With the internet and sharing web sites developement (forums, blogs, online surveys, ...), new data source exploitation in order to extract opinions about various subjects (film, business, ...) becomes possible. In this paper, we show an opinion mining approach from short texts. We explain how our choice of using opinions clustering have conducted us to use an implicit representation like vectorial representation. We present different semantic process that we have incorporated into our process chain (negation process, lemmatisation, stemmatisation, synonymy or polysemy) and we discut their impact on the cluster quality. représentation des textes, représentation vectorielle, traitement de textes courts, regroupements d'opinions. text representation, vectorial representation, short text processing, opinion clustering.  ONYME SARL  1  Avec le développement d'internet, on observe la croissance de nouvelles sources d'informations reflétant  des opinions sur des sujets variés : un film, une actualité, les valeurs d'une entreprise, les prestations d'un commerçant, un site internet, ... Ces sources prennent des formes diverses telles que des sites communautaires (forums, blogs) ou des sites de sondages en ligne. Les textes sont assez courts et dépassent rarement 4 phrases. Dans ce contexte, plusieurs stratégies d'extractions d'opinions («fouilles d'opinions» ou «Opinion Mining») ont vu le jour. Alors que certains travaux visent à une analyse de sentiments afin de déterminer si les auteurs sont plutôt favorables ou défavorables au sujet en question (Poirier et al., 2008), nous nous intéressons à la problématique du regroupement afin d'extraire les principales idées développées. Nous faisons appel à deux techniques différentes : des méthodes d'analyse sémantique qui extraient l'information des textes dans un modèle («représentation de textes») et des méthodes de regroupements non supervisés («clusterings») qui transforment cette information en groupes d'opinions (Fig. 1).  Les textes que nous avons à traiter ont une taille moyenne de deux phrases excèdant rarement 5 mots  chacune. Ils reflètent des opinions d'auteurs différents, n'utilisant pas le même niveau de registre de langue et n'écrivant pas non plus dans un langage fortement rigoureux. Deux constats peuvent être faits. D'une part, la taille des représentations est petite. Chaque texte n'exprime que peu d'idées / opinions, rarement répétées dans un même texte. D'autre part, il n'est pas rare de trouver des fautes d'orthographe ou des abréviations. Si celles-ci portent sur l'opinion du message, il est peu probable que l'on puisse récupérer l'information complète a posteriori d'après le premier constat. Deux grands types de représentations de la sémantique d'un texte existent. Les «représentations explicites», dont les graphes sémantiques sont un exemple (Rastier, 1989) (Sowa, 1984), prennent en compte les liens sémantiques existants entre les mots du texte(«sémantique des mots»). Elles permettent d'obtenir une précision importante mais ne sont pas aisées à construire. Les «représentations implicites» représentent la sémantique en utilisant un ensemble de variables booléennes. Elles ne permettent pas de représenter la sémantique des mots mais offrent une métrique simple de comparaison entre les représentations («distance sémantique») par comparaisons booléennes. Cette distance peut ensuite être utilisée par les algorithmes de regroupements pour rapprocher les données. La représentation vectorielle standard est un exemple de représentation implicite : elle utilise comme variables booléennes, la présence ou l'absence des mots des textes («vecteurs de mots» (Salton et al., 1975)). Cette représentation a fait l'objet de nombreuses études et est souvent utilisée en corrélation avec des méthodes statistiques tels que Hyperspace Analogue to Language (HAL) (Lund et al., 1995) ou Latent Semantic Analysis (LSA) (Deerwester et al., 1990) pour permettre la représentation de la sémantique des mots. Il est également courant d'utiliser des méthodes de pondération afin de mesurer la quantité d'information apportée au texte par chaque mot («pertinence des mots»). Cette information va nous servir à identifier les mots les plus propices aux rapprochements.  CRIL  2 L'utilisation de tous les mots des textes engendre une taille de représentation considérable, difficile à traiter. Il est courant d'effectuer des traitements sémantiques visant à la simplifier en regroupant ou supprimant certaines composantes des vecteurs. Cette simplification des descripteurs a un impact sur la qualité finale du traitement : si les textes ne sont pas correctement représentés, il est peu vraisemblable que le résultat obtenu soit probant car la représentation ne reflétera pas le sens du texte. Certains chercheurs préconisent de ne pas systématiquement employer ces méthodes de simplification mais au contraire de réfléchir à leur pertinence et au fait que des mots supprimés traditionnellement des représentations peuvent être primordiaux pour des traitements proches de la sémantique (Riloff, 1995).  La pondération vise à accorder plus d'importance à certaines variables booléennes, à en pénaliser d'autres  en allant jusqu'à les retirer (équivalent à une pondération nulle) et s'oppose à l'équi-importance qui considère que tous les mots apportent la même quantité d'information. Utiliser une pondération est particulièrement intéressant en clustering pour distinguer les mots véhiculant beaucoup d'informations, de ceux n'en apportant que peu. Deux types d'approches existent. Les premières, méthodes statistiques, se basent sur les occurrences des mots dans le corpus pour déterminer l'importance des mots en contexte. La formule "term frequency, inverse document frequency" (TF.IDF) (Sparck Jones, 1972) en est un exemple. Dans le cadre de regroupements, un mot qui apparaît dans la majorité des textes n'est pas assez discriminant et conduit à rapprocher trop de textes. Un mot apparaissant très rarement conduit à en rapprocher trop peu sur des idées peu représentatives. Les deuxièmes, méthodes linguistiques, consistent à établir une liste des mots à éliminer, considérée comme peu évolutive et de taille raisonnable (Salton et al., 1975) (Salem, 1987). Le contenu et la longueur de cette liste («black list», «stop list» ou «liste noire») sont différents en fonction de la nature du traitement. Quelle que soit l'approche retenue, la suppression à ce stade d'un descripteur important pour le corpus est définitive et provoque une dégradation sensible des résultats.  Dans notre contexte, les opinions étant rarement répétées, il est important de faire attention à ne pas  supprimer de mots utiles pour éviter les pertes d'informations. Utiliser une liste noire pour supprimer les mots inutiles permet le contrôle des mots retirés sous réserve de ne pas y inclure de mots qui pourraient être informatifs. Considérer les autres mots comme équi-importants ne semble pas être une solution efficace car ceux qui véhiculent le plus par leur présence le sens global des textes sont plus importants que les autres. Utiliser une technique statistique de pondération semble donc judicieux. La formule du TF.IDF n'est pas appropriée car sa pertinence repose sur l'hypothèse de répétition des sens importants dans un texte, peu vérifiée si les textes sont très courts. De même, l'IDF seul privilégie les mots très rares. Utile dans un cadre de recherche de termes discriminants, cela a pour effet dans notre cas de provoquer des rapprochements sur des mots issus du niveau de langage du répondant plus que sur les idées exprimées. On peut par contre émettre l'hypothèse que l'importance des mots pour les textes est équivalente à l'importance des mots pour l'ensemble des textes. Nous proposons d'utiliser l'entropie de Shannon appliquée sur l'ensemble des  Analyse sémantique  par des méthodes linguistiques et statistiques  Clustering ou Regroupements  Textes courts d'opinions Représentations  vectorielles des textes Groupes ou  clusters d'opinions  ONYME SARL  3  documents (formule 1) pour que les mots ayant une probabilité d'apparition moyenne dans l'ensemble du  corpus soient privilégiés.  I  = (P  log(P )) , avec P = Occ N b (1)  Dans (1), I  , P et Occ représentent l'importance, la probabilité d'apparition et l'occurrence du mot dans le corpus, et N b , le nombre de mots au total dans le corpus. Deux mots sémantiquement proches devraient obtenir des notes qui reflètent leurs liens. Pour cela, il est courant d'associer à la représentation vectorielle des méthodes permettant d'identifier les liens sémantiques entre les mots du corpus. Une fois encore, les méthodes sont soit statistiques (HAL, LSA) soit linguistiques (utilisation de ressources tels qu'un thésaurus ou une ontologie). Nous proposons d'utiliser une méthode linguistique basée sur une ontologie. La plus connue est le Wordnet de Princeton (Miller, 1995), créé pour la langue anglaise et fondateur des «Wordnets» : ressources aux caractéristiques similaires, développées pour plus de 70 langues et listées par la «Global Wordnet Association» . Chaque unité de sens de la langue est représentée par un groupe de mots porteur de ce sens appelé synset. Des liens sémantiques tels que l'antonymie, l'hypéronymie ou l'hyponymie sont définis entre les synsets. Pour le français, on trouve le Wordnet Libre du Français (WOLF) (Sagot & Fier, 2008), utilisé pour nos tests, et le projet francophone EuroWordnet (Vossen, 1998). Le problème majeur est alors la polysémie des mots car si l'ontologie fournit l'ensemble des sens du mot et les liens existants pour chacun d'eux, il est difficile de déterminer lequel est employé. Dans le cadre de textes longs, la répétition du sens employé dans le texte peut aider à l'identifier, fait non vérifié dans des textes courts. Nous avons donc opté pour une méthode qui calcule la probabilité d'apparition d'un mot t comme la somme des probabilités d'apparition des mots i partageant un de leurs sens en commun avec le mot t (formule 2).  I  = (P  log(P )) , avec P = P , et Syn = s (2)  Dans (2), I  et P représentent l'importance et la probabilité d'apparition d'un mot selon la représentativité de ses sens dans le corpus, i, un mot de l'ontologie, s, un synset de l'ontologie et P , la probabilité d'apparition du mot i calculée selon la sous-formule P de la formule (1). La formule 2 a pour propriétés essentielles de provoquer la maximisation des probabilités d'apparition des mots en considérant chaque mot potentiellement porteur du sens comme porteur et de ne pas requérir de désambiguisation au préalable des sens des mots. Cette stratégie, peu justifiée dans un contexte pluri thématique, l'est dans notre cas car la probabilité d'emploi polysémique d'un terme au sein des textes du corpus se trouve considérablement réduite en l'absence de thèmes multiples.  Le tableau 1 montre les mots identifiés comme les plus importants dans deux corpus de textes différents  selon cette méthode, mots propices aux regroupements d'opinions (ouverture de magasins, progression du chiffre d'affaire, formation à l'anglais, favoriser la mobilité, développer les connaissances culturelles, ...). Les mots «améliorer» et «promouvoir» ont reçu une note identique grâce à la détection d'une proximité sémantique dans leurs sens. Nous expliciterons ensuite les effets sur le clustering de ces pondérations. L'ontologie permet également de tenir compte de la distance sémantique entre les mots lors des regroupements. En l'absence de thèmes multiples, nous considérons que deux mots sont sémantiquement liés si l'ontologie connaît un sens à ces mots partageant un lien. Dans le cas, où plusieurs liens pourraient être trouvés, le lien le plus fort est retenu. A savoir, par ordre décroissant d'importance, la synonymie forte,  CRIL  4  la synonymie faible, l'hypéronymie et la fratrie par hypéronymie commune (formule 3). Ce raisonnement  possède les mêmes propriétés que celles évoquées pour la pondération : maximisation de la probabilité d'identification d'un lien sémantique et non désambiguisation du contexte.  D(i, j) = min  (d(s, s )) (3)  Dans (3), i et j représentent deux mots du corpus, D(i, j), la distance sémantique entre i et j, s et s , deux  synsets de l'ontologie distincts ou non et d(s, s ), la distance entre s et s selon l'ontologie.  La représentation de la négation est un problème à cause notamment des formes multiples qu'elle peut  prendre, simples (ne...pas, ne...plus, ... ) ou complexes (double négation souvent par antonymie), et de sa «portée» dans le texte (sur une ou plusieurs phrases ou parties de phrases). Cette liste n'est pas exhaustive mais illustre bien les problèmes rencontrés. Alors que les chercheurs travaillant sur l'identification de la thématique des textes n'effectuent aucun traitement particulier et se contentent de traiter les mots de la négation comme des mots ordinaires voire de les inclure à la liste noire, d'autres, travaillant sur la sémantique préconisent une différenciation entre les phrases selon que l'idée exprimée est niée ou non (Poirier et al., 2008). Traiter la négation en particulier, nécessite de se confronter au problème de sa portée. Comme les textes sont très courts, nous pouvons poser l'hypothèse que la négation, si elle existe, peut être appliquée sur l'ensemble du texte sans en dégrader le sens (Poirier et al., 2008). Cela n'est bien sûr pas vérifié dans des textes complexes (phrases avec conjonctions, ...).  Afin de valider ces considérations, des tests ont été réalisés sur un jeu d'essai comportant deux sortes de  messages : des messages affirmant aimer les chats et des messages niant aimer les chats. Ils ont consisté à effectuer des regroupements en considérant successivement les marques de la négation comme appartenant à la liste noire, comme des mots ordinaires pour lesquels aucun traitement n'est à faire et enfin comme des mots discriminants permettant de marquer les messages avec une valeur affirmée ou niée. Dans ce  ONYME SARL  5  dernier cas, les marques de la négation et antonymes sont retirés. Puis, les messages sont marqués comme  affirmés, s'ils contenaient un nombre pair d'expressions de négation et antonymes, et comme niés sinon. Dans le cas où la négation est dans la liste noire, aucune distinction n'est faite entre les messages affirmés et niés. Dans le cas du non traitement de la négation, la distinction est faite uniquement sur la présence ou l'absence des mots négatifs. Cela engendre le regroupement à tort des messages contenant une double négation avec ceux n'en contenant qu'une simple : «Rien ne me fera aimer les chats» et «Rien ne me fera détester les chats». Dans le cas du marquage, la distinction se fait sur la polarité induite aux messages par la négation. Cette dernière distinction est la meilleure dans notre cas puiqu'elle permet d'obtenir deux clusters d'opinions opposées : «ceux qui aiment les chats» et «ceux qui n'aiment pas les chats».  Ces méthodes identifient les mots différents à cause des règles syntaxiques et grammaticales mais ayant  une sémantique identique. La lemmatisation identifie la fonction grammaticale et le lemme du mot, soit à l'aide du contexte au moyen d'une désambiguïsation, solution étudiée dans cet article, soit en établissant une liste des différents lemmes possibles du mot («lemmatisation en ou hors contexte»). La stemmatisation ne résout jamais le contexte mais identifie selon la forme et la langue utilisée, la fonction grammaticale du mot et en déduit son radical. La lemmatisation simplifie les représentations de mots dont le radical varie mais pas celles de ceux occupant une fonction grammaticale différente. La stemmatisation, au contraire, est capable d'effectuer des rapprochements entre les mots occupant une fonction grammaticale différente mais pas entre ceux dont le radical varie et provoque de plus un rapprochement non désiré entre les mots sémantiquement différents mais ayant une racine commune.  Nos choix se sont portés sur TreeTagger (Schmid, 1994), étiqueteur multilingue réalisé par le laboratoire  de l'Université de Stuttgart, pour la lemmatisation et sur Snowball, sous projet de Apache Lucène , pour la stemmatisation. Ils ont été testés sur différents jeux de tests. Ils ne commettent pratiquement aucune erreur en contexte orthographique correct. TreeTagger semble même parvenir à désambiguïser correctement dans des phrases comportant des homonymes comme le verbe «porter» et le nom «porte». Sur un corpus mal orthographié, les résultats de lemmatisation s'effondrent. Aucun lemme correct n'a été identifié sur les termes inconnus et peu de fonctions grammaticales l'ont été. Du côté de la stemmatisation, les résultats sur un corpus mal orthographié sont mitigés. Les mots sur lesquels la faute porte sur la partie considérée comme le radical n'ont pas été corrigés. De même, certaines fautes portant sur le suffixe ont modifié le radical retourné par Snowball (exemple : «jouet» donne le radical «jouet» alors que «jouer» donne le radical «jou»).  Ces tests sur la lemmatisation et la stemmatisation montrent que la lemmatisation est peu efficace dans un  contexte orthographique difficile. Cela est surtout un handicap si le terme affecté est un terme décisif pour les regroupements. La stemmatisation se révèle être une solution si la faute ne modifie pas le radical du mot. Ces constats nous ont conduits à supposer que la combinaison des deux méthodes permettrait de tirer parti des avantages de chacune des deux stratégies : la lemmatisation permet de regrouper dans un premier temps les mots dont le radical évolue et la stemmatisation, de regrouper ensuite les différentes formes grammaticales d'un même concept tout en corrigeant éventuellement quelques fautes d'orthographe. Les résultats intermédiaires obtenus après la lemmatisation sont conservés et utilisés lors des rapprochements sémantiques à l'aide de l'ontologie. Il serait également possible d'utiliser les statistiques ainsi obtenues  CRIL  6  pour déterminer si deux mots proches après stemmatisation le sont à cause de leur sémantique.   Dans le tableau 1, «formation»/«formations», «culturel»/«culturelle» ont la même importance grâce à la  lemmatisation, et «culture»/«culturelles», «expatriation»/«expatriés» grâce à la stemmatisation. Le tableau 2 reprend les 120 combinaisons de traitements sémantiques évoquées. Parmi elles, celle soulignée dans le tableau s'est démarquée dans nos réflexions et tests par son adéquation avec nos attentes. Une analyse des regroupements obtenus au moyen d'une méthode hiérarchique dans cette configuration est présentée dans le tableau 3. Les tests, conduits sur méthode par partitions (KMeans), ont montré des problèmes sémantiques similaires à ceux évoqués ci après pour la méthode hiérarchique.  Dans le premier extrait, les idées de «réunion régulière», «proximité, convivialité», «fêter les succès» ont  été détectées. L'expression «mise en place» a été considérée comme une opinion au lieu des compléments de cette expression. Dans le deuxième extrait, les idées «d'écouter et de voir» aussi bien les clients que d'autres métiers et de «voyage» ont été trouvées. Cet exemple montre l'intérêt d'employer des techniques tels que la lemmatisation ou la stemmatisation : le rapprochement sémantique a ainsi pu être fait entre le nom «voyage» et le verbe «voyager». Dans le troisième extrait, «projets internationaux» et «projets mondiaux» ont été rapprochés par la détection de liens sémantiques entre les termes «internationaux» et «mondiaux». Par ailleurs, cet extrait porte sur l'un des deux jeux utilisés pour tester la pondération. On retrouve bien les idées faisant l'objet de la plus forte pondération : formation à l'anglais, favoriser la mobilité et développement des connaissances culturelles. Dans le dernier extrait, notre traitement de la négation en particulier a permis de rapprocher le message «je n'ai pas eu de problèmes avec les produits» du groupe «satisfaction produit». En revanche, sur des textes plus complexes, notre technique engendre comme prévu, des erreurs de compréhension : le message «je n ai rien a dire je suis tres heureuse de ma commande» a été rapproché du groupe «insatisfait commande» à cause de la négation qu'il comprend («n»). «mercie a vous touts» a été bien classé, malgré l'orthographe, en combinant la lemmatisation et la stemmatisation, mais «je crois savoir ma la respnsable du pont relais...» ne l'a pas été.  Une analyse statistique a été menée sur le clustering produit par cette méthode hiérarchique sur un jeu de  test créé à partir de plusieurs corpus. Cette qualité a été évaluée, sur l'ecart entre le nombre de groupes attendu et produit, et sur l'homogénéité de ces derniers. Chaque message est codifié manuellement selon l'idée principale qu'il exprime. L'homogénéité d'un cluster correspond au pourcentage de messages codifiés avec l'idée majoritaire du cluster. Si aucune idée n'est majoritaire, le cluster est déclaré comme totalement hétérogène. L'homogénéité globale est ensuite calculée comme la moyenne des homogénéités  ONYME SARL  7  CRIL  8 le critère d'homogénéité. Nous avons pris comme référence la combinaison mise en évidence précédemment («solution avec tous les traitements»), puis nous l'avons comparée avec quelques autres proches en terme de traitements (Fig. 2).  La solution de référence obtient un bon résultat mais les autres traitements de la négation (en liste noire  et sans traitement) semblent meilleurs, le traitement en liste noire l'étant davantage que la solution sans traitement. Parmi les messages comportant une négation dans ce jeu, seul 44% répondent aux critères de complexité évoqués. Cela illustre la faible pertinence de cette solution en présence de messages complexes. Il est également intéressant de souligner que toutes les solutions ont produit un nombre de clusters plus élevé que celui attendu. Nos solutions n'arriveraient donc pas à regrouper les idées autant qu'un expert. Ce test met également en évidence la très forte pertinence de la liste noire et de la distance sémantique des mots calculée selon les sens. Tous les tests réalisés contradictoirement obtiennent des résultats nettement inférieurs. La pondération des sens semble meilleure que la pondération des mots car elle permet de produire moins de groupes même s'ils semblent légèrement moins homogènes. L'emploi de la lemmatisation ou de la stemmatisation semble indispensable sous peine de produire un nombre de clusters trop élevé. La lemmatisation se révèle toutefois plus efficace que la stemmatisation et de qualité presque égale voire légérement supérieure à la combinaison des deux méthodes. Ce constat tend à prouver que la stemmatisation peut dégrader les résultats par rapprochements de mots ayant seulement une racine commune.  20  25 30 35 40 45 50 55 60  0  5 10 15 20  ONYME SARL  9  se révèle être médiocre dans un cadre contraire. Enfin, la lemmatisation se révéle très peu efficace dans  un contexte orthographique difficile. Ce constat n'est pénalisant dans notre application que si les fautes portent sur l'opinion évoquée. La stemmatisation des formes lemmatisées permet de les corriger dans le cas où le radical n'est pas affecté. Les axes de travaux futurs concernent la mise en place d'une correction orthographique automatique du corpus avant le traitement et une réflexion plus approfondie sur la gestion des messages complexes comportant plusieurs idées.  Je remercie messieurs Pierre Marquis et Vincent Dubois, directeur et co-encadrant de thèse, et messieurs  Antoine Serniclay et Thibaud Vibes, responsables d'Onyme, pour leurs conseils dans mes recherches.  
