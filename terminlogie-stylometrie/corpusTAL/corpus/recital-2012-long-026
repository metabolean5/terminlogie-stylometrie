Cet article décrit les méthodes que nous employons pour transformer les arbres syntaxiques  du corpus de Paris VII en arbres de dérivation d'une grammaire AB (Lambek, 1958), pour l'extraction de cette grammaire et son utilisation pour l'analyse de phrases. Les grammaires AB sont utilisées dans des algorithmes d'apprentissage tels que celui de Buskowsky et Penn (Buszkowski et Penn, 1990), qui permet d'apprendre une grammaire AB rigide , ou celui de Kanazawa (Kanazawa, 1998), permettant d'apprendre une grammaire k-valuée ; c'est pour cela que nous avons souhaité, dans un premier temps, utiliser de telles grammaires. Les grammaires AB représentent un fragment des grammaires de Lambek, comprenant uniquement des règles de dérivation de type a  a/b b et a  b b\a. Le corpus de Paris VII (Abeillé et al., 2003) est composé de 12855 phrases tirées du journal Le Monde, annotées et analysées par le laboratoire de Paris VII. Les arbres syntaxiques sont planaires, le nombre de fils par noeud et la profondeur ne sont pas fixés. Cela rend l'application d'algorithmes d'apprentissage usuels impossible ; nous avons donc pris le parti d'utiliser un transducteur d'arbres. Nous avons utilisé, pour notre travail, une sous-partie du corpus, présentée sous forme parenthésée de 12351 phrases, alors que le corpus complet est au format XML. Les 504 phrases laissées de côté forment un corpus annexe dont nous nous servons pour l'évaluation.  En premier lieu, nous présenterons le transducteur, utilisé pour transformer les arbres syntaxiques  en arbres de dérivation, puis nous nous pencherons sur l'extraction d'une grammaire PCFG. La troisième partie détaillera l'analyse du placement des syntagmes prépositionnels dans la phrase ; tandis que la quatrième présentera les résultats expérimentaux obtenus en utilisant notre grammaire PCFG pour trouver la meilleure analyse possible pour une phrase via l'algorithme CYK (Younger, 1967). Ce n'est pas la première fois que les transducteurs sont utilisés dans le cadre de la linguistique computationnelle ; on peut citer Knight et Graehl (Knight et Graehl, 2005), qui utilisent des transducteurs d'arbres à états finis, dont hélas l'utilisation ne correspondait pas à notre problématique.  Des travaux de recherche plus appliqués, tels que (Hockenmaier et Steedman, 2007; Moot,  2010a,b; Moortgat et Moot, 2001), utilisent des algorithmes spécialisés qui s'appliquent uniquement à un corpus donné, avec un espoir faible de réutilisation. Etant donné les différences d'annotations d'un corpus à l'autre, et les variations grammaticales que l'on peut trouver entre deux langues, adapter un outil pour le corpus de Paris VII est toujours particulièrement laborieux. Etant donné que nous avons totalement séparé, lors de l'implémentation, le fonctionnement du transducteur de l'ensemble des données qui lui sont passées en entrée ( telles que les fichiers de règles et le corpus sous forme parenthésée), nous pensons qu'un lissage des données suffit à appliquer notre transducteur à d'autres ensembles d'arbres.  Le transducteur que nous avons créé est le pivot central du processus d'extraction de grammaire.  En effet, c'est la binarisation des arbres syntaxiques, fondée sur les règles usuelles de dérivation d'une grammaire AB et les annotations morpho-syntaxiques du corpus (Abeillé et Clément, 2003), qui paramétrise la grammaire extraite. Nous avons d'abord mis au point une version théorique de notre G-transducteur (G pour généralisé) avant de l'implémenter pour le tester sur le corpus de Paris VII.  La création du transducteur d'arbres est décrite en détail dans (Sandillon-Rezer et Moot, 2011).   En nous fondant sur les transducteurs d'arbres top-down décrits dans TATA (Comon et al., 2007),  nous avons généralisé les règles de transduction de manière à créer un outil plus adapté au corpus de Paris VII. Ainsi, on peut dire que les trois principales différences entre un transducteur top-down classique et notre G-transducteur sont : sa récursivité, sa paramétrisation et son système de règles de priorité.  La récursivité permet d'appliquer un ensemble de règles à un noeud, jusqu'à ce qu'il soit traité  en entier, sans pour autant changer l'état du transducteur ni utiliser un nouvel ensemble de règles de transduction (voir figure 1).  La paramétrisation permet de définir des règles avec variables. Ainsi, on peut donner une  transduction générale pour les adverbes et les modificateurs (voir figure 2).  Les règles de priorité : assurent le déterminisme de notre transducteur. Ainsi, lorsque deux  règles peuvent s'appliquer, on leur donne un ordre d'application qui permet d'avoir toujours les mêmes arbres de sortie (voir figure 3).  F  1 - Le nouveau noeud P : y a moins de fils qu'avant la transduction et pour le transducteur, il restera dans le même état et avec le même label que le noeud parent P :x . Généralement, la règle sera écrite de manière à ce que le sous arbre T :z soit binaire et les types y et z doivent obligatoirement se combiner pour donner le type x.  F  2 - La même règle sera appliquée pour X  {ADV, PP MOD, AdP MOD, AP MOD, ...}  F  3 - Lorsque plus d'une règle peut s'appliquer à un arbre, le fait de suivre un ordre prédéfini permet d'éviter le non-déterminisme du transducteur.  Les règles ont été déduites d'une analyse systématique des formes présentes dans le corpus. Un  exemple de règle est donné dans la figure 4 et un de résultat dans la figure 5. Une fois le corpus transformé en forêt d'arbres de dérivations, nous n'utilisons plus le transducteur, que ce soit pour l'extraction de grammaire ou l'analyse de phrases.  (rule  (SENT:* NP-SUJ (VN tree VPP) PP-OBJ) (&#34;SENT:*&#34; &#34;NP-SUJ:np&#34; (&#34;VN:np\\*&#34; &#34;VN:(np\\*)/(np\\s_p)&#34; (&#34;:np\\s_p&#34; &#34;VPP:(np\\s_)/pp&#34; PP-OBJ:pp))))  F  4 - Exemple de règle telle que donnée au transducteur. On note deux points importants, directement dérivés des spécifications de notre G-transducteur : le mot clef tree, qui permet de remplacer &#34;un certain nombre de noeuds&#34;, qui peut apparaître plusieurs fois dans le motif de départ mais pas dans le motif de remplacement ; et le type *, qui remplace n'importe quel type hérité des étapes précédentes.  Même si le lexique, récupéré à partir des feuilles des arbres de dérivation, suffirait à représenter  la grammaire AB, il nous limite aux mots présents dans le corpus. Or, bien que nous puissions avoir des probabilités sur les types des mots, nous voulions une grammaire PCFG. Par conséquent, nous avons pris le parti d'extraire une grammaire probabiliste à partir des arbres.  Les arbres en sortie du transducteur donnent des informations à la fois syntaxiques, car nous  gardons les labels donnés par le corpus et, bien sûr, des informations structurelles. Nous avons pris le parti de laisser le choix des informations que nous souhaitons garder, en effectuant une passe de prétraitement, sachant bien sûr que les types sont, de toute façon, obligatoirement conservés. La grammaire extraite sera de toute façon une grammaire hors contexte, avec une probabilité calculée sur les règles en fonction de leur racine. Pour plus de simplicité, on rappelle que les grammaires sont de la forme {N, T, S, R} :  N l'ensemble des symboles non terminaux, correspondant aux noeuds internes de l'arbre.   T l'ensemble des symboles terminaux, correspondant à l'ensemble des mots typés.   F  5 - Arbre d'entrée et de sortie du transducteur correspondant à la phrase &#34;Pholmann lancera les demandes de permis de construire au mois de janvier.&#34;.  S le symbole initial. On choisira, en fonction de la passe de pré-traitement, TXT :txt ou txt.   R l'ensemble des règles.  L'algorithme utilisé pour extraire la grammaire consiste à parcourir les arbres donnés en paramètre et stocker les règles de dérivation que l'on rencontre. On considère qu'une règle de dérivation est constituée d'une racine et d'un ou deux fils :  La racine a deux fils : On est dans le cas de figure classique d'une règle d'élimination à droite  ou à gauche (a  a/b b ou a  b a\b).  La racine a un seul fils : Il y a simplement transmission de type au fils. Ce cas de figure apparaît,  par exemple, lorsqu'un groupe nominal est composé uniquement d'un nom propre, ou encore lorsqu'on est au niveau du noeud pré-terminal, c'est à dire l'étiquette de partie du discours (POS-tag) de la feuille. Dans ce cas, la feuille héritera directement du type du POS-tag.  Chaque règle est accompagnée d'un compteur et les probabilités sur les règles sont calculées par  groupe ayant la même racine. On récupère aussi des informations de profondeur minimale et maximale d'apparition de la règle, cependant elles ne sont pas utilisées pour l'instant. Ainsi, on résume dans le tableau 1 les différentes grammaires que peut générer l'extracteur .Chacune des versions montre un intérêt : autant la première, extraite des arbres juste après transduction, garde les informations syntaxiques données par le corpus ; autant les suivantes sont plus utiles pour appliquer un algorithme d'analyse de phrases, tel que CYK (voir section 4), sur des phrases non typées. Le tableau 2 montre des extraits des différentes grammaires en fonction des arbres donnés en entrée.  T  1 - Grammaires extraites en fonction des arbres de dérivation donnés en entrée. On précise que n  N et t  T.  T  2 - Exemples des différentes règles que l'on peut extraire des arbres.  La question de l'analyse de phrases en fonction d'une grammaire PCFG se subdivise en deux  problèmes. En effet, il faut d'une part trouver les types des mots et d'autre part que les règles existent dans la grammaire passée en paramètre à l'analyseur.  En réunissant les feuilles des arbres de dérivation, nous pouvons collecter un lexique contenant  les mots, leur occurrence, les types de ceux-ci et la probabilité du type (nb_occurrences_du_type/ nb_occurrences_du_mot). Cependant, nous n'utilisons pas encore le lexique pour typer les phrases que nous analysons. Il faudrait pourtant sélectionner les types apparaissant le plus souvent et les lier aux mots. Cette technique n'assurerait pas l'analyse systématique de la phrase, car si le type nécessaire fait partie de ceux écartés, une phrase juste pourrait ne pas avoir d'analyse. Nous avons pris le parti de typer les mots soit en utilisant le Supertagger ((Moot, 2010a,b)), soit en utilisant les phrases typées à la sortie du transducteur. La première méthode nous permet à la fois de valider les types donnés aux mots par le Supertagger et d'analyser des phrases dont les mots n'apparaissent pas dans le corpus de Paris VII, tandis que la seconde méthode nous permet de tester nos différentes grammaires en fonction des arbres de dérivation. On peut aussi utiliser un typage plus manuel, qui utilise le Supertagger pour effectuer une première passe de typage et qui permet ensuite à l'utilisateur de modifier à loisir les types proposés.  Pour l'algorithme de reconstruction des phrases, nous avons décidé d'utiliser l'algorithme CYK  (Younger, 1967; Knuth, 1997; Hopcroft et Ullman, 1979) et d'en implémenter une version probabiliste : en effet, étant donné que cet algorithme a déjà été testé et est une référence, il nous a permis de tester l'efficacité de notre grammaire sans avoir à s'inquiéter de l'efficacité de l'algorithme. D'autres algorithmes auraient pu être utilisés, tel que celui d'Earley (Earley, 1973), cependant CYK demandait en entrée une grammaire très proche de celle que nous obtenions après extraction. De plus, l'ajout de l'aspect probabiliste était trivial sur cet algorithme. La seule modification que nous avons effectuée était de retirer la phase de typage des mots, initialement effectuée par CYK grâce aux règles de type n  t . Nous avons donc pu donc utiliser la grammaire la plus simple, de 3494 règles, pour analyser les phrases. Le premier test effectué, pour savoir si l'algorithme fonctionnait correctement, a été d'analyser les phrases extraites des arbres de dérivation avec les règles provenant de ces mêmes arbres. Nous avons ensuite pu tester l'analyse avec des phrases typées par le Supertagger ou notre transducteur et des grammaires extraites soit du corpus de 12351 phrases, soit du corpus de phrases laissées de côté (cf section 6).  Les arbres de dérivation correspondants aux phrases &#34;Pourtant tout n'est pas gagné.&#34; et &#34;Ce  procès gagné donne au Crédit Lyonnais les coudées franches pour gérer MGM&#34; sont montrés dans la figure 6 et 7. A chaque fois, on a pris les deux arbres les plus probables, typés par le Supertagger et les phrases ont été analysées avec la même grammaire et l'algorithme CYK. Deux informations sont intéressantes pour choisir quel est le meilleur arbre de dérivation sur les phrases : on regarde à la fois la complexité des types et la probabilité. Cependant, nous sommes conscient qu'il est complexe de comparer deux arbres qui n'ont ni la même structure, ni les mêmes feuilles. La préférence que l'on porte à un résultat sera fortement dépendante des critères de sélection donnés. Ainsi, sur la figure 6, on remarque que les deux arbres ont la même probabilité, cependant nous sélectionnons celui qui a l'indexation la plus faible pendant l'exécution de CYK. Sur la seconde phrase (figure 7), c'est majoritairement l'attachement du groupe prépositionnel final qui modifie la forme de l'arbre. L'attachement de la préposition à un groupe nominal est plus représentatif du corpus d'origine (voir section 5) .  F  6 - Le premier arbre est généré avec le typage du transducteur et a une probabilité de 9, 6x10 et le second est typé avec le Supertagger, avec une probabilité de 1, 9x10  Nous allons nous focaliser sur l'analyse des syntagmes prépositionnels (PP, PP-MOD, PP-OBJ  etc.) et de l'attachement par rapport à la phrase. Dans un premier temps, nous étudierons l'attachement des groupes prépositionnels dans le corpus d'origine, puis nous nous focaliserons sur les types des prépositions, via le transducteur et le Supertagger pour enfin nous pencher sur l'attachement dans les arbres de dérivation générés via l'algorithme CYK.  Les groupes prépositionnels sont particulièrement nombreux dans le corpus (49039 occurrences).  Comme nous pouvons le voir dans le tableau 3, ils sont majoritairement étiquetés PP. Leur attachement de départ dans le corpus est aussi particulièrement important, car c'est celui-ci qui définira le type de la préposition. Le tableau 4 résume la répartition des syntagmes prépositionnels dans le corpus, en fonction de leur parent. En effet, la transduction aura tendance à donner un type aux syntagmes prépositionnels qui correspond à leur place dans la structure de la phrase.  F  7 - Probabilité du premier arbre : 2, 2x10 . Probabilité du second arbre : 1, 5x10 .  Ainsi, dans un groupe nominal, le PP aura plus souvent le type n\n, alors qu'au milieu d'une  phrase le typage sera plus complexe. Lors de la transduction, on ne change pas l'ordre des mots, mais quelques fois leur attachement au sein de la structure. Cependant, on peut dire que les groupes prépositionnels ne bougent pas, sauf s'ils sont à l'extérieur d'un noyau verbal et que celui-ci se termine par un VPP, auquel cas on lie plus spécifiquement le participe passé au groupe prépositionnel, comme on peut voir figure 4.  T  3 - Distribution des groupes prépositionnels en fonction de leur label.  Pour étudier le typage, nous nous sommes focalisés sur les groupes prépositionnels dont, bien  sûr, la transduction avait réussi. Cela fait tomber le nombre de syntagmes prépositionnels à 45351 (92, 5% du total). Les quatre familles de types les plus donnés (au dessus de 2000 fois) par le transducteur sont résumés dans le tableau 5. Ils couvrent 92, 2% des types que l'on peut trouver pour des prépositions. Les types restants, marginaux, correspondent, par exemple, à un syntagme prépositionnel contenant uniquement un pronom relatif, qui prend en argument une  T  4 - Distribution des groupes prépositionnels en fonction de leurs parents. On remarque que les groupes nominaux sont ceux qui regroupent le plus de PP , c'est à dire presque la moitié.  subordonnée.   Le typage effectué avant l'analyse via CYK, avec le Supertagger, nous permet de régler la précision  que l'on souhaite sur les types : en effet, on peut régler le paramètre , qui déterminera le nombre de types possibles autorisés par mot. On gardera alors les types ayant une probabilité supérieure ou égale à  fois la plus grande probabilité trouvée . Le tableau 6 résume la justesse des types donnés aux prépositions en fonction de . On remarque que ce sont des mots difficiles à typer, étant donné que les résultats sont inférieurs aux résultats globaux, bien que les adverbes et les verbes soient encore plus complexes à typer de manière exacte. Il faut cependant noter qu'il n'est pas nécessaire d'avoir une formule correcte pour que l'attachement du syntagme prépositionnel dans la phrase soit correct.  T  5 - Les quatre familles de types les plus courants correspondent à un modificateur de groupe nominal, un groupe prépositionnel généralement argument d'un groupe verbal et des modificateurs de phrase, placés au début ou à la fin de la phrase.  T  6 - Justesse du typage via le Supertagger.  Pour cette partie, nous nous sommes focalisés sur 55 PP, que nous avons sélectionnés dans le  corpus d'origine, de manière à respecter le ratio présenté dans le tableau 3. Cela correspond à 21 phrases, dont l'analyse a réussi. Nous avons généré les types possibles avec  = 0.05. Ensuite, nous avons étudié la différence de types donnés aux prépositions ainsi que leur attachement. On remarque, dans le tableau 7, que les syntagmes prépositionnels liés aux groupes nominaux sont attachés sensiblement au même endroit. On note une différence faible entre les groupes prépositionnels qui seront arguments d'un verbe, un peu plus importante entre les modificateurs globaux qui agissent sur toute la phrase. Il y a 4 cas, dans les arbres régénérés via CYK, où l'algorithme a jugé plus pertinent de préférer le type n ou np pour le syntagme prépositionnel (&#34;On ne porte pas impunément atteinte à des tabous.&#34;), alors qu'on s'attend plutôt à une analyse qui lierait &#34;atteinte&#34; et &#34;à&#34; et qui prendrait en argument le groupe nominal &#34;des tabous&#34; .  On peut dire que le typage et l'attachement des syntagmes prépositionnels semblent cohérents  avec l'attachement présent dans le corpus d'origine, ainsi que le typage effectué par le transducteur. Cependant, pour pouvoir l'affirmer, il faudrait faire des tests plus poussés, qui prendraient en compte la totalité du corpus.  T  7 - Typage des prépositions dans le cadre d'une transduction comparées à celui effectué via le Supertagger avant reconstitution des arbres de dérivation avec CYK. Les modificateurs autres sont des modificateurs de proposition infinitive ou de syntagme adjectivaux.  Le typage, cependant, n'est pas entièrement lié à l'attachement dans la phrase. Nous avons  comparé l'attachement des syntagmes prépositionnels et nous pouvons dire que, sur les 55 cas, il y en a 37 placés de manière identique et 18 non, soit 67, 3% de ressemblance. Les différences majeures sont au niveau des prépositions qui sont plus souvent attachées aux groupes nominaux et argument des noyaux verbaux (ceux-ci peuvent alors prendre le type np plutôt que pp).  L'évaluation des différentes méthodes a été effectuée avec différents ensembles de données. Pour  tester la totalité de nos travaux, nous avons utilisé le corpus de Paris VII dans son intégralité, c'est à dire : - Les 12351 phrases parenthésées que nous avons étudiées en profondeur pour fonder l'ensemble de règles de notre transducteur, que nous appellerons corpus principal. - Les 504 phrases qui n'existaient pas sous forme parenthésée. Ce corpus annexe a été adapté pour être sous forme parenthésée et pour que les étiquettes soient celles utilisées par les règles. Quel que soit le corpus utilisé, on parlera d'un corpus partiel pour dénoter le fragment dont la transduction a réussi. Les grammaires extraites des arbres de dérivation, donc des corpus partiels, auront le même nom que le corpus dont elles sont extraites, soit grammaire principale et grammaire annexe. L'évaluation du transducteur et de l'analyseur de phrases se mesure en pourcentage de phrases sur lesquelles l'opération a réussi. Dans le cadre du transducteur, cette notion correspond à la transformation des arbres syntaxiques en arbres de dérivation et dans le cadre de l'analyseur, elle correspond à la réussite de la combinaison des types donnés aux mots par le Supertagger.  Le transducteur transforme pour l'instant, avec 1671 règles, 92, 6% du corpus principal (soit  11447 phrases) et 87, 3% du corpus annexe (404 phrases) en arbres de dérivation d'une grammaire AB. On peut résumer l'utilisation des règles, dans le cadre de la transduction du corpus principal, dans le tableau 8. On remarque que, bien qu'il y ait de nombreuses règles qui sont utilisées peu de fois, elles ont un poids faible sur la totalité des transductions effectuées. Les règles les plus importantes sont exprimées dans le tableau 9, sous forme parenthésée telle qu'utilisée dans la syntaxe de Tregex (Levy et Andrew, 2006). La dernière règle, gérant la ponctuation finale, n'est pas utilisée autant de fois qu'il y a d'arbres de dérivation. Cela vient du fait que nous avons souhaité traiter différemment les phrases comprenant uniquement un groupe nominal et que certaines phrases, tels les titres d'articles, n'ont pas de ponctuation finale. De même, la règle qui s'occupe du déterminant au début d'un nom commun devrait être employée plus que ça, vu le nombre de groupes nominaux du corpus. Cependant, une règle prioritaire s'occupe du cas où le groupe nominal est composé d'un déterminant et d'un nom commun et est appelée 8892 fois.  T  8 - Récapitulatif de l'utilisation des règles.  T  9 - Quelques règles du transducteur, dont les quatre règles les plus utilisées. Les arbres de dérivation des deux corpus nous permettent d'extraire deux grammaires, sur lesquelles les tests d'analyse que nous avons effectués seront détaillés dans la partie suivante 6.2. En addition des grammaires, nous pouvons créer un lexique, contenant les mots et les différents types qui leur sont associés en fonction des transductions. Le lexique correspondant au corpus principal contient 26765 mots sur les 27589 présents, il couvre donc 96, 9% du vocabulaire présent dans le corpus de Paris VII.  Nous avons effectué de nombreux tests avec notre analyseur de phrases. En effet, nous avons  utilisé les deux grammaires différentes et nous avions à disposition des phrases typées par le transducteur ou par le Supertagger, avec  = 0.01.  Grâce au Supertagger, nous avons pu analyser aussi bien les phrases venant du transducteur que  les phrases laissées de côté. Les résultats sont regroupés dans la table 10. On remarque que les résultats sont proportionnellement moins bons, mais que certaines phrases venant de la partie non traitée des différents corpus sont analysées et transformées en arbre de dérivation.  T  10 - Tableau de résultat.  Dans cet article, nous avons rapidement rappelé le principe du G-transducteur dont nous nous  servons pour transformer les arbres syntaxiques du corpus de Paris VII en arbres de dérivation d'une grammaire AB, puis expliqué la méthode que nous employons pour extraire une PCFG de ces arbres. Les résultats expérimentaux d'analyse de phrase via l'algorithme CYK, en utilisant notre PCFG et des phrases typées au préalable, nous permettent de comparer les annotations produites par le transducteur et la méthode semi-automatique mise en place par Moot.  Cependant, ce travail est loin d'être terminé et nous avons encore plusieurs perspectives à étudier.  Bien sûr, nous souhaitons améliorer la couverture du transducteur par rapport au corpus et dépasser les 95% de phrases analysées, bien qu'il ne reste plus que des cas complexes à traiter. Etant donné que les grammaires AB peuvent sembler limitatives lorsque l'on souhaite traiter d'une langue complexe, nous souhaiterions transformer notre transducteur en un transducteur d'arbres vers les graphes. Cela nous permettrait d'utiliser l'ensemble des règles de Lambek et de nous rapprocher de travaux plus modernes sur la question. Par rapport à l'analyseur de phrase, il manque cruellement d'un typage relatif au lexique que nous extrayons des arbres de dérivation. Cette méthode de typage devrait être implémentée rapidement. De même, il pourrait être intéressant d'utiliser d'autres algorithmes que CYK, tel que l'algorithme d'Earley, ou de typer les phrases en utilisant un système tel que SYGFRAN (Chauché, 2011). Notre travail est disponible à (Sandillon-Rezer, 2012), sous licence GNU General Public Licence.  
