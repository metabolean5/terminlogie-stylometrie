On oppose souvent en TAL les systèmes qui exploitent des connaissances linguistiques et ceux  qui reposent sur des indices de surface. Les premiers systèmes ne sont pas toujours fiables parce qu'ils exploitent des connaissances complexes qui peuvent être erronées lorsqu'elles sont calculées automatiquement ou incomplètes lorsqu'elles sont produites manuellement. Les seconds systèmes s'appuient généralement sur des méthodes d'apprentissage automatique et sur des indices de surface qui sont plus faciles à obtenir mais qui ne permettent de traiter que les cas simples ou les plus courants de la tâche dévolue au système.  Dans cet article nous proposons une nouvelle approche qui permet de dépasser cette opposition  entre systèmes «pauvres» et système «riches» en connaissances. Cette approche repose sur le formalisme des réseaux bayésiens. Ce formalisme est encore peu exploité en TAL mais il repose sur un modèle probabiliste conçu pour raisonner sur des informations incertaines, partielles et manquantes.  Nous validons notre approche sur la tâche de la résolution automatique des anaphores où, en  raison de la complexité et du nombre de connaissances nécessaires, l'opposition des systèmes à base de connaissances linguistiques et d'indices de surface est très marquée. Après avoir validé l'approche en développant un premier classifieur bayésien qui permet de distinguer pronoms impersonnels et pronoms anaphoriques, nous analysons les performances d'un second classifieur qui trouve l'antécédent des pronoms anaphoriques. La section suivante revient sur les raisons de l'opposition précédente dans le cadre de la résolution des anaphores pronominales. La section 3 décrit le modèle des réseaux bayésiens et son intérêt pour le TAL. Dans la section 4 nous validons notre approche en comparant les performances de différents systèmes pour la distinction des pronoms impersonnels et anaphoriques. Enfin, la dernière section présente un classifieur pour la tâche complète de la résolution des anaphores et compare ses résultats par rapport à l'état de l'art.  L'anaphore est une relation linguistique entre deux entités textuelles définie lorsqu'une entité  textuelle (l'anaphore) renvoie à une autre entité du texte (l'antécédent). Comme la présence d'anaphores dégrade considérablement les performances des systèmes de TAL, la question de leur résolution est étudiée depuis longtemps. Ce travail se limite à la résolution de l'anaphore du pronom it dans les textes anglais, l'anaphore la mieux connue et la plus facile à résoudre.  L'approche classique pour sa résolution automatique distingue trois étapes : la distinction des  pronoms anaphoriques et impersonnels (it is known that... vs it produced...), la sélection des candidats possibles à l'antécédence et le choix de l'antécédent. Pour chaque étape, les premiers systèmes proposés dans la littérature exploitaient des connaissances linguistiques complexes traduisant les contraintes syntaxiques et sémantiques qui régissent l'anaphore. Comme le calcul automatique de ces connaissances était considéré comme impossible ou trop peu fiable pour être utilisable, ces connaissances linguistiques étaient produites manuellement, ce qui présupposait un important travail d'analyse préalable des textes.  Durant les années 1990, devant le besoin de systèmes de résolution robustes et peu coûteux à  mettre en place, un nombre important de systèmes à bases d'indices de surface ont été proposés (Mitkov, 2002). Ces systèmes abandonnent les connaissances linguistiques complexes des premiers systèmes. Ils approchent les connaissances nécessaires par des indices plus simples à calculer et que l'on suppose plus fiables. Pour la distinction des pronoms anaphoriques, (Husk & Paice, 1987) a ainsi proposé un ensemble d'automates encodant des connaissances linguistiques et permettant de reconnaître les séquences contenant des pronoms impersonnels. Jugeant que ces automates avaient une couverture trop faible, (Evans, 2001) propose une voie alternative reposant sur l'apprentissage automatique des indices de surface pour reconnaître les séquences caractéristiques. Pour le choix de l'antécédent, les connaissances syntaxico-sémantiques sont approchées de la même manière par des méthodes robustes. On sait que les schémas prédicat-argument améliorent les résultats du filtrage (Ponzetto & Strube, 2006), mais comme ces ressources ne sont pas toujours disponibles,  on a cherché à les approcher par un calcul fréquentiel : les régularités des coocurrences entre  les sujets, les compléments et les verbes dessinent les contours des classes sémantiques. Les auteurs de (Dagan & Itai, 1990) montrent que les contraintes obtenues peuvent partiellement remplacer les connaissances sémantiques. Si les indices approchés proposés lors des années 1990 ont permis l'implémentation de systèmes robustes (Mitkov, 2002), leur apport et leurs limites étaient mal connus. Des travaux récents commencent à en mesurer les limites. L'étude de (Kehler et al., 2001) montre ainsi que les fréquences de (Dagan & Itai, 1990) n'améliorent pas les performances d'un système qui exploite déjà des informations morpho-syntaxiques. Les auteurs en concluent que l'apport des fréquences tient davantage du hasard que d'une véritable capture du sens sémantique. Les limites rencontrées par les systèmes à base d'indices de surface nous renvoient au problème initial. Nous avons besoin de connaissances sémantiques et syntaxiques complexes pour la résolution de l'anaphore pronominale. Ces connaissances linguistiques, lorsqu'elles sont disponibles, ne sont pas fiables. On peut chercher à les remplacer par des indices de surface dont le calcul est toujours réalisable et plus fiable mais ces indices peuvent ne pas exprimer, ou seulement de manière imprécise, les connaissances nécessaires à la résolution, ce qui produit des erreurs. Nous proposons une modélisation reposant sur les Réseaux Bayésiens (RB), conçu pour raisonner sur des données incertaines et incomplètes. Cette approche probabiliste offre la possibilité d'unifier dans une unique représentation connaissances linguistiques et indices de surface. Cette unification permet de corroborer les connaissances linguistiques grâce aux indices de surface qui sont observés en corpus. A l'inverse, l'exploitation de connaissances linguistiques permet de corriger certaines des erreurs des systèmes à base d'indices de surface.  La distinction des pronoms impersonnels comme le choix de l'antécédent sont des tâches qui,  comme de nombreuses tâches du TAL, se reformulent facilement en problèmes de classification.  Considérons par exemple la classification des pronoms impersonnels et anaphoriques : soit Cor-  pus un ensemble de textes d'un même domaine, Corpus_entraînement et Corpus_test deux sous-ensembles stricts disjoints de Corpus, C et C les classes des occurrences des pronoms impersonnels et anaphoriques présents dans Corpus. e est une occurrence d'un pronom présent dans Corpus décrit par un vecteur a = v , ...v d'attributs à valeurs dans R. Pour les occurrences de Corpus_entraînement, les valeurs des attributs v sont obtenues à partir d'une analyse humaine du corpus : elles représentent selon les cas des connaissances linguistiques ou des indices de surface. Le théorème de Bayes dit comment prédire la meilleure classe d'appartenance pour une occurrence d'un pronom inconnu de Corpus_test sur la base d'observations faites sur les occurrences  de Corpus_entrainement. La classe sélectionnée doit maximiser la probabilité   P  (C |E) =  où C  {C , C }, E une occurrence du corpus de test et P (C |E) la probabilité conditionnelle que E appartienne à la classe C sachant la valeur des attributs de E, une probabilité estimée à partir des données d'entraînement. Si nous imposons la contrainte d'indépendance des attributs, le classifieur est un «classifieur bayésien naïf». Les attributs étant indépendants, la probabilité P (E|C ) se décompose en P (v |C )  ...  P (v |C ) et la probabilité à maximiser se reformule en  P  (C |E) =  P (v |C )  Pour tout E de Corpus_test, un classifieur bayésien attribue la classe C  à l'exemple E si P(Pronom=Impersonnel|E)P(Pronom=Anaphorique|E) et la classe C sinon.  3.1.1  Le choix des attributs pour la classification  L'un des premiers systèmes distinguant les pronoms it impersonnels et anaphoriques (Husk &  Paice, 1987) s'appuie sur un ensemble de règles de logique du 1 ordre pour reconnaître les séquences qui contiennent une occurrence du pronom impersonnel. Les séquences qui introduisent les it impersonnels partagent une forme remarquable : elles commencent par un it et se terminent par un délimiteur comme to, that, whether.... Les règles varient selon le délimiteur. Les tests réalisés par Paice montrent que ces règles réalisent un bon score avec 91,4%Acc sur un corpus technique. Cependant les performances sont dégradées si on applique les règles à des corpus de nature différente. Le nombre de faux positifs (FP) augmente : certains attributs sont discriminants sur les corpus techniques mais ne le sont plus sur des corpus de nature différente.  Afin d'éviter cet écueil, (Lappin & Leass, 1994) décrit entièrement les séquences au moyen  d'automates à états finis de la forme It is not/may be<Modaladj> ; It is <Cogv-ed> that < Subject> où <Modaladj> et <Cogv> dénotent des classes d'adjectifs modaux et de verbes cognitifs connus pour introduire des it impersonnels (par exemple necessary, possible et recom- mend, think). Ce système a une bonne précision (il produit peu de FP), mais il a un mauvais rappel (il produit beaucoup de FN) : seules les séquences exactes sont reconnues et il est toujours difficile d'obtenir des classes d'adjectifs et de verbes exhaustives.  (Evans, 2001) renonce à exploiter des connaissances linguistiques aussi complexes et se concentre  sur des attributs plus fiables, les indices de surface. Evans considère 35 indices syntaxiques et contextuels (ex. la position du pronom dans la phrase, le lemme du verbe suivant...). Un système d'apprentissage, utilisant la méthode des K plus proches voisins, détermine le poids des attributs discriminants pour le domaine du corpus et classe les occurrences inconnues. Les premiers essais réalisent un score de 71,31%Acc satisfaisant sur un corpus de langue générale. (Litran et al., 2004) reproduit un essai identique avec une Machine à Support de Vecteur (SVM) sur un corpus de génomique et obtient un score de 92,71%Acc.  3.1.2  L'inférence sur des attributs imparfaits  Le RB est un modèle conçu pour raisonner sur des attributs incertains et incomplets. Il est  composé d'une description qualitative de leurs dépendances, un graphe orienté sans circuits, et d'une description quantitative, un ensemble de probabilités conditionnelles où chaque Variable Aléatoire (VA) est associée à un noeud du graphe. Une 1 étape de paramétrage permet de représenter les connaissances a priori pour chaque VA sous la forme d'une table de probabilités conditionnelles. L'étape suivante, l'étape d'inférence, consiste à réviser certaines probabilités a priori pour obtenir des probabilités a posteriori et à modifier en conséquence les valeurs des VA correspondantes à partir d'observations faites en corpus. Ces nouvelles informations sont propagées au travers du réseau et permettent de réviser les valeurs a priori même pour les variables non-observées.  Expliquons sur un exemple très simplifié le mécanisme d'inférence du réseau de la figure 1,  un réseau destiné à la classification des pronoms it. La 1 étape de paramétrage du réseau, permet de calculer les valeurs a priori des probabilités. Sur l'analyse des fréquences d'un corpus d'entraînement ou à partir de l'estimation d'un expert, nous établissons a priori qu'environ un tiers des pronoms it du corpus sont impersonnels, P(Pronoun=Impersonal)=0,3. Un lien d'influence relie les variables Pronom et Lappin_Rules, indiquant qu'un it a d'autant plus de chance d'être reconnu par une règle de (Lappin & Leass, 1994) qu'il est impersonnel. De même, les liens entre les variables Pronoun et Paice_Rules d'une part, Pronoun et Start_Sentence d'autre part indiquent respectivement qu'un it a d'autant plus de chance d'être reconnu par une règle de (Husk & Paice, 1987) et d'être en début de phrase qu'il est impersonnel. L'arc (Start_Sentence,Paice_Rules) unit les deux variables, car, toujours au regard du corpus d'entraînement ou de l'estimation de l'expert, elles ne sont pas indépendantes. La fiabilité de la règle de (Husk & Paice, 1987) reconnaissant une séquence est augmentée si la séquence est située en début de phrase. Cette influence est mesurée par la table de probabilités conditionnelles associée au noeud Paice_Rules de la figure 1.  Une fois l'ensemble des probabilités conditionnelles déterminé, l'étape d'inférence débute.   Considérons par exemple la phrase It is well documented that treatment of serum-grown....  Nous appliquons les règles de (Lappin & Leass, 1994) et les règles de (Husk & Paice, 1987) sur cette séquence. Aucune règle de (Lappin & Leass, 1994) ne reconnaît la séquence, nous posons P(Lappin_Rules = No_Match)=1. Une règle de (Husk & Paice, 1987) la reconnaît, nous posons P(Paice_Rules = Match)=1 et comme la séquence se situe en début de phrase nous posons aussi P(Start_Sentence = Start)=1. En représentant graphiquement l'indépendance conditionnelle des VA, le RB permet de compacter la loi jointe globale. A l'aide des probabilités conditionnelles fournies en paramètres nous pouvons inférer la probabilité qui nous intéresse : P(Pronoun=Impersonal|Lappin_Rules=No_Match, Start_Sentence=Start, Paice_Rules=Match)  Du fait qu'une règle de (Husk & Paice, 1987) a reconnu la séquence et que l'occurrence se  trouve en début de phrase, le réseau infère une probabilité de 38,9% pour l'occurrence d'être impersonnelle. Nous pouvons modifier cette conclusion en ajoutant d'autres variables au réseau ou en raisonnant avec des observations incertaines ou manquantes. On peut par exemple indiquer que la fiabilité de l'observation est inférieure à 100% et poser P(Lappin_Rules=No_Match)=0,9 pour tenir compte de l'incomplétude des règles de (Lappin & Leass, 1994). re L'objectif de cette première expérience est de valider notre modèle (on trouvera dans (Weissenbacher & Nazarenko, 2007) une description précise du système développé et une analyse plus complète des résultats obtenus). Nous avons mesuré les performances du Classifieur Bayésien (CB) de la figure 2 , ainsi que celles du classifieur bayésien naïf (CBN) associé , puis nous les avons comparées avec celles des systèmes de l'état de l'art.  Méthode  Résultats Règles De (Lappin & Leass, 1994) 88,11% 12,8 169,1 Règles De (Husk & Paice, 1987) 88,88% 123,6 24,2 Machine à Vecteurs de Support 92,71% Classifieur Bayésien naïf 92,58% 74,1 19,5 Classifieur Bayésien 95,91% 21,0 38,2  Nous avons travaillé sur un corpus de résumé d'articles de génomique construit à partir de  la base Medline interrogée avec les mots clés bacillus subtilis, transcription factors, Human, blood cells, gene and fusion. Nous en avons extrait 11 966 résumés (environ 5 millions de mots) où nous avons identifié 3347 occurrences du pronom it. Deux annotateurs humains ont classé chaque occurrence du pronom soit comme anaphorique soit comme impersonnelle. L'accord des annotateurs fut entier après discussion.  Notre corpus étant de taille moyenne, nous avons procédé à une validation croisée pour valider  nos résultats. Nous sélectionnons aléatoirement 2/3 du corpus pour calculer les probabilités conditionnelles a priori. Nous appliquons ensuite notre CB, ainsi que le CBN, paramétrés grâce à ces probabilités sur le tiers restant. Nous réitérons 20 fois ces opérations pour obtenir une moyenne des performances de chaque système sur le corpus.  Le tableau 1 résume les moyennes des résultats (en exactitude) obtenus par les systèmes de  l'état de l'art décrits plus haut et celles des deux classifieurs. Ces résultats montrent que le CB produit une meilleure classification que les autres systèmes, notamment les systèmes à base de règles. Ces résultats valident notre modèle : le CB exploite tous les attributs pertinents et corrige le bruit d'un attribut par la fiabilité des autres. Privé des relations de dépendance entre les attributs, le CBN ne bénéficie pas du mécanisme de correction et surestime leurs fiabilités. Les systèmes à base de règles sont quant à eux entièrement assujettis à la fiabilité des attributs. Les résultats confirment les craintes soulevées dans la section 3.1.1 : on obtient un faible rappel pour les règles de (Lappin & Leass, 1994) et une mauvaise précision pour celles de (Husk & Paice, 1987). nde  Assurés des bonnes performances de notre modèle sur la distinction des pronoms impersonnels,  nous proposons un classifieur bayésien pour la résolution d'anaphore.  Nous avons utilisé le système MARS (Mitkov, 2002) comme système de référence pour notre  évaluation. Ce système repose sur des indices de surface pour trouver l'élément le plus saillant dans le discours qui précède une occurrence donnée de pronom. Cet élément est celui qui a la plus forte probabilité d'être l'antécédent du pronom. Nous avons ré-implémenté le système en utilisant le même prétraitement des textes que dans notre système bayésien de manière à comparer uniquement les algorithmes des deux systèmes (choix des attributs et mécanisme de prise de décision).  Pour réaliser notre classifieur bayésien (voir figure 3  ), nous avons conservé tous les indices approchés de MARS (noeuds coloriés en noir sur la figure) mais nous avons ajouté une série d'autres indices (en gris sur la figure) qui sont également pertinents pour le calcul de la saillance et qui sont proposés par plusieurs travaux de l'état de l'art. De notre point de vue, il est en effet utile d'avoir à la fois les indices et les connaissances linguistiques qu'ils approchent. Par exemple, le sujet d'une phrase est souvent l'élément saillant mais comme le calcul du rôle grammatical peut être erroné, il est intéressant d'exploiter en parallèle l'information concernant un indice de surface (First_NP : le premier GN de la phrase est très souvent le sujet du verbe) qui peut confirmer ou infirmer l'hypothèse du rôle grammatical.  En suivant un protocole expérimental identique à celui de la section précédente sur le même  corpus, nous avons réalisé la résolution avec 4 systèmes différents. Trois systèmes servent de comparaison : le système Aléatoire qui choisit un antécédent au hasard dans la liste des candidats, le système Premier GN qui sélectionne toujours le premier GN de la phrase précédant le pronom comme antécédent et le système MARS. Le dernier système est le classifieur bayésien (CB) que nous cherchons à évaluer.  Pour les trois derniers systèmes, nous donnons deux mesures différentes des performances, un  taux de succès strict et partiel . Le taux de succès est strict lorsque l'antécedent exact a été  annoté par le système et partiel lorsque seule une partie de l'antécédent à été annotée. En raison  des erreurs de l'analyse syntaxique en constituants sur laquelle la liste des candidats est calculée, certains GN candidats ne sont identifiés que partiellement ou font défaut. Les performances de nos systèmes ne peuvent atteindre 100%, la dernière colonne donne les scores maximum possibles pour la résolution.  System  Results Strict Partial Aléatoire 6% Premier GN 36.3% 51% MARS 26.7% 43% Classifieur Bayésien 44.0% 61% MAX 93.3% 97.8%  Une analyse détaillée des erreurs du CB montre les limites de notre analyse de la saillance.  47% des erreurs sont dues à un calcul erroné de l'élément saillant : le système ne retrouve pas ce que l'annotateur humain juge «intuitivement» être l'élément saillant parce qu'un nombre plus important d'indices favorisent un candidat différent de l'élément saillant auquel le classifieur associe la plus grande probabilité d'antécédence. Dans 21% des cas, le systèmes trouve bien l'élément qui paraît saillant à l'annotateur humain mais cet élément n'est pas l'antécédent, ce qui met en cause soit notre définition de la saillance soit son rôle dans la résolution de l'anaphore. Dans l'exemple suivant [Amino acid sequence analysis] of [the 33-kDa protein] revealed that it is a sigma factor, sigma E. l'élément le plus saillant est le candidat 1 et il est choisi comme antécédent par le système, une décision qui viole les connaissances du domaine, un facteur sigma est une protéine, des connaissances qu'il faut prendre en compte pour choisir le candidat 2 comme antécédent. Les erreurs restantes proviennent des imperfections des prétraitements linguistiques : principalement des erreurs de segmentation en phrase et de l'analyse syntaxique incorrecte qui ne permet pas de repérer tout les GN candidats. Les réseaux bayésiens présentent un véritable intérêt pour les nombreuses tâches de classification du TAL. Ce modèle permet de dépasser l'opposition historique des systèmes à base de connaissances linguistiques et d'indices de surface. De fait, cette opposition apparaît infondée :  les connaissances linguistiques sont nécessaires mais souvent indisponibles et peu fiables ; les  indices de surface sont généralement calculables et de bonne qualité mais il reste des problèmes d'ambiguïté. En unifiant ce deux types de connaissances au sein d'une unique représentation, le modèle offre un mécanisme de raisonnement dont nous nous servons pour corriger et suppléer les connaissances linguistiques en les complétant des indices de surface. Tout l'enjeu consiste selon nous à raisonner sur l'ensemble des connaissances et indices disponibles à un moment donné mais en tenant compte de leur relative fiabilité dans le processus de décision. Nous avons ensuite validé notre modèle sur le problème de la résolution des anaphores en proposant deux classifieurs, le premier pour distinguer les pronoms impersonnels et anaphoriques, le second pour le choix de l'antécédent. Les résultats de nos classifieurs sont supérieurs à ceux des systèmes de l'état de l'art.  Actuellement seule une expertise linguistique rend compte de la structure des deux classifeurs  que nous avons présentés. Nous envisageons de tester les mécanismes permettant d'apprendre la structure même du réseau. Comparer notre structure avec une structure apprise automatiquement devrait permettre de vérifier et d'enrichir la structure du CB actuelle.  
