Dans le domaine biomédical, les problématiques d'accès à l'information sont particulièrement  importants. De nombreux documents sont en effet quotidiennement collectés dans des bases  spécialisées très consultées. La base PubMed regroupe par exemple 16 millions de publications  médicales et fait face à plus de 3 millions de requêtes par jour. Dans la plupart de ces bases, les documents sont indexés à l'aide de terminologies de référence en anglais ; la mise en place de stratégies multilingues pour faciliter l'accès à ces bases pour les non-anglophones est donc cruciale. Quelques terminologies biomédicales multilingues existent, mais elles sont mises en défaut par l'évolution rapide des connaissances et le manque de moyens pour certaines langues. En réponse à ces besoins, nous présentons et évaluons dans cet article une méthode de traduction automatique de termes biomédicaux fonctionnant sur différentes langues (anglais, espagnol, français, russe...). Cette méthode permet de produire des traductions de termes simples (i.e. composés d'un seul mot) du domaine biomédical d'une langue source dans une langue cible. Ce travail repose sur deux hypothèses majeures : 1- dans le domaine biomédical, les termes équivalents entre deux langues sont souvent morphologiquement proches ; 2- les différences entre termes de chaque langue sont régulières et peuvent être apprises automatiquement. Ces deux hypothèses s'appuient sur le fait que les termes biomédicaux sont construits sur les mêmes racines grecques et latines (Namer, 2005), et leurs dérivations très régulières (e.g. pour le couple français-anglais / , / , / ). Notre approche s'appuie sur une technique d'apprentissage artificiel simple que nous avons développée. Elle nous permet d'inférer un ensemble de règles de réécriture à partir de couples de termes langue source-langue cible traductions l'un de l'autre. Ces règles, une fois apprises, peuvent alors être appliquées à des termes de la langue source pour produire les termes équivalents dans la langue cible. Il est intéressant de noter qu'aucune connaissance, ni intervention humaine n'est requise à l'exception de la phase de supervision (i.e. la constitution de l'ensemble de couples de termes langue source-langue cible), celle-ci pouvant se faire simplement en exploitant les terminologies multilingues existantes.  Dans la section suivante, nous présentons les travaux connexes à notre problématique. Nous  décrivons ensuite en section 3 notre technique de traduction de termes biomédicaux que nous évaluons sur différentes paires de langues en section 4.  Peu de travaux se placent dans le cadre de la traduction directe de termes, et moins encore dans  le domaine biomédical. Cette problématique a cependant déjà été abordée et une solution fonctionnelle a été proposée par Claveau & Zweigenbaum (2005b; 2005a). Celle-ci repose sur une technique d'apprentissage de transducteurs mais ne peut s'appliquer qu'aux langues partageant le même alphabet, contrairement à l'approche présentée ici. Outre sa plus grande souplesse, nous montrons en section 4 que notre technique obtient, de plus, des performances supérieures à cette approche par transducteurs. Schulz et al. (2004) ont également proposé une technique de traduction de termes biomédicaux, du portugais vers l'espagnol, s'appuyant sur des règles de réécriture. Cependant, ces règles sont fournies manuellement ; une telle approche n'est donc pas envisageable à grande échelle pour le traitement de plusieurs paires de langues. Hors du domaine biomédical, des problématiques proches sont parfois abordées dans le domaine de la traduction automatique de textes. Ainsi, la détection de cognats (couples de mots bilingues de formes proches) (Fluhr et al., 2000, inter alia) s'appuie sur des opérations morphologiques simples parfois proches des règles de réécriture que nous inférons. D'autres travaux reposent quant à eux sur des recherches en corpus à l'aide de techniques statistiques de cooccurrences pour trouver des alignements - et donc des relations de traduction potentielle - entre termes dans des corpus alignés (Ahrenberg et al., 2000; Gale & Church, 1991) ou comparables (Fung & McKeown, 1997). Outre le problème de la rareté de corpus spécialisés alignés, ces approches diffèrent de la nôtre en cela qu'il s'agit pour ces auteurs de retrouver une traduction d'un mot dans un texte (mise en relation), alors que nous nous posons dans le cadre plus strict de la traduction (génération). Mentionnons enfin les travaux sur la translittération, notamment du katakana ou de l'arabe (Tsuji et al., 2002; Knight & Graehl, 1998, par exemple). Les techniques utilisées dans ceux-ci sont parfois proches de celle proposée ici, mais ne concernent que la représentation d'imports dans des langues ayant un alphabet différent de la langue source.  La technique de traduction de termes biomédicaux que nous proposons fonctionne en deux  temps. Tout d'abord, des règles de réécriture sont inférées à partir d'exemples de paires de termes traductions l'un de l'autre (sous-section 3.1). Un modèle de langue est ensuite appris et utilisé pour choisir la traduction la plus probable parmi les possibilités générées par l'application des règles de réécriture inférées (sous-section 3.2). Nous terminons la section par quelques commentaires sur cette technique de traduction de termes.  La technique de traduction proposée repose sur l'apprentissage de règles de réécriture (que l'on  peut aussi voir comme des règles de translittération). Ces règles, apprises à partir de listes de paires bilingues de termes du domaine (cf. section 4.1), sont de la forme : input string  output string . Dans la suite de l'article, nous notons r une règle de réécriture, R est la liste de toutes les règles inférées pendant une expérience, input(r) et output(r) désignent respectivement la chaîne d'entrée et la chaîne de sortie de la règle r.  Algorithme 1 Apprentissage des règles de réécriture  aligner les paires de termes au niveau des lettres, mettre le résultat dans L for all paire de termes W1 dans L do for all alignement de lettres dont les 2 lettres diffèrent dans W1 do trouver la meilleure hypothèse de règles r dans l'espace de recherche E ajouter r à l'ensemble de règles R end for end for  L'algorithme 1 donne un aperçu global de notre technique d'apprentissage. La première étape  est réalisée à l'aide de DPalign (http://www.cnts.ua.ac.be/~decadt/?section= dpalign). Ce logiciel aligne deux séquences en minimisant leur distance d'édition par programmation dynamique selon l'algorithme de Wagner & Fischer (1974) ; les coûts de substitution des caractères sont calculés sur l'ensemble des paires à aligner. Ce logiciel ne repose donc pas sur une similarité formelle des caractères pour aligner les séquences ; il nous est ainsi possible d'aligner des termes ne partageant pas le même alphabet.  Une liste de paires de termes est donnée en entrée ; à chaque terme sont ajoutés deux caractères  pour représenter le début et la fin de la chaîne de caractères. La liste de sortie L va alors contenir les paires de termes alignés au niveau des lettres ; le tableau 1 en présente quelques exemples (' ' signifie aucun caractère). Par la suite, le terme d'entrée (respectivement de sortie) d'une telle paire alignée p est noté input(p) (resp. output(p)) ; de plus, align(x, y) indique que la sous-chaîne x est alignée avec la sous-chaîne y dans la paire de termes considérée.  Dans notre processus d'apprentissage, ces paires de mots alignés sont considérées comme des  exemples à partir desquels les deux boucles imbriquées infèrent des règles de réécriture. Comme pour beaucoup de problèmes d'apprentissage artificiel symbolique, cette phase d'inférence (ligne 4) peut être considérée comme un problème de parcours d'espace. À chaque élément de cet espace est associé un score ; on cherche à trouver l'élément de l'espace maximisant ce score. Dans notre cas, l'espace de recherche est composé de toutes les règles de réécriture possibles compatibles avec l'exemple choisi. Par exemple, considérons que la paire de mots W1 choisie à la ligne 2 est , et supposons que c'est l'alignement qui est choisi à la ligne 3. Quelques règles de réécriture compatibles dans ce contexte sont  ,  ,  (on ne note pas le caractère dans les règles),  ...  Le score d'une règle est calculé à partir de la liste L ; c'est le ratio entre le nombre de fois où la  règle s'applique aux termes alignés de la liste d'exemples et le nombre de fois où la prémisse de la règle apparaît dans les termes source de la liste d'exemples. Formellement, le score d'une règle r est donc défini par ( représente l'inclusion de chaîne de caractères) :  score  (r) = |{p  L | input(r)  input(p)  output(r)  align(input(r), p)}| |{s  L | input(r)  s}|  Du fait du très grand nombre de règles possibles, chercher la règle maximisant la fonction de  score pour chacun des exemples peut être une tâche très lourde en temps de calcul. Heureusement, l'espace de recherche peut être organisé hiérarchiquement pour rendre l'exploration plus efficace. En effet, les règles compatibles pour un exemple peuvent être organisées de la plus générale à la plus spécifique avec la notion de subsomption suivante :  r  r  (input(r )  input(r )  output(r )  output(r )).  Cette relation de subsomption est réflexive, antisymétrique et transitive ; l'espace résultant est  un treillis. La figure 1 présente l'espace de recherche organisé par cette subsomption construit à partir de l'exemple dans . Dans notre cas, la recherche est effectuée du plus général au plus spécifique (top-down) ; cela, et les propriétés d'héritage que cette structure implique, nous permet de rechercher efficacement la meilleure règle (calcul du score d'une règle en n'examinant que les paires de termes que son père couvre, élagage de l'espace basé sur le meilleur score courant...).  P  (w) = P (l |l , ..., l ) pour un terme w composé des lettres l , l , ..., l  En pratique, les probabilités P (l  |...) sont estimées à partir des termes biomédicaux de la langue cible, décomposés en n-grammes de lettres, issus de la liste d'exemples. Pour prévenir le problème des séquences de lettres non vues, les probabilités sont en réalité calculées à partir d'un historique réduit aux n  1 lettres précédentes (i.e. P (l |l , ..., l )) et un lissage simple est appliqué. Dans les expériences présentées ci-après, n est fixé à 7 lettres.  Intuitivement, le ML va favoriser les traductions qui ressemblent à des termes biomédicaux bien  formés dans la langue cible. Parmi toutes les traductions proposées pour un terme de la langue source, on conserve donc finalement celle qui obtient la probabilité la plus forte selon le ML appris. Par ailleurs, il est intéressant de noter qu'en plus de choisir la traduction la plus probable, cette technique nous donne un facteur de confiance sur la traduction retenue.  Deux points concernant la technique de traduction proposée méritent d'être mentionnés. Il est  tout d'abord intéressant de constater que l'approche que nous avons adoptée peut être rapprochée du cadre usuel de la traduction artificielle statistique dans lequel le but est de traduire une séquence de mots f dans une langue source en une séquence e dans la langue cible en cherchant e maximisant P (e) · P (f |e) (Brown et al., 1993). Le terme P (f |e) représente la probabilité que la séquence f soit la traduction de e. Ces probabilités, qui sont estimées à partir d'un corpus aligné, peuvent être rapprochées de nos règles de réécriture et leur score. Le terme P (e) sert à vérifier que la séquence proposée soit bien formée ; son fonctionnement est en tout point similaire au modèle de langue que nous utilisons, si ce n'est que nos séquences sont composées de lettres et non de mots. Il y a cependant quelques différences importantes avec notre approche, principalement induites par la nature de nos données. Ainsi, dans le cadre de la traduction artificielle de textes, les différences d'ordonnancement des mots entre la langue source et la langue cible sont des problèmes difficiles à résoudre et mènent à construire des modèles de traduction compliqués. Dans notre cas, ce problème est quasiment inexistant : l'ordre des morphes, et donc des lettres composant les termes, varie peu d'une langue à l'autre. Le fait de manipuler des lettres et non des mots nous permet aussi d'utiliser un ML avec un historique de taille importante sans craindre de tomber trop souvent sur des séquences non observées ; les combinaisons possibles de lettres sont en effet bien moins nombreuses que les combinaisons de mots.  Le deuxième point à noter concerne une des limites évoquées par Claveau & Zweigenbaum  (2005b) à propos de leur technique de traduction de termes. Ces derniers indiquent en effet que leur approche par transducteur ne peut pas prendre en compte des informations sur les termes comme les parties-du-discours (PoS). Cela a pour effet de générer des erreurs et de complexifier l'apprentissage dans le cas de mots polyfonctionnels comme qui se traduira différemment selon qu'il soit nom ou adjectif. Dans notre cas, cette limite est levée puisque l'ajout de ces informations se fait très naturellement avec le modèle de langues. Les probabilités peuvent en effet être calculées en incluant la partie-du-discours de la séquence en cours de traitement (on calcule alors les scores en fonction des P (l |l , ..., l , P oS )).  Deux jeux de données sont utilisés pour nos expériences de traduction. Le premier est une  collection de termes français-anglais issue du dictionnaire médical Masson ( ). C'est la même collection que celle utilisée dans Claveau & Zweigenbaum (2005b), ce qui nous permettra de comparer les résultats. Seules les paires composées de termes simples dans la langue source et dans la langue cible, hors acronymes, sont conservées. La liste bilingue ainsi constituée contient environ 12 000 paires de termes.  Le second jeu de termes multilingues est le Métathésaurus de l'UMLS (Bodenreider, 2004).  Cette collection de thésaurus rassemble des termes biomédicaux dans 17 langues et associe à chacun des termes un identifiant de concept indépendant des langues, le Concept Unique identifier, CUI. Ces CUI nous permettent donc de constituer des ensembles de paires de termes bilingues. Là encore, seuls les termes simples non acronymes sont conservés.  Pour l'évaluation de notre technique, nous suivons une approche standard : la liste initiale de  paires de termes est découpée en deux ensembles, le premier sert pour l'apprentissage (inférence de règles et modèle de langue), et le second, composé de 1 000 paires, sert de jeu de test. Une fois les règles et le modèle de langue appris sur le jeu d'entraînement, nous l'appliquons à chaque terme d'entrée du jeu de test. Nous comparons alors la traduction proposée avec celle attendue. Si les deux chaînes de caractères sont identiques, la traduction est considérée correcte ; dans tous les autres cas, elle est considérée incorrecte.  Les résultats sont évalués en terme de précision (pourcentage de traductions correctes générées).  Cependant, puisque le modèle de langue nous fournit un indice de confiance, on peut décider de ne conserver que les traductions dont l'indice est supérieur à un certain seuil. Un seuil élevé doit favoriser la précision au détriment du nombre de traductions proposées, et vice-versa. À la manière de courbes rappel-précision, nous représentons donc ci-après la précision suivant le pourcentage de mots traduits pour tous les seuils possibles d'indice de confiance.  4.3.1  Traduction entre le français et l'anglais Pour cette première expérience, nous nous intéressons à la traduction entre le français et l'anglais. Comme précisé précédemment, nous utilisons le jeu de données Masson qui nous permet de comparer directement nos résultats à ceux de Claveau & Zweigenbaum (2005b; 2005a) dont nous reportons les résutats ci-après. Nous utilisons aussi les informations de parties-du-discours dans le modèle de langue. Les figures 2 et 3 présentent les graphes de précision des traductions générées sur les ensembles de test pour les deux sens de traduction. Dans des langues proches comme le sont le français et l'anglais, beaucoup de termes spécialisés sont identiques. Comme simple baseline, nous calculons donc la précision qu'obtiendrait un système proposant systématiquement un terme comme sa propre traduction ; cette précision minimale donne ainsi une idée de la difficulté de la tâche de traduction.  Notre approche obtient de très bons résultats : 85.4 % de précision pour 100 % des mots traduits   pour le sens français-anglais et 84.8 % pour le sens inverse. Dans les deux cas, l'amélioration  par rapport à l'approche par transducteur (Claveau & Zweigenbaum, 2005b) est de 10 %. Cela s'explique principalement par la souplesse de notre approche par règles qui lève la contrainte de déterminisme de l'approche par transducteur imposant qu'une séquence ne puisse se traduire que d'une façon, limitant et complexifiant ainsi l'apprentissage en présence de données bruitées, d'exceptions ou de mots polyfonctionnels. Concernant l'utilisation des modèles de langue, on remarque qu'utiliser les ML sans prendre en compte des parties-du-discours fournit des précisions légèrement plus faibles (82.6 % pour le sens français-anglais et 84.8 % pour l'autre sens). Et choisir le candidat au hasard parmi les différentes traductions génerées plutôt qu'utiliser les scores de ML mène à une précision d'environ 50 %. Ces deux résulats montrent bien l'intérêt des ML pour choisir la meilleure traduction et le bien-fondé de l'inclusion des partiesdu-discours dans ces ML. Enfin, notre technique est très largement au-dessus de la baseline, mais il convient de noter que celle-ci montre que 25 % des termes biomédicaux sont identiques en français et en anglais, ce qui semble indiquer que les deux langues sont suffisamment proches pour rendre la tâche d'apprentissage relativement aisée.  4.3.2  Autres paires de langues  Nous répétons les expériences avec d'autres paires de langues disponibles dans l'UMLS.  Parmi les différentes combinaisons de langues possibles, nous n'en présentons ci-dessous que quelques unes. La figure 4 présente les résultats obtenus avec deux langues réputées proches : l'espagnol et le portugais. Les résultats sont très bons : 87.9 % des termes portugais sont correctement traduits en espagnol quand on traduit tous les termes (i.e. quand aucun seuil pour le ML n'est fixé) ; dans le sens inverse, ce sont 85 % des termes qui sont correctement traduits. Ces bons résultats ne sont pas surprenants : l'espagnol et le portugais sont très proches, et comme le soulignent les très hautes baselines, beaucoup de mots sont en fait identiques. Nous présentons maintenant les résultats obtenus par la traduction de diverses langues vers l'anglais - cas le plus à même d'être utilisé en pratique. La figure 5 présente les performances de la traduction de l'espagnol et du portugais vers l'anglais. Les résultats sont plutôt bons : 71.7 % des termes espagnols et 71.5 % des termes portugais sont correctement traduits quand toutes les traductions sont gardées (i.e. aucun seuil de ML n'est fixé). Ces résultats sont conformes avec la proximité de l'espagnol et du portugais illustrée dans l'expérience précédente. La traduction de l'italien et du tchèque vers l'anglais (figure 6) donne également des résultats comparables : au pire cas, 70 % des termes italiens et 75.5 % des termes tchèques sont correctement traduits.  Comme nous l'avons dit précédemment, notre technique de traduction peut traiter des langues  avec des alphabets différents, pourvu qu'elles montrent des régularités pouvant être apprises automatiquement. Pour illustrer cela, nous nous intéressons à la paire russe-anglais. La figure 7 présente les résultats obtenus ; la précision minimale obtenue ici est de 57.5 % (du fait de la différence d'alphabet, la baseline est ici à 0). Bien qu'inférieurs aux autres paires de langues, ces résultats sont relativement bons étant donnée la difficulté apparente de la tâche. Cela met en exergue l'emploi en russe des mêmes racines gréco-latines que pour les autres langues étudiées.  Parmi les perspectives ouvertes par ce travail, la traduction des termes complexes (composés  de plusieurs mots, comme ) est l'une des plus importantes pour assurer une bonne couverture des terminologies à traduire (ils représentent par exemple environ 50 % de la terminologie MeSH). Enfin, dans un cadre plus applicatif, l'utilisation de cette technique dans un cadre de recherche d'information translingue (traduction de requêtes de la base PubMed) est à l'étude et donne des premiers résultats encourageants (Claveau, 2007).  
