La plupart des mots ont plusieurs significations. La désambiguïsation lexicale consiste à choisir la bonne signification d'un mot polysémique dans un contexte donné. Cette opération est utile ou indispensable pour la plupart des applications de traitement automatique des langues : recherche d'information, traduction automatique, reconnaissance de la parole, etc. (Ide & Véronis, 1998). La campagne d'évaluation trisannuel SensEval (Edmonds, 2002) atteste de l'importance de cette tâche.  La désambiguïsation lexicale s'effectue toujours en utilisant l'information présente dans le  contexte du mot à désambiguïser. Cette information peut être enrichie par un certain nombre d'annotations (étiquette morphosyntaxique, lemmatisation, etc.). Il n'est cependant pas pos sible d'utiliser toute l'information disponible car elle est bien trop importante et bruitée. Il faut  donc se focaliser sur un certain nombre d'indices. Le choix de ces indices, déterminé par ce que nous appelons des critères de désambiguïsation lexicale, est primordial et constitue un enjeu important dans le domaine de la désambiguïsation lexicale automatique (Bruce et al., 1996; Ng & Zelle, 1997; Pedersen, 2001b).  Notre approche s'inscrit dans celles qui utilisent des techniques de classification supervisée sur  un corpus lexicalement désambiguïsé. Dans ce type d'approche, de nombreux travaux cherchent à améliorer la précision de la désambiguïsation en améliorant les techniques de classification. Le choix des indices utilisés est généralement déterminé plus ou moins arbitrairement par la connaissance, l'expérience et l'intuition du chercheur. Peu de travaux avaient étudié systématiquement l'impact du choix des indices utilisés sur la précision de la désambiguïsation. Pour cette raison, nous avons présenté une étude des critères de désambiguïsation sémantique automatique (Audibert, 2003a) basés sur les unigrammes (i.e. cooccurrences de mots isolés). Nous avons complété cette étude en explorant des indices basés sur des bigrammes et des trigrammes (Audibert, 2004). Dans ces travaux, les critères étudiés étaient homogènes dans le sens où ils étaient constitués d'indices de même nature : par exemple, soit des lemmes, soit des étiquettes morphosyntaxiques, mais pas une combinaison des deux.  Dans le présent article, nous présentons, dans un premier temps, une petite étude comparative  de différents algorithmes de classification. Nous nous intéressons ensuite à la sélection automatique des meilleurs indices du contexte pour former des critères de désambiguïsation hétérogènes sur lesquels un algorithme de classification peut s'appuyer efficacement pour effectuer de la désambiguïsation lexicale. Ce travail s'appuie toujours sur les 60 mots cibles (20 noms, 20 adjectifs et 20 verbes) des travaux précédents (Audibert, 2003a; Audibert, 2004).  Notre corpus de travail est composé de textes de genres variés et comporte 6 468 522 mots. Il a  été constitué dans le cadre du projet SyntSem qui vise à produire un corpus français d'amorçage étiqueté au niveau morphosyntaxique, lemmatisé et comportant un étiquetage syntaxique peu profond ainsi qu'un étiquetage lexical de 60 mots-cibles sélectionnés pour leur caractère fortement polysémique (Véronis, 1998). Ces 60 mots-cibles, qui totalisent 53796 occurrences dans le corpus, sont également répartis en 20 noms, 20 adjectifs et 20 verbes et sont détaillés dans le tableau 1. L'une des difficultés majeures de l'étiquetage sémantique automatique réside dans l'inadéquation des dictionnaires traditionnels (Véronis, 2001) ou dédiés (Palmer, 1998) pour cette tâche. Pour remédier à ce problème, l'équipe DELIC a entrepris la construction d'un dictionnaire distributionnel en se basant sur un ensemble de critères différentiels stricts (Reymond, 2001). C'est ce dictionnaire qui a été utilisé pour étiqueter les occurrences des 60 mots-cibles du projet SyntSem. Dans ce dictionnaire, le nombre de lexies par vocable est important car il inclut les locutions figées ou composées comme mettre sur pied, mettre à pied, pied de nez, etc. Un consensus semble émerger selon lequel l'étiquetage morphosyntaxique, et plus particuliè rement la levée de l'ambiguïté sur la catégorie grammaticale des vocables, n'est pas du ressort  de la désambiguïsation lexicale (Kilgarriff, 1997; Ng & Zelle, 1997). Nous avons confié l'étiquetage morphosyntaxique de notre corpus au logiciel Cordial Analyseur (développé par la société Synapse Développement), qui offre une lemmatisation et un étiquetage morphosyntaxique d'une exactitude satisfaisante (Valli & Véronis, 1999).  Le Tableau 2 présente un extrait du corpus SyntSem. Il permet de visualiser l'ensemble des  étiquettes que possède un mot. C'est l'information de ces étiquettes que nous utilisons dans nos critères de désambiguïsation lexicale.  Nous désignons par le terme d'indice une source potentielle d'information pouvant participer à  la levée de l'ambiguïté d'un mot cible dont nous cherchons la bonne lexie. Un indice peut être le lemme du mot qui précède par exemple. Un critère est simplement la donnée d'un ensemble d'indices. Nous avons étudié une grande variété de critères dans (Audibert, 2004). Les noms de ces critères précisent leur nature et sont de la forme [P1|P2|P3|P4]. Le paramètre P1 indique si le critère considère des unigrammes (P1=1gr), des bigrammes (P1=2gr) ou des trigrammes (P1=3gr) ; un n-gramme étant la juxtaposition de n mots. Le paramètre P2 indique si l'on regarde la forme brute des mots (P2=jeton), leur lemme (P2=lemme), leur étiquette morphosyntaxique (P2=ems) ou leur étiquette morphosyntaxique simplifiée (P2=smallems). Le paramètre P3 indique si les mots considérés sont différenciés par leur position (P3=ordonne), différenciés suivant qu'ils appartiennent au contexte droit ou gauche (P3=differencie), ou non différenciés (P3=non-ordonne). Enfin, le paramètre P4 indique si le critère considère tous les mots (P4=mot) ou seulement les mots pleins (P4=mot-plein). Nous qualifions ces critères de critères homogènes dans la mesure où l'ensemble des indices de désambiguïsation sont de la même nature puisque entièrement déterminés par l'instanciation des quatre paramètres.  Dans cette expérience, nous comparons différents algorithmes de classification supervisée en  utilisant un critère assez standard constitué du lemme des mots en tenant compte de leur position (i.e. [1gr|lemme|ordonne|mot]) dans une fenêtre de ±3 mots. Les algorithmes de classification évalués sont les suivants : MAJ est un classifieur qui retourne toujours la lexie la plus fréquente ; nous l'utilisons comme borne inférieure à la précision de la désambiguïsation ; PCM est un algorithme basé sur une liste de décisions, proche de celui utilisé par (Yarowsky, 1994) et détaillé dans (Audibert, 2003a) ; NB est notre implémentation du classifieur Naïf de Bayes ; KPPV est une implémentation élémentaire d'un classifieur du type k plus proches voisins ; PEBLS est classifieur du type k plus proches voisins possédant une métrique bien plus sophistiqué que celle de KPPV ; NBW est l'implémentation du projet Weka du classifieur Naïf de Bayes ; C45W est l'implémentation du projet Weka du classifieur C45. Le tableau 3 montre les résultats de cette expérience comparative. Dans toutes les expériences de désambiguïsation de cet article, toutes les occurrences reçoivent une classification. Le rappel étant égal à la précision dans ce cas, nous ne mentionnons que la précision obtenue.  Les temps d'exécution des deux algorithmes du projet Weka que nous avons utilisés (NBW et  C45W ) sont rédhibitoires pour nos expériences. Les raisons de ces temps d'exécution sont, ou peuvent être, la non optimisation de l'implémentation, l'utilisation du langage java et le format,  MAJ  PCM NB KPPV PEBLS NBW C45W Précision 42, 9% 72, 3% 74, 5% 65, 5% 70, 9% 58, 2% 74, 6% Intervalle de confiance ±0, 38% ±0, 37% ±0, 40% ±0, 38% ±0, 42% ±0, 37% Temps 3s 3s 5s 26mn 2h33mn 1h47mn 35h43mn  peu adapté au problème, de la représentation des données d'apprentissage. Le temps d'exécution  du classifieur PEBLS est également bien trop important et est une conséquence de la complexité de la métrique utilisée.  Les classifieurs NB et PCM, nécessitent tous deux des estimations de probabilités. En raison  des observations souvent rares et parfois nulles qui interviennent dans ces estimations, nous utilisons la m-estimation (Cussens, 1993) plutôt que l'estimation classique des probabilités. Cette différence explique certainement l'écart de performance des classifieurs NB et NBW.  Nous pouvons tirer deux enseignements de cette expérience. La premier est qu'il est souvent  difficile et parfois préjudiciable d'utiliser un algorithme de classification comme une boîte noire (cf. la comparaison entre NB et NBW). Le second est que la complexité et la sophistication des algorithmes de classification n'apportent pas forcément un gain important pour notre tâche (cf. la comparaison entre NB, PEBLS et C45). Actuellement, des gains bien plus importants sont à attendre des indices fournis aux classifieurs plutôt que des classifieurs eux-mêmes. En prenant tous les indices générés par tous les critères homogènes [P1|P2|P3|P4] correspondants aux différentes instanciations possibles des quatre paramètres P1 à P4, et en considérant une fenêtre de ±12 mots, nous obtenons 3 (1gr, 2gr ou 3gr) ×4 (jeton, lemme , ems ou smallems) ×3 (ordonne, differentie ou non-ordonne) ×2 (mot ou mot-plein) ×24 (contexte de ±12 mots ) soit 1728 indices différents.  En réduisant la taille du contexte considéré, nous avons généré un deuxième jeu d'indices réduit  à 888 indices. Dans ce jeu d'indices, la taille du contexte pour les critères basés sur les étiquettes lemme et jeton et composés d'unigrammes (respectivement de bigrammes et trigrammes) est de ±6 mots (respectivement ±8 et ±10), et pour les critères basés sur les étiquettes ems et smallems et composés d'unigrammes (respectivement de bigrammes et trigrammes) est de ±4 mots (respectivement ±5 et ±6).  La question est de savoir quels indices retenir, parmi les 1728 du premier jeu d'indices ou parmi  les 888 du second, pour former un critère hétérogène efficace pour la levée de l'ambiguïté. Pour représenter un critère nous utilisons une chaîne de bits, appelée un génome, composée de 1728 bits pour le premier jeu et de 888 bits pour le second. La valeur de chaque bit permet de préciser si l'indice associé est retenu ou pas. Un génome caractérise donc un critère (une sélection d'indices) hétérogène (tous les indices ne sont pas forcément de la même nature). En raison de la complexité combinatoire de notre problème d'optimisation de sélection d'indices, il n'existe pas de méthode exacte pour le résoudre en un temps raisonnable. Il faut donc se contenter de solutions approchées que nous obtenons en utilisant deux techniques classiques d'optimisation : les algorithmes gloutons et les algorithmes génétiques . Le principe de l'algorithme glouton est de rechercher le meilleur indice pris individuellement, puis de chercher quel indice lui associer pour améliorer au maximum la précision, et ainsi de suite jusqu'à ne plus obtenir d'amélioration. Les algorithmes génétiques, quant à eux, tentent de mettre en oeuvre le principe de la sélection naturelle (croisements et mutations) sur des populations de solutions potentielles (i.e des génomes) et se rapprochent de la solution au cours de générations successives.  Pour mettre en oeuvre ces techniques, le corpus de départ est scindé en deux sous-corpus. Le  premier sous-corpus contient 60% des exemples d'apprentissage. Il est utilisé dans un premier temps pour effectuer la sélection des indices en utilisant l'algorithme glouton ou l'algorithme génétique. Cette sélection se fait en générant une famille de génomes en suivant les règles propres à l'algorithme glouton ou génétique. L'évaluation de la performance de chacun des génomes (i.e. sous-ensemble d'indices) est réalisée par l'estimation de la précision obtenue par le classifieur NB en utilisant une méthode d'évaluation croisée k fois (avec k = 10) toujours sur ce même sous-corpus. Cette méthode est coûteuse en temps de calcul, mais permet l'évaluation des critères (i.e. des génomes) sur la totalité du sous-corpus. Une nouvelle génération de génomes est ensuite calculée en fonction de la génération précédente et des règles de l'algorithme glouton ou génétique. L'expérience est répétée tant que des génomes plus performants émergent des générations successives.  Les indices sélectionnés par le génome obtenant la meilleure performance constituent un critère  hétérogène utilisé pour l'apprentissage du classifieur NB sur la totalité du sous-corpus contenant 60% des exemples. Le deuxième sous-corpus, qui contient 40% des exemples d'apprentissage, est enfin utilisé pour estimer la précision de désambiguïsation obtenue par le classifieur NB précédemment entraîné.  Cette expérience a été conduite d'un côté sur chacun des vocables indépendamment (i.e. un  génome est sélectionné pour chacun des vocables) et d'un autre côté par catégorie grammaticale (i.e. un unique génome est sélectionné pour les 20 vocables d'une catégorie). L'expérience par catégorie grammaticale n'a pas été menée pour le jeu contenant 1728 indices en raisons des temps de calcul déjà de l'ordre de la dizaine de jours pour le jeu contenant 888 indices. Le tableau 4 rend compte des résultats de notre expérience. La lecture du tableau 4 permet d'observer immédiatement que chacune des expériences de sélection automatique des indices à permis de surpasser la précision obtenue par le meilleur critère homogène identifié dans (Audibert, 2004).  Nous avons systématiquement obtenu de meilleurs résultats en sélectionnant les indices avec  l'algorithme génétique plutôt qu'avec l'algorithme glouton qui est incapable de se sortir d'un  Noms  Adjectifs Verbes Moyenne P (%) Am. ICA P (%) Am. ICA P (%) Am. ICA P (%) Am. ICA Baseline (MAJ) 57, 2 46, 3 37, 2 42, 9 Critère homogène 81, 4 0, 0 75, 1 0, 0 72, 3 0, 0 74, 7 0, 0 Glou/Voc (1728) 82, 5 1, 0 ±1, 6 75, 7 0, 5 ±2, 0 74, 3 2, 0 ±1, 1 76, 3 1, 6 ±0, 8 Géné/Voc (1728) 83, 5 2, 1 ±1, 6 75, 9 0, 7 ±2, 0 75, 1 2, 8 ±1, 0 77, 0 2, 3 ±0, 8 Glou/Voc (888) 82, 9 1, 5 ±1, 6 75, 7 0, 6 ±2, 0 75, 0 2, 7 ±1, 0 76, 8 2, 1 ±0, 8 Géné/Voc (888) 85, 3 3, 9 ±1, 5 77, 3 2, 2 ±2, 0 77, 3 5, 0 ±1, 0 79, 0 4, 3 ±0, 8 Glou/Cat (888) 83, 7 2, 3 ±1, 6 75, 9 0, 7 ±2, 0 76, 8 4, 5 ±1, 0 78, 1 3, 4 ±0, 8 Géné/Cat (888) 85, 9 4, 4 ±1, 5 78, 2 3, 1 ±2, 0 77, 7 5, 4 ±1, 0 79, 5 4, 8 ±0, 8  minimum local. Dans nos expériences, l'algorithme glouton sélectionne environ 20 indices.  D'un autre côté, un algorithme génétique est capable, par définition, de se sortir d'un minimum local. Cependant, il ne garantit pas que tous les indices sélectionnés sont utiles et il sélectionne, dans nos expériences, environ 180 indices.  Un autre phénomène qui ressort de la lecture de ces résultats est que le jeu d'indices qui n'en  contient que 888 permet d'aboutir à de meilleurs résultats que le jeu d'indices en contenant 1728 . Les deux raisons de ce comportement sont la taille du corpus d'apprentissage, probablement trop faible pour une telle quantité d'indices, et le piège du surapprentissage sensible dans notre approche. De manière surprenante, nous obtenons de meilleurs résultats en opérant la sélection sur l'ensemble d'une catégorie grammaticale plutôt que sur chacun des vocables pris individuellement. Opérer la sélection sur l'ensemble d'une catégorie grammaticale permet de limiter le phénomène de surapprentissage et d'augmenter le nombre d'exemples sur lesquels se fait la sélection. Le gain obtenu par la limitation du phénomène de surapprentissage et l'augmentation du nombre d'exemples est ici supérieur à celui obtenu par l'ajustement de la sélection des indices individuellement pour chaque vocable. L'accord entre plusieurs annotateurs (ITA pour InTer-annotator Agreement en anglais) a été estimé à 96.4% (Audibert, 2003b) sur notre corpus. La précision moyenne de 79, 5% obtenue en effectuant une sélection automatique des indices permet de gagner 4, 8pt (avec un intervalle de confiance de ±0, 8) sur la précision obtenue par le meilleur critère homogène, ce qui correspond à 22% de l'écart avec la borne maximale estimée. Il s'agit donc d'une amélioration très  Nous avons cherché à en savoir plus sur les indices sélectionnés par l'algorithme génétique  appliqué par catégorie grammaticale sur le jeu de 888 indices, c'est-à-dire par la sélection qui obtient les meilleurs résultat et qui correspond à la dernière ligne du tableau 4. La figure 1 résume ces observations pour chacune des catégories grammaticales.  Les graphiques de gauche permettent de remarquer que les étiquettes jeton et lemme sont  bien plus utilisées que les étiquettes ems et smallems ce qui paraît logique et cohérent avec la littérature. Ils permettent également d'observer que les indices sélectionnés sont constitués en proportions comparables d'unigrammes, de bigrammes et de trigrammes. Cette observation conforte celle que nous avions faite dans (Audibert, 2004), à savoir que les bigrammes et les trigrammes véhiculent une information importante qui ne se retrouve pas dans les unigrammes. Ces graphiques permettent enfin d'observer que la sélection opérée par l'algorithme génétique ne privilégie pas les indices constitués uniquement de mots pleins. Comme nous l'avions remarqué dans (Audibert, 2004), le filtrage consistant à supprimer les mots grammaticaux n'apparaît absolument pas pertinent. Les graphiques de droite de la figure 1 montrent que la répartition spatiale des indices sélectionnés par l'algorithme génétique diffère suivant la catégorie grammaticale du mot à désambiguïser. Concernant les noms, la répartition des indices est grossièrement symétrique par rapport au mots à désambiguïser et les indices les plus proches sont privilégiés. La répartition des indices pour la désambiguïsation des adjectifs est bien plus aplatie que pour les deux autres catégories grammaticales. De plus, ce sont les adjectifs qui bénéficient le moins de l'amélioration de la précision apportée par la sélection automatique des indices : 3, 1pt contre 4, 4pt pour les noms et 5, 4pt pour les verbes. Comme nous l'avions déjà observé dans (Audibert, 2004), la répartition des indices pour la désambiguïsation des verbes est fortement dissymétrique probablement parce que la désambiguïsation des verbes se fait plus en fonction de leur objet que de leur sujet, la forme sujet-verbe-complément étant la plus fréquente.  Comme (Mohammad & Pedersen, 2004; Ng & Lee, 2002; Pedersen, 2001a), entre autres, nous  pensons que les performance d'un algorithmes de désambiguïsation dépendent principalement de la qualité des indices du contexte considéré plutôt que de la sophistication des algorithmes de désambiguïsation utilisés. Dans cet article, nous avons exposé une expérience consistant à automatiser une sélection d'indices de natures différentes. Ainsi, en réalisant une sélection automatique basée sur un algorithme génétique, nous sommes parvenus à une précision de désambiguïsation, sur les 60 vocables de notre étude, de 79.5%, soit 4, 8pt de plus que la précision obtenue par le meilleur critère homogène identifié lors de notre étude systématique précédente (Audibert, 2004). Cette amélioration est importante, mais d'autres espoirs d'améliorations sont à attendre de l'enrichissement des indices disponibles en utilisant, par exemple : - des indices issus de relations syntaxiques binaires (nom-nom, nom-verbe, adjectif-nom, etc.) ; - des thésaurus ou des ontologies pour effectuer des généralisations sur les mots du contexte du mot à désambiguïser ; - des informations sur le thème du texte.  
