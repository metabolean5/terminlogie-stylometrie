Le contrôle des hypothèses concurrentes générées par les différents modules qui peuvent intervenir dans des processus de TALN reste un enjeu important malgré de nombreuses avancées en terme de robustesse. Nous présentons dans cet article une méthodologie générique de contrôle exploitant des techniques issues de l'aide multicritère à la décision. À partir de l'ensemble des critères de comparaison disponibles et la formalisation des préférences d'un expert, l'approche proposée évalue la pertinence relative des différents objets linguistiques générés et conduit à la mise en place d'une action de contrôle appropriée telle que le filtrage, le classement, le tri ou la propagation. The control of concurrent hypotheses generated by the different modules which compose NLP processes is still an important issue despite advances concerning robustness. In this article, we present a generic methodology of control inspired from multicriteria decision aid methods. Based on available comparison criteria and formalized expert knowledge, the proposed approach evaluate the relevancy of each generated linguistic object and lead to the decision of an appropriate control action such as filtering, ordering, sorting or propagating. méthodologie de contrôle, aide multicritère à la décision, apprentissage automatique de métriques. control methodology, multicriteria decision aid, metrics automatic learning. De nombreuses avancées en termes de formalisme, d'algorithmique et de développement de ressources ont permis aux systèmes de traitement automatique des langues naturelles (TALN) d'atteindre une couverture très satisfaisante des différents phénomènes linguistiques observables. Cependant, quelle que soit la tâche ou le niveau d'analyse concerné, les différentes approches envisagées sont de manière récurrente confrontées au manque de précision des résultats générés. Ce phénomène se matérialise par la présence d'objets linguistiques concurrents de différentes natures. Bien que justifiable en présence d'ambiguïtés locales "naturelles", ces indéterminations concernent la plupart du temps des erreurs d'interprétations souvent qualifiées d'ambiguïtés "ar tificielles". Le contrôle du processus d'analyse a pour objectif d'identifier le plus tôt possible  ces ambiguïtés "artificielles" afin notamment d'éviter leur propagation vers les étapes suivantes de l'analyse. Bien que des propositions d'architectures de TALN conformes vis à vis des modèles cognitifs aient été proposées afin d'éviter la génération d'objets linguistiques erronnés (Rady, 1983) (Sabah, 1990), la mise en place de stratégies spécifiques de contrôle semble indispensable.  Nous verrons dans un premier temps que le contrôle des indéterminations, appelés "points  d'embarras" par (Sabah, 1989) repose sur la prise en compte d'informations distinctives hétérogènes. En s'appuyant sur un exemple de chaîne de TALN et un cas concret d'indétermination, nous verrons dans un second temps que le contrôle peut être considéré comme une démarche décisionnelle basée sur plusieurs critères de comparaison. Nous avons ainsi développé une méthode complète et générique inspirée des approches d'aide multicritère à la décision. Avant de présenter les premiers résultats obtenus, nous verrons que la prise d'une décision repose sur la formalisation des connaissances d'un expert sur la tâche à contrôler.  De nombreux systèmes de TALN peuvent être représentés comme un ensemble de modules  d'analyse qui appliqués successivement composent le processus complet d'interprétation linguistique. L'objectif de chacun de ces composants est de construire ses propres interprétations à partir de ressources linguistiques et des informations générées par les étapes précédentes. Ces interprétations que nous nommerons par la suite objets linguistiques peuvent correspondre à : - des unités lexicales ou de sens ; - à un découpage en constituants suite à une analyse syntaxique de surface ; - à un arbre de dépendance syntaxique suite à l'application d'une grammaire de dépendances ; - à des graphes sémantiques ; - à des suggestions de corrections orthographiques ; - à des rubriques sémantiques d'indexation correspondant à une requête. Fréquemment appliqués séquentiellement, ces modules sont sources de "points d'embarras" et affectent donc la complexité et l'efficacité du processus d'analyse et nuisent également à l'utilisabilité des résultats générés. Il devient alors indispensable de contrôler l'apparition de ces indéterminations, notamment en comparant la pertinence relative de chaque objet linguistique instancié et en mettant en place une action de contrôle appropriée pour éviter la propagation d'interprétations erronnées. En conservant la terminologie proposée par (Sabah, 1989), l'enjeu du contrôle de ces processus réside dans la transformation des "points d'embarras" en "points de décision". Ce dernier désigne un état du processus de traitement où plusieurs objets linguistiques concurrents ont été générés, mais qui est également caractérisé par la disponibilité de connaissances et de critères de  comparaisons à partir desquels une stratégie de contrôle peut être déployée. Ainsi, pour pallier  le manque d'informations distinctives nécessaires à la comparaison des différents objets linguistiques, de nombreux travaux ont proposé d'intégrer des connaissances supplémentaires de différentes natures (probabiliste (Blache & Rauzy, 2006), statistiques (Charniak & M.Johnson, 2005), heuristique (Uszkoreit, 1991), symbolique (Bourigault & Frérot, 2004)) pour qualifier la pertinence de chaque candidat et permettre la mise en place d'une action de contrôle. On constate également que pour un "point d'embarras" identifié, plusieurs sources indépendantes de connaissances peuvent être exploitées pour affecter à chacun des objets linguistiques un critère de comparaison. Il apparaît cependant que pour chaque contexte de contrôle, aucune connaissance ne permet individuellement de caractériser et d'évaluer pleinement la validité de chaque interprétation envisagée. L'indéterminisme lié à l'attachement d'un groupe prépositionnel constitue un exemple très illustratif . En effet, l'application d'une grammaire donnée sur une phrase "jouet" comme : "Je possède la statue de bois de rose de Charles", entraînerait sans doute la construction d'au moins 5 arbres syntaxiques concurrents. Afin de déterminer leur pertinence, chaque attachement peut être jugé par rapport : - à sa conformité vis à vis des informations prosodiques (rarement disponibles) ; - à son respect des heuristiques d'attachement droit ou minimal ; - à des données de sous-catégorisations syntaxiques (Bourigault & Frérot, 2004) ; - à sa fréquence d'apparition observée sur corpus (Gala, 2003) ; - à des préférences d'usages liées à la sémantique des propositions (Whittemore et al., 1990) ; - etc. Chacune des sources de jugement citées précédemment apporte ainsi une information discriminante permettant d'identifier pour certains cas "ambiguïtés" d'attachement envisageables les erreurs d'interprétation à filtrer, ou réciproquement les attachements à privilégier, mais également une erreur d'appréciation pour les autres cas. Afin d'augmenter la robustesse et la crédibilité apportée à l'évaluation de la pertinence de chaque objet linguistique, il semble indispensable de combiner et d'exploiter différents points de vue de jugement. Bien que des arguments psychololinguistiques (Altmann, 1998) (Gibson & Pearlmutter, 1998) aient déjà été avancés en faveur de l'usage combinée de sources de connaissances, peu de stratégies de contrôle exploitent la complémentarité de différents critères de comparaison (Rosso et al., 2003) (Rigau et al., 1997). Nos travaux se sont donc focalisés sur la mise en place d'un formalisme et d'une méthodologie générique de contrôle exploitant l'information apportée par chaque source de jugement pour comparer la pertinence d'objets linguistiques concurrents.  TiLT  est une boîte à outils de TALN développée par l'équipe Langues Naturelles de France Télécom R&D . Le processus d'analyse paramétrable est composé d'un ensemble de modules de traitements qui, appliqués séquentiellement, construisent de manière itérative des interprétations linguistiques de différentes natures. En fonction des caractéristiques du contexte applicatif, certaines étapes de traitement constituent des "points d'embarras". Pour éviter la propagation d'objets linguistiques erronés, différents traits, scores ou probabilités calculés, méthodes spécifiques de jugement ont été intégrés au processus classique d'analyse pour être exploités comme critères de comparaison. Cependant aucune stratégie spécifique de contrôle ne permettait de les combiner ou d'évaluer leur efficacité. L'architecture modulaire d'analyse de  TiLT  a été dans un premier temps modifiée (Smits, 2006) afin de simplifier l'intégration de ces critères de comparaison, de les centraliser et de permettre la mise en place de phases de contrôle entre les étapes d'analyse. L'architecture décisionnelle de TiLT centralise en tant que critères de comparaison les connaissances supplémentaires intégrées lors du contrôle d'un "point d'embarras". En plus du cadre formel, l'approche de contrôle propose une méthode complète permettant à un expert, le linguiste ou l'informaticien en charge du paramétrage de TiLT, d'exprimer ses connaissances et intuitions sur la tâche de contrôle en question et la façon dont les critères disponibles doivent être exploités. Nous nous rapprochons ainsi du domaine de l'aide multicritère à la décision qui "vise, comme son nom l'indique, à fournir à un décideur des outils lui permettant de progresser dans la résolution d'un problème de décision où plusieurs points de vue, souvent contradictoires, doivent être pris en compte." (Vincke, 1998).  La méthode envisagée (Smits, 2007) s'inspire profondément des méthodes de surclassement (en  particulier ELECTRE III et ELECTRE TRI (Roy, 1990)). À partir des valeurs des critères de comparaison qui qualifient les objets comparés et des connaissances exprimées par le décideur, ces méthodes établissent entre les différentes hypothèses candidates des relations de surclassement. Une telle relation notée oSo est établie entre deux objets linguistiques o et o si "il y a suffisamment d'arguments pour admettre que o est au moins aussi bonne que o , sans qu'il y ait de raison importante de refuser cette affirmation." Ces relations "abstraites" de surclassements permettent d'établir des relations de préférence, d'indifférence (utile pour la factorisation) ou d'incomparabilité (exploitées pour le filtrage).  Pour répondre à une problématique de classement, on exploiter l'ensemble des relations de  surclassement établies entre les différents objets linguistiques pour établir un pré-ordre partiel (avec ex aequo) ou total (Fig. 1). Quant aux problématiques de tri et filtrage, les différents objets linguistiques concurrents ne sont plus comparés entre eux, mais par rapport à des profils d'acceptabilité qui définissent, pour chaque classe considérée, les performances à atteindre sur chacun des critères pour faire partie de la classe en question (cf. cas d'expérimentation Fig. 2).  Soit O : o  , o , ..., o l'ensemble des objets linguistiques comparés et G : g , g , ..., g les m critères utilisés lors du contrôle, où g (o ) correspond à la valeur obtenue par l'objet o pour le j critère.  Les préférences et connaissances du décideur se matérialisent dans un premier temps à travers  les critères choisis pour la tâche de contrôle, mais également par un ensemble de paramètres qui peuvent être associés à chaque critère g : - un poids d'importance w ;  - un seuil de préférence p  ; il correspond à la plus petite différence de valeur à partir de laquelle une situation de préférence peut être établie entre deux objets. - un seuil d'indifférence q (q <= p ) ; correspond à la plus grande différence préservant l'indifférence entre 2 objets sur le critère j. - un seuil de veto v (p <= v ). correspond à la différence de valeur à partir de laquelle un objet devient incomparable vis à vis d'un autre, car jugé trop faible sur un critère important. Ce paramètre permet notamment de définir des conditions de filtrage. Ces préférences expertes interviennent dans le calcul d'un indice de surclassement S(o, o ), quantifiant la crédibilité du surclassement de o par l'objet o, où o peut correspondre à un objet concurrent de o ou à un profil d'acceptabilité d'une classe pour les problématiques de tri. Cet indice de surclassement S(o, o ) repose sur le produit d'un indice de concordance C(o, o ), représentant la majorité des critères en faveur de o, et d'un indice de discordance D(o, o ), représentant la minorité des critères refusant le surclassement de o par o : S(o, o ) = C(o, o ) . D(o, o ) , où C(o, o ) = w c (o, o )  c  (o, o ) =        1, si g (o)  g (o ) >= p 0, si g (o)  g (o ) <= q , si q < g (o)  g (o ) < p  , et D(o, o ) =  , G = j  G/d (o, o ) > C(o, o )  d  (o, o ) =        1, si g (o )  g (o) >= v 0, si g (o )  g (o) <= p , si p < g (o )  g (o) < v  L'interprétation des relations de surclassement permet de définir des situations de préférence  stricte : oP o si S(o, o )  ¬S(o , o), d'indifférence : oIo si S(o, o )  S(o , o) ou d'incomparabilité : oRo si ¬S(o, o )  ¬S(o , o). Les relations établies, regroupées dans une structure de préférences (Fig. 1), sont exploitées pour établir un pré-ordre complet ou partiel (avec ex aequo) des objets comparés.  La pertinence des relations de comparaison établies entre les objets concurrents dépend à la  fois de l'information distinctive portée par les critères qui les qualifient, mais également des préférences du décideur. Il est cependant difficile et peu naturel pour un décideur de déterminer clairement et par l'intermédiaire de valeurs numériques, les valeurs de ces différents paramètres décisionnels. Même si l'externalisation de l'ensemble de ces informations dans un module spécifique de contrôle facilite les expérimentations itératives, l'impact de chaque paramètre sur le résultat final est difficilement quantifiable a priori. Il est en revanche nettement plus évident pour un expert de se prononcer sur la pertinence des objets linguistiques générés. Cette démarche de validation des résultats générés par un expert est fortement exploitée pour la construction de corpus de références, servant ensuite de données pour l'apprentissage de ressources ou l'évaluation de systèmes. Nous proposons de considérer l'identification des objets linguistiques de référence comme l'expression de l'expertise de l'annoteur sur une tâche de contrôle à automatiser. Ainsi, qualifier une hypothèse comme valide revient à qualifier les performances qu'elle a obtenu sur les critères exploitées comme discriminants. Une hypothèse annotée comme correcte ou incorrect et les performances calculées sur les critères concernés par l'étape de contrôle constituent un enregistrement de ce que nous nommons un tableau de performances : Nous exploitons ce tableau de  Objets annotés.  vecteur de performances annotation critère 1 critère 2 ... critère m o 4.2 Vrai ... 36 correct o 5.0 Vrai ... 16 correct o 2.6 Faux ... 24 incorrect o 1.2 Faux ... 42 correct ... ... ... ... ... ... o 4.0 Vrai ... 4 incorrect o 0 Faux ... 17 incorrect  performances pour évaluer et quantifier la pertinence de chacun des critères disponibles. Une  distribution de performances d'un critère est jugée pertinente, si elle permet de caractériser un certain type d'annotation (i.e. la classe des hypothèses correctes ou la classes des hypothèses incorrectes). La méthode d'apprentissage de métriques RELIEF (Kononenko, 1994) permet d'atteindre ce but, en associant à chaque critère un poids normé sur [1, 1], où une valeur négative caractérise un critère non représentatif de la classe des hypothèses correctes. Les résultats de la méthode sont ensuite exploiter lors de la construction de l'indice de crédibilité en tant que vecteur de poids des critères.  Nous proposons également de considérer la performance minimale obtenue sur un critère par  les hypothèses annotées comme correctes en tant que limite d'acceptabilité de ce critère.  Nous présentons dans cette section les premiers résultats obtenus sur un des nombreux cas de  contrôle envisageables. Il s'agit de répondre à une problématique de classement des couples antécédent/reprise-anaphorique candidats extraits d'un corpus.  Cette expérimentation s'inscrit dans le cadre d'une collaboration et d'une extension des travaux  réalisés par O TARDIF (Tardif, 2006). Un algorithme extrait à partir d'un texte un ensemble de couples d'expressions constituant potentiellement des patrons antécédent/repriseanaphorique. Une expression correspond à une entité nommée (NPR : Mickaël Gordbatchev, l'URSS, Vilnius), un pronom (PRON : il, celui-là) ou un groupe nominal (NCOM : le dirigeant soviétique, le parlement). L'enjeu du contrôle est de construire une classes des candidats valides à partir des performances qui leurs sont associées sur différents critères, tels que : - des mesures de distances (en mots, phrases, etc.) ; - la correspondance des classes sémantiques et des fonctions syntaxiques ; - des marques morphologiques (indéfini, possessif) ; - des mesures de distance et de similarité alphabétiques ; - des propriétés d'accords de genre et de nombre. Pour constituer la classe des reprises anaphoriques valides, les relations de surclassement ne sont pas construites entre les couples candidats, mais entre chaque candidat et un profil d'acceptabilité (Fig. 2). Ce vecteur de limites d'acceptabilité constitue une nouvelle préférence mise en place par l'expert pour contrôler la validité des hypothèses comparées. Ainsi, un candidat qui surclasse ce profil est considéré comme un cas de reprise anaphorique.  Nous disposons d'un corpus de 80 textes journalistiques (Le Monde de 1989-1990) annoté  automatiquement par TiLT afin de disposer d'informations morphologiques, syntaxiques et sémantiques sur les expressions et leur rôle dans la phrase. Les liens de coréférences entre les expressions ainsi que la classe sémantique (personne, lieux, organisation) de celles-ci ont ensuite été marqués manuellement.  Les couples d'expressions constituées à partir du corpus ont été partitionnés en fonction de leur  type : NPR-NPR, NPR-NCOM, NPR-PRON, NCOM-NCOM, NCOM-PRON, PRON-PRON. Nous nous sommes restreint pour cette évaluation aux couples ayant pour antécédent un nom propre.  Dans un premier temps, nous avons, à travers une démarche interactive, demandé à un expert du  domaine de constituer trois profils de paramètres décisionnels (voir Sec. 3.2) pour les trois cas de reprise anaphorique traités. L'expert devait ainsi identifier les critères qu'il jugeait pertinents dans chacun des cas, ainsi que leur importance relative dans l'agrégation, un profil d'acceptabilité et éventuellement des seuils de préférence, indifférence et veto. Dans un second temps, nous avons exploité une partie du corpus annoté pour apprendre automatiquement les poids des différents critères ainsi que les seuils délimitant la classe des couples valides (Sec. 3.3). Ce corpus est constitué de 950 paires npr-npr, 3400 paires npr-ncom et 620 paires npr-pron, composé respectivement de 90, 46 et 48 cas valides (positifs) de coréférence. Nous avons ensuite évalué les différents profils de paramètres sur un corpus d'évaluation extrait du corpus de référence, constitué de 120 paires candidates NPR-NPR (19 positives), 80 paires NPR-PRON (12 positives) et de 414 paires NPR-NCOM (9 positives).  L'apprentissage automatique des poids des critères ainsi que des limites d'acceptabilité nous  permet d'améliorer sensiblement les résultats bien que le corpus soit principalement composé d'exemples négatifs (à plus de 90% sur le corpus de test et à plus de 95% sur le corpus d'apprentissage). Inférer automatiquement ces paramètres décisionnels nous permet identifier et de quantifier l'utilité des différents critères disponibles, contredisant parfois les intuitions de l'expert qui exploitait des critères n'apportant que du bruit. Par exemple, pour le cas des couples NPR-PRON, l'expert a sélectionné quatre critères comme pertinents et a formulé les préférences suivantes concernant l'importance relative de chacun d'eux : 1. accord en nombre entre l'antécédent et la reprise 2. accord en genre entre l'antécédent et la reprise 3. nombre d'occurences de l'antécédent dans le texte 4. nombre d'expressions séparant l'antécédent de la reprise 5. antécédent et reprise ont la fonction sujet  Cependant, par apprentissage sur corpus de référence, de nouveaux critères ont été identifiés  comme pertinents et l'ordre d'importance de l'ensemble des critères utilisé a été modifié, ce qui explique l'amélioration des résultats (les autres paramètres de seuils restants identiques au profil décisionnel de l'expert) :  1. antécédent est l'expression la plus proche   2. antécédent et reprise sont dans la même phrase   3. nombre d'occurences de l'antécédent dans le texte   4. accord en nombre entre l'antécédent et la reprise   5. nombre d'expressions séparant l'antécédent de la reprise   6. nombre de mots séparant l'antécédent de la reprise   7. antécédent et reprise ont la fonction sujet   8. accord en genre entre l'antécédent et la reprise   Cette tâche d'identification des couples antécédent/reprise-anaphorique avait dans un premier  été traitée à l'aide de classifieurs bayésiens naïfs. Outre des améliorations des valeurs de précision et de rappel, notre approche offre à l'expert la possibilité d'intervenir sur le comportement de la méthode de classification mais également une meilleure compréhension des décisions émises.  Nous proposons une méthode générique de contrôle des points d'embarras apparaissant lors  d'un processus de TALN. Cette méthode inspirée de l'aide multicritère à la décision se base sur l'agrégation de critères de comparaison hétérogènes. Les différents paramètres externalisés dans un profil décisionnel permettent à un expert d'exprimer ses connaissances et intuitions sur le problème traité. Pour valider ou inférer automatiquement les préférences émises par un expert, nous utilisons des méthodes d'apprentissage supervisé exploitant un corpus de référence. La méthode d'apprentissage de métriques RELIEF s'avère efficace pour quantifier la représentativité d'un critère vis à vis d'un ensemble d'exemples annotés comme valides. Nous envisageons cependant d'exploiter une variante de cette méthode pour réduire l'impact de la forte proportion d'exemples négatifs lors de l'apprentissage. Nous travaillons actuellement sur la mise en place de méthodes de seuillage pour inférer automatiquement les autres paramètres décisionnels.  L'approche proposée est en cours de validation sur un autre cas concret d'expérimentation : le  classement des arbres syntaxiques concurrents. L'automatisation d'une procédure d'aide à la décision basée sur la comparaison deux à deux des hypothèses concurrentes, pour les problématiques de classement, pose cependant des problèmes de complexité. Ainsi, en présence d'un grand nombre d'hypothèses concurrentes, il ne semble pas judicieux de construire un classement de tous les candidats. Nous proposons donc d'effectuer un premier filtrage en exploitant notamment les critères jugés comme les plus pertinent par la méthode d'apprentissage automatique des poids. Sur le sous-ensemble d'hypothèses restant, des relations de surclassement peuvent être établies et interprétées pour obtenir un classement des N meilleurs candidats.  
