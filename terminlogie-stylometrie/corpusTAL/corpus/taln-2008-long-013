Cet article présente une architecture inspirée des systèmes de reconnaissance  vocale pour effectuer une normalisation orthographique de messages en « langage SMS ». Nous décrivons notre système de base, ainsi que diverses évolutions de ce système, qui permettent d'améliorer sensiblement la qualité des normalisations produites. This paper presents a system aiming at normalizing the orthography of SMS messages, using techniques that are commonly used in automatic speech recognition devices. We describe a baseline system and various evolutions, which are shown to improve significantly the quality of the output normalizations. SMS, décodage phonétique, modèles de langage, transducteurs finis. SMS, phonetic decoding, language models, finite-state transducers. La diffusion des outils de communication électronique (mails, SMS, blogs, forums de discussion, chats, etc) a favorisé l'émergence de nouvelles formes d'écrits (Veronis & Guimier de Neef, 2006). Destinés à des proches ou à des pairs, rédigés dans l'instant, avec des interfaces qui imposent des contraintes nouvelles (claviers d'ordinateurs, d'assistants personnels ou de téléphones portables), ces textes se caractérisent par un net relâchement vis-à-vis de la norme orthographique, ainsi que par de multiples détournements de l'usage conventionnel des caractères alphabétiques, utilisés non seulement pour encoder des formes linguistiques, mais également du méta-discours (citations), des émotions (colère, humour), des attitudes (emphase, dérision) etc. Si chaque média impose des contraintes spécifiques et se caractérise par des modes d'écriture et des codes qui lui sont propres (voir, par exemple, (Torzec et al., 2001) pour les mails, (Falaise, 2005) pour les chats, ou (Anis, 2001; Anis, 2002; Fairon et al., 2006) pour les SMS), ces nouvelles formes de communication écrite partagent de nombreuses similarités. Face à ces textes d'un genre nouveau, il importe de développer de nouveaux outils de traitement automatique, permettant, par exemple, de pouvoir indexer et effectuer des recherches dans des corpus de messages. Dans cette étude, nous nous intéressons plus spécifiquement aux SMS, messages courts rédigés sur les claviers de téléphones portables, qui, nous semble-t-il, condensent à l'extrême les difficultés que posent ces écrits aux systèmes de traitement des langues.  Le « langage SMS » a fait l'objet de plusieurs études linguistiques (Anis, 2001; Anis, 2002;  Fairon et al., 2006), qui permettent de cerner ses principales caractéristiques, notamment la très forte variabilité graphique des formes lexicales. Cette variabilité résulte, d'une part, de l'utilisation simultanée de plusieurs systèmes d'encodage : pour dire vite , l'écriture alphabé tique usuelle , est en compétition avec une écriture plus phonétique, ainsi qu'avec une écriture  « consonantique » (seules subsistent les consonnes), enfin avec une écriture « rébus » (lettres et chiffres encodent la valeur phonétique de leur épellation). Elle découle également d'un style de communication relâché, qui autorise les plus grandes libertés par rapport à la norme orthographique (non-respect des accords, des flexions verbales, etc). En conséquence, du point de vue lexical, ces messages se caractérisent par un très fort taux de mots « hors-vocabulaire », correspondant à des néographismes, ainsi que par une forte augmentation de l'ambiguïté des formes lexicales « attestées ». Restaurer une orthographe normalisée est donc un préalable pour pouvoir leur appliquer d'autres traitements (synthèse vocale, indexation , etc.) ; elle représente également, du fait de la créativité des scripteurs, un sérieux défi.  Les travaux portant explicitement sur la normalisation automatique de SMS sont relativement  rares : mentionnons, pour le français, (Guimier de Neef et al., 2007) qui aborde le problème sous l'angle de la correction orthographique et propose une chaîne complète de traitements symboliques pour effectuer cette correction ; (Barthélemy, 2007) est plus prospectif et suggère une modélisation à base d'automates finis permettant de gérer efficacement la concurrence entre divers modes d'écritures. Pour l'anglais, signalons (Aw et al., 2006), qui s'inspire des méthodes utilisées en traduction statistique, ainsi que (Choudhury et al., 2007), dont le système de normalisation utilise des méthodes statistiques de correction d'orthographe.  Le système de normalisation présenté dans cet article propose une approche différente, qui  cherche à tirer parti de la proximité, relevée par de nombreux auteurs, entre les formes d'écriture utilisées dans les SMS et la langue orale. Notre hypothèse est que le recensement (par exemple dans un dictionnaire) de l'ensemble des variations orthographiques est voué à l'échec. Il semble comparativement plus aisé de produire une représentation phonémique approximative et ambiguë d'un message, sous la forme d'un ensemble de phonétisations possibles, comme il est commun de le faire en correction orthographique. La reconstruction d'un message normalisé est alors très similaire au décodage phonétique, puisqu'il s'agit de retrouver, dans un treillis phonétique la séquence de mots la plus vraisemblable : il semble alors naturel d'utiliser, pour ce problème, des techniques utilisées en reconnaissance de la parole.  Cet article est organisé comme suit. Dans un premier temps, nous décrivons notre système de  base (section 2), avant de présenter, à la section 3, plusieurs évolutions de ce système : amélioration du traitement des mots hors-vocabulaire ; introduction de grammaires locales pour les heures et dates ; acquisition automatisée d'un dictionnaire d'exceptions. La section 4 présente une évaluation des performances du système de base et des évolutions proposées, sur l'analyse desquelles nous nous appuyons pour esquisser quelques perspectives (section 5).  Notre système de normalisation repose sur un principe d'expansion/contraction :  - dans un premier temps, le message est converti en un ensemble de séquences phonétiques représentant toutes les prononciations possibles sous la forme d'un « treillis » de phonèmes. - la conversion inverse est ensuite calculée : transformation des séquences de phonèmes en  SMS  Prétraitements Traitement des exceptions  Phonétisation   Dictionnaire  inverse Modèle de langage SMS normalisé Séquence alphabétique  Graphe alphabétique   Graphe phonétique   Graphe de mots  Séquence de mots   [a]   [b]   qui exprime la récriture du motif a en b dans un contexte décrit par les expressions rationnelles   et . Le non-déterminisme de ces règles, c.-à-d. la possibilité que le langage dénoté par b contienne plusieurs mots est inhabituel en transcription graphème-phonème : c'est toutefois un aspect crucial du système, qui assure que l'espace des prononciations possibles est complètement envisagé. Par exemple, la règle de prononciation la plus générale de la lettre 'c' lui associe les quatre prononciations : / k/, /s/, /sE/, /se/ : si les deux premières prononciations sont attendues, les deux suivantes expriment la possibilité que cette lettre soit utilisée phonétiquement (et doive donc être « épelée »). Les exceptions détectées lors de la première étape subissent ici un traitement particulier : dans la mesure où ces formes sont déjà normalisées, la phonétisation s'applique de façon déterministe, par accès à un dictionnaire de prononciation.  La suite du traitement utilise les ressources suivantes :  - un dictionnaire de prononciation, utilisé pour convertir des séquences de phonèmes en séquences de mots ; - un modèle de langage statistique, qui permet d'ordonner par probabilité croissante les séquences de mots ; L'accès au dictionnaire permet de dégager, à partir du graphe de phonèmes, l'ensemble des séquences de mots possibles ; le modèle de langage permet de pondérer l'ensemble des hypothèses de phrases possibles ; enfin, un algorithme de programmation dynamique sélectionne la séquence de mots la plus probable. Chacun de ces modules peut être implanté par des automates ou transducteurs finis éventuellement pondérés. C'est le cas des deux dictionnaires décrits dans la section précédente : le dictionnaire d'exception réalise une transduction de séquences orthographiques en séquences de phonèmes (transducteur E), l'inverse du dictionnaire de prononciation (transducteur D) associe des séquences de mots à des séquences de phonèmes. C'est encore le cas du module appliquant des règles de phonétisation contextuelles (Kaplan & Kay, 1994; Mohri et al., 1996), qui sont globalement compilées en un transducteur R, ainsi que du modèle de langage de type n-gramme, représenté par un accepteur pondéré L. Ces transducteurs sont construits , pour les trois premiers, par des scripts ad-hoc et par les outils de la suite GRM (Allauzen et al., 2005) pour le modèle de langage. Une fois le message en entrée converti en un automate fini M par le module de prétraitement , l'ensemble des récritures réalisant la normalisation est prise en charge par les opérations suivantes : - construction de l'ensemble des séquences de mots possibles pour M , pondérées par leur probabilité pour le modèle de langage. Cette opération est réalisée par composition des différents transducteurs : T = M  E  R  D  L, dont on ne conserve par projection que le langage de sortie  (T ). - recherche de la séquence de probabilité maximale dans  (T ) par un algorithme calculant des plus courts chemins dans un graphe valué. Il est possible d'optimiser ce traitement en précalculant E  R  D  L, ainsi qu'en optimisant (par déterminisation et minimisation) préalablement D  L selon des procédés usuellement utilisés en reconnaissance vocale. L'ensemble de ces opérations est réalisée par les outils de la suite de manipulation de transducteurs finis FSM (Mohri et al., 2000). Le passage par une représentation phonétique comporte un avantage supplémentaire : dans l'optique d'une vocalisation des SMS, il permet de produire sans calcul supplémentaire non seulement la forme orthographique normalisée, mais également la forme phonétique associée à cette normalisation.  L'architecture décrite ci-dessus permet de traiter simplement la question des frontière de mots.  Il est courant de trouver dans les messages des formes agglutinées telles que :  (1)  Kestu fe ? (2) ... avec lbac blanc ...  (3)  g ésayé 2tapelé pl1 2foi (exemple tiré de (Guimier de Neef et al., 2007)) Ces exemples sont notoirement difficiles à traiter par des systèmes symboliques (Guimier de Neef et al., 2007). Pour autant, les messages à normaliser sont partiellement segmentés (espaces, ponctuations) ; cette information est relativement fiable et doit être utilisée. Notre architecture  En revanche, il n'est pas possible, dans ce schéma, que deux mots soient « recollés » : tout  séparateur présent dans l'entrée sera également présent dans la sortie. Ceci rend notre système incapable de traiter correctement des entrées telles que &#34;je ne pep a mpaC dtoi&#34; ou encore &#34;slt le zami&#34; dans lequel des formes sont incorrectement segmentées.  Le système tel décrit ci-dessus (cf section 2) correspond à notre système baseline. Son lexique  contient de plus de 23000 mots. Nous avons également utilisé un dictionnaire de plus de 900 exceptions, ainsi qu'un ensemble de 140 règles de phonétisation contextuelles. Les contextes  p  /  p/ | /pe/ | /pE/ | si fin de mot, p  / p/ | /pe/ | /pE/ sinon  Comme dans un système de reconnaissance vocale, le lexique de l'application de normalisation  de SMS est fini. Avec le système baseline, les mots du hors-vocabulaire (HV) du SMS ne sont pas correctement traités. Dans la mesure où ils ne peuvent être restitués tels quels en sortie du système, ils sont resegmentés en mots phonétiquement proches : ainsi, &#34;puiske té a meyrarg&#34; (&#34;meyrarg&#34; est HV) produit &#34;puisque t' es a mis rare&#34; ). Pour y remédier, le module de prétraitement a été complété de façon à produire une hypothèse supplémentaire, correspondant à la recopie du mot HV dans la sortie : ces mots, qui sont potentiellement corrects, peuvent alors figurer dans la meilleure solution. La figure 3 détaille la façon dont sont gérés les mots HV dans le formalisme des FSMs, en l'illustrant sur la forme « meyrarg&#34;. Lors du pré-traitement, &#34;meyrarg&#34; est reconnu comme mot HV : deux chemins alternatifs sont alors créés. Le premier segmente l'entrée en graphèmes élémentaires, qui seront phonétisés. Le second chemin est identique, à l'insertion près d'une balise <HV>. Cette balise rend transparentes les étapes de phonétisation et d'accès au dictionnaire. La séquence graphémique figurera dans l'ensemble des hypothèses de séquences de mots et pourra être sélectionnée par le modèle de langage. Un post-traitement permet de retrouver le mot correspondant initialement à cette balise.  Une seconde amélioration concerne le traitement des heures et des nombres, très nombreux dans  le corpus des SMS ; initialement, les chiffres sont traités comme les autres graphèmes. Ainsi, un nombre à deux chiffres est systématiquement segmenté en deux chiffres distincts. Nous avons donc introduit des grammaires régulières, compilées sous la forme de transducteurs finis ; la composition avec le SMS prétraité fournit l'ensemble des analyses possibles des heures et des nombres. Lorsqu'une heure ou un nombre est reconnu, la balise associée est émise ; les étapes de traitement des exceptions, de phonétisation et d'accès au dictionnaire restent identiques. Le modèle de langage est appliqué au graphe de mots et de balises. Ce dernier est appris au préalable sur le même corpus d'apprentissage que précédemment, après étiquetage des nombres et des montants (la phrase 'Je viens à 20 h' devient 'Je viens à _HEU RE_' ). La figure 4 illustre, pour cette même entrée, la façon dont sont définies les grammaires locales pour les heures et les nombres dans le formalisme des transducteurs finis. Lors du pré-traitement, les formes sont segmentées en graphèmes élémentaires et mises sous la forme d'un automate. Les grammaires régulières décrivant les heures et les nombres sont également mises sous la forme d'un transducteur. La composition du SMS initial avec ce dernier permet de retrouver toutes les instances d'heures et de nombres dans le SMS initial (Figure 4). Une balise associée à chacune de ces grammaires est émise. Comme pour les mots hors-vocabulaire, ces balises sont transparentes aux étapes de phonétisation et d'accès au dictionnaire. Elles figureront alors dans l'ensemble des normalisations possibles et pourront être sélectionnées par le modèle de langage.  Le système baseline intègre un dictionnaire d'abréviations construit manuellement par analyse  de corpus. Dans cette section, nous décrivons une méthode permettant d'apprendre automatiquement les abréviations les plus fréquentes à partir d'un corpus d'apprentissage contenant d'une part, les SMS originaux, pré-traités (suppression de la ponctuation et des majuscules) et leur transcription d'autre part. Cette méthode est basée sur les alignements automatiques et l'extraction de segments bilingues utilisés dans les systèmes de traduction statistique.  Des alignements automatiques sont calculés pour le corpus d'apprentissage à l'aide du logiciel  GIZA++ (Och & Ney, 2003). La technique des refined alignments (Koehn et al., 2003) permet de déduire des alignements automatiques croisés une table de traduction, donnant pour chaque segment « source » (en langage SMS) l'ensemble des segments « cible » associés (en français standard). Pour les abréviations, nous ne conservons que les segments &#34;source&#34; constitués d'un seul mot et les segments &#34;cibles&#34; constitués d'au maximum 3 mots (par exemple, l'abréviation  &#34;jtm&#34; alignée avec la séquence &#34;je t'aime&#34; ). Un score, s(t, w) est enfin estimée pour chaque  segment t apparié avec w ; s(w) = max P (t|w) dénote alors le meilleur score d'un segment apparié avec w. Seuls les appariements dont la forme source est suffisamment fréquente (plus de 5 occurrences) et dont le score est supérieur à un certain ratio  (fixé ici à 0.1) du meilleur score ({t | s(t, w)  s(w)}) sont finalement conservés. Ont ainsi été extraites 3264 abréviations/exceptions nouvelles, auxquelles sont associées leurs meilleures expansions. Notons que toutes ces exceptions ne sont pas utiles car il est possible qu'une abréviation et le segment associé aient la même phonétisation. Les expériences utilisent deux corpus : le premier a été collecté par l'université d'Aix en Provence (Hocq, 2006; Guimier de Neef et al., 2007) ; il est constitué d'environ 9700 messages. Le second corpus est issu d'une collecte organisée en Belgique par l'Université Catholique de Louvain, et comprend 30000 messages (Fairon et al., 2006). Un corpus d'apprentissage App de 36704 SMS a été constitué en mélangeant les deux corpus. Les 2998 SMS restants nous ont servi de corpus de test Test. Le modèle de langage utilisé dans les évaluations est un modèle de langage 3-gram lissé en utilisant un lissage de type Kneser-Ney et estimé sur le corpus App.  Contrairement à (Aw et al., 2006; Guimier de Neef et al., 2007), qui évaluent leurs performances  en termes de mesure BLEU (Papineni et al., 2002), nous avons choisi d'évaluer nos systèmes en termes de taux d'erreurs mots ou WER (Word Error Rate), métrique qui est également utilisée en reconnaissance vocale. La mesure BLEU, qui s'appuie sur un décompte des n-grams présents dans l'hypothèse et dans une référence, ne vaut que lorsque plusieurs références sont disponibles, comme il est commun en traduction automatique. Pour notre problème, l'ambiguïté dans le choix de la transcription de référence est presque nulle justifiant le calcul de taux d'erreurs par mots et par phrases.  Le tableau 4.2 détaille les résultats obtenus et permet d'apprécier l'impact des améliorations  apportées au système. Le système baseline donne un WER de 19.79% ; la majorité des erreurs sont des erreurs de substitution, qui portent souvent sur des mots courts comme 'les'  'le', 'j"  'je', 'des'  'de', etc. Dans une majorité des cas, le mot est pourtant bien orthographié dans le SMS, mais l'étape de phonétisation réintroduit une ambiguïté que le modèle de langage ne parvient pas toujours à compenser. La deuxième ligne du tableau 4.2 montre l'apport du traitement des mots hors-vocabulaire, qui permet de diminuer principalement le nombre d'insertions ; en effet le système baseline avait tendance à segmenter les mots HV en plusieurs petits mots proches phonétiquement et donc à commettre plus d'insertions. Sur l'exemple de &#34;puisk té a meyrarg ...&#34;, le système baseline fournit &#34;puisque t'es à mes ir argh&#34;, sortie qui est corrigée par le traitement des mots HV.  L'utilisation des grammaires locales (pour les nombres et les heures) améliore globalement les  résultats en termes de WER ; moins d'erreurs sont commises sur les nombres. L'introduction  de ces grammaires améliore également la capacité de généralisation du modèle de langage. Cet  effort d'introduction de grammaires locales doit donc être poursuivi. Les deux dernières lignes  WER  Ins. Sub. Del. baseline 19.79% 4.76% 13.44% 1.59% Traitement des mots HV 18.13% 2.51% 12.83% 2.80% Utilisation de grammaires 17.58% 2.54% 12.68% 2.35% Abréviations automatiques 16.96% 2.56% 12.10% 2.30% Combinaison 16.51% 2.21% 11.94% 2.36%  du tableau 4.2 chiffrent l'apport de l'apprentissage automatique des exceptions par rapport à  l'utilisation d'abréviations collectées manuellement. Les performances sont améliorées significativement en termes de WER, démontrant la validité de l'approche proposée. Les résultats sont encore améliorés en combinant les deux dictionnaires d'abréviations.  Nous avons présenté, dans cet article, une nouvelle approche pour la normalisation des SMS,  basée sur un décodage phonétique. Les différentes évolutions ont permis d'améliorer sensiblement les performances du système baseline, qui sont probablement sous-estimées par la métrique WER : de nombreuses erreurs correspondent à des problèmes d'accord, que le modèle de langage échoue à corriger. Ces erreurs sont pourtant sans conséquence dans une perspective de vocalisation car elles correspondent le plus souvent à la perte ou à l'ajout d'un morphème flexionnel « muet ». Ces erreurs sont également bénignes dans une optique d'indexation automatique.  Le système actuel peut toutefois être amélioré de multiples façons :  - les SMS contiennent de nombreuses formes qui sont correctement orthographiées : après phonétisation, cette information est perdue. Une approche qui semble meilleure consiste à chercher celles qui existent dans le dictionnaire D et à les phonétiser par accès direct ; il faudra ensuite exprimer, par des pondérations, que l'on préfère utiliser une suite phonémique extraite du dictionnaire plutôt qu'une suite produite par des règles. - les règles de conversion graphème-phonème (module E) sont exagérément libérales. Si le non-déterminisme doit être préservé, il importerait de le modérer en pondérant les différentes sorties des règles de récriture : s'il est correct d'autoriser la lettre 'é ' à valoir / e/ ou /E/, il est probable que l'on gagnerait à rendre une des deux options plus probable que l'autre. - nous avons pour l'instant supprimé toute information liée à la ponctuation, aux majuscules ; cette information pourrait nous être utile pour segmenter le SMS et ainsi améliorer le pouvoir prédictif du modèle de langage.  Les auteurs remercient Émilie Guimier de Neef (Orange Labs) pour avoir mis à disposition la  liste d'abréviations ainsi que les différents corpus.  
