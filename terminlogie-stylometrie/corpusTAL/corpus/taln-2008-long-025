Dans cet article, nous proposons une méthode permettant d'enrichir les résultats obtenus par   un système de détection automatique d'entités nommées en utilisant les relations syntaxiques  qui leur sont associées par un analyseur syntaxique robuste, XIP (Xerox Incremental Parser),  et en vérifiant les types sémantiques des arguments en relation syntaxique à l'aide de la  ressource ontologique WordNet (Fellbaum, 1998). L'utilisation de relations syntaxiques pour  raffiner la tâche de détection d'EN n'est pas nouvelle, voir par exemple (Ehrmann et Jacquet,  2006) ou (Brun et Hagège, 2004). De même, l'utilisation de WordNet dans le cadre de la  détection d'EN est décrite dans plusieurs travaux, comme par exemple dans (Magnini et al.,  2002). Les travaux de (Benetti et al., 2006) montrent aussi l'enrichissement d'un système de  reconnaissance d'EN grâce à l'utilisation de Wikipedia. La nouveauté de notre méthode est de  coupler information syntaxique et information sémantique sur les résultats de cette analyse  syntaxique fine. Cela va nous permettre non seulement de valider ou d'invalider les résultats  préalablement fournis par le système de détection d'EN, mais aussi de considérer de  nouveaux types sémantiques via WordNet et de les associer à des noms propres non typés par  le système initial, créant ainsi de nouvelles catégories d'entités nommées.    Après avoir présenté l'analyseur syntaxique robuste XIP, ainsi que le système de détection   d'EN, basé également sur XIP, nous décrivons en détail cette méthode et son implantation.  Puis, nous donnons les résultats de différentes expérimentations réalisées avec le prototype  que nous avons développé. Enfin, nous tirons les conclusions  relatives à cette méthode.    La détection d'entités nommées fait l'objet d'un intérêt certain pour le TALN (voir les   conférences MUC http://www.itl.nist.gov/iaui/894.02/related_projects/muc/, les campagnes  ACE http://www.nist.gov/speech/tests/ace/, ESTER, etc.), en particulier pour la tâche  d'extraction d'information, mais aussi pour beaucoup d'autres applications spécifiques. De  nombreux systèmes, symboliques ou statistiques, détectent et catégorisent les NE avec de  bonnes performances (environ 90 de f-mesure).  Cependant, certaines applications requièrent  plus de précision et la méthode que nous proposons vise à améliorer a posteriori les résultats  d'en système d'extraction d'EN.       XIP (Ait-Mokhtar  et al., 2002) est un analyseur dont l'objectif est d'extraire des dépendances   syntaxiques de façon robuste. Cet analyseur accepte en entrée n'importe quel document ou  partie de document au format texte ou XML et produit en sortie une représentation  grammaticale du contenu de ce document.    Le formalisme proposé par XIP nous permet d'exprimer un large éventail de règles qui vont   de la désambiguïsation catégorielle à la construction de dépendances, en passant par la  constitution de syntagmes noyaux : XIP permet de relier par des relations des éléments  linguistiques qui peuvent être des éléments lexicaux, mais aussi des éléments non lexicaux  correspondant à des syntagmes noyaux.   Dans le cadre du travail présenté dans cet article, nous utilisons la version la plus complète de   la grammaire de l'anglais développée au sein de XIP, que nous désignons par grammaire «de   normalisation ». Cette grammaire est construite sur la base des résultats obtenus lors de  l'analyse grammaticale générale de l'anglais.    Grammaire générale : La grammaire générale de l'anglais permet le « chunking » (analyse   en syntagmes noyaux) et réalise une extraction des dépendances standards (Sujet, Objet,  modifieurs, attributs etc.).    A titre d'exemple, voici une phrase analysée par cette grammaire :    Analyse par XIP (grammaire générale):    Grammaire de normalisation  (Hagège, Roux, 2003):  Une couche supplémentaire de  développement a été rajoutée à cette grammaire de base, l'objectif applicatif visé étant  l'extraction d'information. Ces développements permettent d'avoir, après l'analyse, une  représentation commune pour des suites de signifiants qui ne sont pas identiques mais qui  véhiculent une information similaire. A l'heure actuelle, ce travail de normalisation s'effectue  selon trois axes :        L'exploitation des relations syntaxiques mises en évidence lors de l'analyse générale :  L'analyse par la grammaire générale est tout d'abord raffinée afin de considérer les  sujets et objets de verbes non finis et les antécédents des relatives dans le calcul du  sujet et de l'objet, de normaliser la forme passive en forme active et de typer certains  compléments. Ensuite, certaines alternances verbales telles qu'elles sont définies dans  (Levin,  93)  sont exploitées.       La hiérarchisation des propositions dans une phrase : la grammaire normalisée permet  de reconnaître les degrés d'enchâssements des verbes par rapport au verbe principal.        L'exploitation d'information de morphologie dérivationnelle : cette information permet  d'exprimer des équivalences entre verbe-compléments et nom-arguments.   L'analyse de la phrase précédente avec cette version de la grammaire donne alors :    Analyse par XIP (grammaire normalisée):   Nous pouvons remarquer dans l'analyse effectuée par la grammaire de normalisation qu'une  relation de type « sujet normalisé » (SUBJ-N) est établie entre le verbe « succeed » et  « McMurphy » (à partir de la suite « McMurphy was successful »). L'identification de  l'antécédent de la relative ainsi que la normalisation entre forme passive et forme active  permettent d'extraire une relation « sujet normalisé » entre le verbe « impose » et « Nurse  Ratched » et une relation « objet normalisé » entre ce même verbe et le nom « rule ». Enfin,  une relation « sujet normalisé » est également extraite entre le verbe « change » et le nom  « McMurphy ».    C'est cette version de la grammaire que nous avons utilisée dans pour construire le prototype  de validation et découverte d'EN.     Un système de détection des EN a été développé au sein de l'analyseur XIP. Il permet de   détecter les types « standards » d'entités nommées à savoir : dates, pourcentages, monnaies,   lieux, personnes, organisations. Il s'agit d'un système à base de règles, consistant en un  ensemble de règles locales qui utilisent de l'information lexicale combinée à de l'information  contextuelle sur les catégories syntaxiques. Ces règles locales sont très similaires à des règles  de « chunking »  (identification des syntagmes noyaux), sauf qu'elles opèrent au niveau du  nom.    Voici un exemple d'analyse  :   Margaret Sinclair Trudeau, born September 10, 1948 in Vancouver, British Columbia,   Canada, was the wife of the late Canadian Prime Minister Pierre Trudeau. The daughter of  James Sinclair, a former Liberal member of the Parliament of Canada and fisheries minister,  she attended Simon Fraser University where she obtained a degree in English literature.   PERSON(Margaret Sinclair Trudeau)   DATE(September 10 , 1948)  LOC_CITY(Vancouver)  LOC_REGION(British Columbia)  LOC_COUNTRY(Canada)  PERSON(Canadian Prime Minister  Pierre Trudeau)  PERSON(James Sinclair)  ORGANISATION(Parliament of Canada)  ORGANISATION(Simon Fraser University)     Le système a été évalué  en interne, sur un corpus de dépêches d'environ 87000 mots,  et  montre une f-mesure de 90 tous types d'entités confondus (Erhmann 2004). Ce système de  détection des entités nommées est intégré aux différentes grammaires présentées dans le  paragraphe précédent.  La validation et découverte d'EN se fait sur la base des résultats  obtenus par ce système initial.                                                        La première étape réalisée par notre prototype est de détecter les entités nommées ainsi que   les entités potentielles non étiquetées sémantiquement (noms propres) à l'aide du système  présenté au paragraphe 2.3.  Notre système va considérer comme nom propre, toute suite de  mots (éventuellement non reconnus par l'analyseur lexical) présentant des particularités  typographiques comme une majuscule initiale et ne rentrant dans aucune des catégories  d'entités nommées reconnues par le système.   Nous appliquons ensuite sur le même texte la grammaire normalisée. Cette grammaire   normalisée a pour particularité d'extraire une relation que nous désignons par relation  attributive. Une relation attributive relie des suites de caractères lorsque des indicateurs  textuels et des constructions syntaxiques permettent d'affirmer qu'ils entretiennent une  relation de type IS-A   Les exemples suivants illustrent la notion de relation attributive telle que nous l'entendons.    (1) John Smith was an inventor.      (2) John Smith, the inventor, made a presentation.     (3) John Smith is expected to be an inventor.     (4) They consider John Smith an inventor.    (5) The inventor John Smith was awarded.    (6) An inventor called John Smith was awarded.    (7) John Smith, who is a great inventor, was awarded.    (8) John Smith, as the inventor of the process, was awarded.    Dans tous ces exemples, "John Smith" est en relation attributive avec "inventor".    A titre d'exemple, l'analyse donnée par XIP pour la phrase (5), en utilisant la grammaire de   normalisation,  est la suivante :    SUBJ-N_PRE(consider,They)   PREPD(inventor,as)  PERSON(John Smith)  OBJ-N(consider,Smith)  ATTRIB(John Smith,inventor)       Nous nous intéresserons uniquement aux relations attributives mettant en jeu les entités   nommées et nom propres extraites à l'aide de XIP : elles correspondent à une relation de type  IS-A du point de vue sémantique, et vont ainsi nous permettre de typer sémantiquement les  EN.    Nous utilisons l'information sémantique fournie par la base de données lexicale WordNet    (Fellbaum 1998), en particulier les classes sémantiques de plus haut niveau associées aux  synsets.     Une fois les relations attributives extraites entre entités et attribut nominal, le système utilise   WordNet pour associer un type sémantique à l'attribut nominal. Pour ce faire, nous avons  extrait de WordNet tous les noms dont le « super type » (person, artifact, substance, etc.) n'est  pas ambigu, par exemple :   Girl [5 sens]   noun.person     Ship [1 sens]   noun.artifact  Drug [1 sens]   noun.artifact   Liquidation [3 sens]   noun.act     En résulte un vocabulaire de 44406 noms accompagnés de leur « super type » sémantique qui  est intégré à des lexiques au sein de XIP.  Un appariement entre « super type » sémantique de  WordNet et type d'entités nommées reconnues par le système initial est également effectué  (par exemple le type WordNet « person » correspond au type « PERSON » de notre système  de reconnaissance de EN.    Le schéma suivant décrit l'architecture du prototype que nous avons développé :        Le résultat de la confrontation entre entité nommée ou nom propre extraits par le système   initial et type sémantique de l'attribut nominal selon WordNet peut produire les cas de figures  suivants :                                                       1) Conflit de type    Dans ce cas, le système initial a associé à une EN un certain type sémantique qui n'est pas   compatible avec le type que WordNet assigne à l'attribut de cette entité, comme par exemple  dans la phrase (où l'EN est indiquée en gras) :   The warship is called the Armando Diaz    Le type de l'EN extrait par le système initial est « PERSON » alors que le type de « warship »   selon WordNet est « artifact ». Ces deux types sont contradictoires.   2) Confirmation de type    C'est le cas pour lequel le type de l'entité nommée est compatible avec le type WordNet de   son attribut. Dans ce cas, il s'agit d'une information supplémentaire qui vient confirmer le  choix du système initial, comme par exemple dans :    If one man has done more than any other to keep Old Labour behind Tony Blair it is surely   his deputy, John Prescott.   Une relation attributive est détectée entre « deputy »  et  « John  Prescott »,  préalablement   identifié comme nom de personne par le système initial. Selon WordNet, « deputy »,  n'appartient qu'au « super type » « person ». Les deux types sont parfaitement compatibles,  donc le système confirme le type de l'entité.    3) Découverte d'un nouveau type    Ce cas s'applique uniquement aux noms propres non typés extraits par le système initial.   Grâce à l'association d'un attribut à ce nom propre, et au typage par WordNet de cet attribut,  nous pouvons proposer d'attribuer ce type sémantique WordNet au nom propre. Par exemple  dans la phrase suivante :   Activia is yogurt, but not just any yogurt.     "Activia" n'est pas détecté comme une EN par le système initial de XIP. Il est cependant en   relation attributive avec le nom « yogurt », dont le super type dans WordNet est « food ». Le  système associe donc la nouvelle étiquette sémantique « food » à « Activia ».    Le corpus général, de 5500 mots, est constitué d'un ensemble de dépêches de provenance   diverse (Herald Tribune, The Guardian, The Observer, The New York Times) ainsi que de  quelques courtes biographies. Le système initial de reconnaissance d'EN détecte 7441 entités  nommées.   L'application postérieure de notre méthode nous permet de considérer 115 entités, parmi   lesquelles 78 sont des compatibilités entre types, 19 sont des découvertes de nouveau type, 18  sont des conflits ;   Compatibilité :    Seuls des entités de type PERSON et ORGANISATION sont concernées. Les 78 cas de   compatibilités extraites sont justes, comme par exemple pour la phrase suivante :   The Democratic challenger, John Kerry, has called on the White House to turn words into   action.    John Kerry a été détecté comme EN de type personne par le système général ("John" étant  une suite codée comme prénom dans le lexique). Cela est confirmé dans un deuxième temps  grâce à l'identification du lien attributif entre "John Kerry" et "challenger" qui lui-même est  considéré comme de type personne par WordNet.    Découverte :    Les types découverts et proposés par le biais de WordNet dans ce texte sont les types   COMMUNICATION et ARTIFACT, comme par exemple dans :     For Tom Hanks, it's his maiden voyage to Cannes where he will be publicising the Coen  brothers ' remake of the classic British comedy The Ladykillers.  ENTITE(Cannes)  ENTITE(Ladykillers)  PERSON(Tom Hanks)  PERSON(Coen)  LOCORG_CITY(Cannes)  ATTRIB(Ladykillers,comedy)  DISCOVERY_WN_COMMUNICATION(Lady killers)   "Ladykillers" qui avait simplement été repérée comme nom propre par le système général, se  voit attribuer le type "COMMUNICATION" grâce à la relation attributive qu'il entretient  avec le nom "comedy".    Sur les 19 entités découvertes, 5 sont erronées et 14 sont correctes. Les erreurs sont dues a des  erreurs de détection de la relation attributive provenant en général d'une erreur dans la  détection de la tête d'un groupe nominal complexe. Cette erreur de détection de la tête est à  son tour souvent liée à des erreurs de désambiguisation de la partie du discours.    On peut remarquer que le faible nombre d'entités découvertes s'explique par le fait que le   corpus traité est en harmonie avec le type d'entités que le système général prévoit (langue  générale, presse).   Conflit :    Nous obtenons pour ce corpus 17 cas de conflit. Il est intéressant de noter que parmi ces   conflits, certains relèvent de cas d'emploi métonymique des entités nommées, comme par  exemple dans la phrase suivante :   While Schröder was saying that D-Day signaled the starting point for today's new Europe   and maintained that the EU was the best guarantor of peace in Europe,...   Une relation attributive entre l'entité nommée « EU » et le nom « guarantor » est extraite. Le   système de base de détection des EN indique que « EU » est de type ORG. Par le biais de  notre méthode, dans la mesure où le nom « guarantor » est de type PERSON, nous obtenons  un conflit de type.    Or, dans le cas présent, c'est bien un usage métonymique de l'entité « EU » dont il s'agit dans   cette phrase, même si par nature, « EU » correspond à un lieu ou à une organisation.   Parmi les 18 cas de conflit, nous obtenons  6 cas de conflits liés à des usages métonymiques   des entités nommées détectées. Nous pouvons donc considérer que ces 6 cas sont pertinents.  Nous obtenons également 3 cas pertinents de conflits pour lesquels le système initial de  détection des EN a fait des erreurs que nous pouvons corriger grâce à notre méthode.   Enfin, les 8 cas restants sont des détections de conflit erronées, ces erreurs étant   essentiellement liées, comme pour les erreurs de découverte à des erreurs d'analyse  syntaxique et de désambiguïsation.   Nous avons également testé notre méthode sur un corpus   spécialisé de biologie, d'environ  92000 mots (il s'agit de 422 articles extraits de pubmed). Nous nous sommes intéressées aux  noms de gènes, annotés dans ce corpus, et qui correspondent aux  classes sémantiques  « BODY »  et « SUBSTANCE» de Wordnet. Sur ce corpus, le système « découvre » 505  noms de gènes, et détecte 8 cas de conflits avec le système initial.  Voici une illustration de  ces résultats :   (1)    Structural basis of multidrug recognition by BmrR, a transcription activator of a  multidrug transporter.    Le nom propre « Bmr» est découvert comme une entité de type « Substance » (gène)  par  notre système car l'attribut « activator» appartient à la classe noun.substance dans WordNet.    (2) ADP is an inhibitor of the phosphorylation by ATP.    Ici, un conflit est détecté car le système initial de reconnaissance considère ADP comme une  organisation  (ADP= Aéroport de Paris), alors que notre système lui associe le type  SUBSTANCE.    Les 8 cas de conflits détectés sont tous corrects, c'est-à-dire que le système initial donne une   annotation erronée pour un nom de gène.   Concernant les noms de gènes découverts,  l'évaluation sur ce corpus donne 85% de précision et 6,6 % de rappel.    Nous obtenons donc une très bonne précision pour un rappel faible, ce dernier point étant   assez prévisible car le système n'utilise que des relations attributives pour détecter les EN. A  titre d'information, 1900 relations attributives sont détectées sur l'ensemble du corpus.                                                         La méthode que nous présentons permet d'améliorer les résultats d'un système de   reconnaissance d'entités nommées en validant ou invalidant les résultats produits par ce  système et permet également de proposer de nouveaux types d'entités nommées pour des  noms propres détectés mais non typés par le système. La méthode utilise les résultats d'une  analyse syntaxique fine permettant d'extraire des relations de type IS-A entre noms propres et  entités reconnues par le système initial et d'autres noms communs catégorisés  sémantiquement par la ressource WordNet.   Les tests effectués sur les corpus montrent que l'apport de notre méthode est très variable   selon le type de corpus sur lequel on travaille. Dans le cas de textes appartenant à un domaine  particulier, c'est l'aspect découverte de nouvelles entités dont les types n'ont pas été  préalablement prédéfinis qui semble le plus intéressant. En effet, même si la couverture reste  basse elle peut constituer une amorce fiable pour des systèmes d'apprentissage. Dans le cas de  textes généraux pour lesquels  les types d'entités nommées prédéfinis sont couvrants, c'est  l'aspect confirmation qui semble le plus prometteur.    
