Dans cet article, nous décrivons la méthode que nous avons développée pour la  résolution de métonymie des entités nommées dans le cadre de la compétition SemEval 2007. Afin de résoudre les métonymies sur les noms de lieux et noms d'organisation, tel que requis pour cette tâche, nous avons mis au point un système hybride basé sur l'utilisation d'un analyseur syntaxique robuste combiné avec une méthode d'analyse distributionnelle. Nous décrivons cette méthode ainsi que les résultats obtenus par le système dans le cadre de la compétition SemEval 2007. In this paper, we describe the method we develop in order to solve Named entity metonymy in the framework of the SemEval 2007 competition. In order to perform Named Entity metonymy resolution on location names and company names, as required for this task, we developed a hybrid system based on the use of a robust parser that extracts deep syntactic relations combined with a non supervised distributional approach, also relying on the relations extracted by the parser. We describe this methodology as well as the results obtained at SemEval 2007 Entités Nommées, métonymie, méthode hybride, analyse syntaxique robuste, approche distributionnelle. Named Entities, metonymy, hybrid method, robust parsing, distributional approach. Le traitement des entités nommées fait aujourd'hui figure d'incontournable en Traitement Automatique des Langues (TAL). Apparue au milieu des années 1990 à la faveur des dernières conférences MUC (Message Understanding Conferences, (MUC, 1995) et (MUC, 1998)), la tâche de reconnaissance et de catégorisation des noms de personnes, de lieux, d'organisations, etc. apparaît en effet comme fondamentale pour diverses applications participant de l'analyse de contenu et nombreux sont les travaux se consacrant à sa mise en oeuvre, obtenant des résultats plus qu'honorables (F-mesure dépassant généralement 0.9), et ce pour diverses langues. Fort de ce succès, le traitement des entités nommées s'oriente désormais vers de nouvelles perspectives avec, entre autres, la catégorisation fine (Ehrmann & Jacquet, 2006), la normalisation et la désambiguïsation. En effet, à l'instar des autres unités lexicales, plusieurs phénomènes de glissement ou de superposition de sens peuvent avoir lieu au regard des entités nommées et il importe de pouvoir les résoudre afin de traiter au mieux ces unités. Nous nous intéressons plus particulièrement à la métonymie des entités nommées et présentons dans cet article une méthode hybride pour la résolution de ce type particulier de polysémie.  La première section reviendra tout d'abord sur la définition et la caractérisation de la métonymie  des entités nommées. La suivante présentera rapidement la campagne d'évaluation SemEval (Semantic Evaluation), dans le cadre de laquelle les travaux ici présentés ont été réalisés et évalués, puis la troisème section s'attachera à décrire le système mis au point. Enfin, la dernière section rendra compte de l'évaluation.  La métonymie correspond au fait d'employer un mot (par exemple, le mot récolte) attaché à  une certaine entité (l'action de récolter) pour en désigner une autre (les produits recueillis), la seconde étant liée à la première par une relation de type partie-tout ou une relation fonctionnelle (ici relation de cause à effet). Si la métonymie permet un nombre indéfini de glissements de sens, il existe néanmoins des changements de sens réguliers ou systématiques, au regard notamment des entités nommées. Examinons les exemples suivants :  La politique américaine est plombée par l'Irak.  La France a gagné en demi-finale. Dans la première phrase, il n'est bien sûr pas question du pays proprement dit mais de l'événement qui s'y déroule, tout comme dans la seconde ou il s'agit non pas de la France en tant que telle mais d'une équipe sportive française. Cet usage des unités Irak et France en tant qu'événement et équipe sportive respectivement est possible pour d'autres noms de pays dans des situations similaires. Il existe bien d'autres exemples possibles, sur lesquels nous reviendrons par la suite, mais il est d'ores et déjà possible de postuler une certaine régularité et productivité des phénomènes de métonymie pour les entités nommées.  Outre ces caractéristiques, des études conduites par K. Markert, U. Hahn et M. Nissim (Markert  & Hahn, 2002), (Markert & Nissim, 2006) ont fait état de la fréquence de ce phénomène, montrant que 17% de l'ensemble des occurrences dans un corpus de 27 magazines allemands étaient  métonymiques, tout comme 20% des occurrences des noms de pays et 30% de celles des noms  d'organisation sur des extraits significatifs du British National Corpus. Régulière, productive et fréquente, la métonymie des entités nommées constitue ainsi un réel intérêt pour le traitement automatique des langues.  La campagne SemEval2007 proposait 18 tâches d'évaluations autour de problèmes sémantiques  tels que la désambiguïsation de prépositions, l'annotation d'expressions et de relations temporelles (TempEval) ou encore la désambiguïsation des noms de personne sur le web (Web People Search ). La tâche proposée par K. Markert et M. Nissim est une tâche lexicale sur l'anglais, portant plus précisément sur la résolution de métonymie pour deux classes sémantiques, la classe avec des noms de lieux et la classe avec des noms d'entreprises. L'objectif pour les participants est de classer automatiquement des occurences pré-sélectionnées et en contexte de noms de lieux et d'entreprises, et ce en fonction de leur interprétation litérale ou non-litérale. Cette première alternative correspond à l'annotation " gros grain " ou coarsegrained annotation . Deux autres niveaux d'annotation sont possibles : un niveau " moyen " (medium ) pour lequel il faut faire la distinction entre des interprétations litérales, métonymiques et mixtes et, enfin, un niveau " fin " (fine), pour lequel il importe de préciser, en cas d'interprétation métonymique, le patron métonymique dont il est question. À titre d'illustration, nous pouvons reprendre les exemples donnés par les organisatrices dans le document décrivant la tâche (Markert & Nissim, 2007) :  At the time of  Vietnam, increased spending led to inflation. BMW slipped 4p to 31p. The BMW slowed down.  Pour la première phrase, le nom Vietnam ne renvoie pas au pays mais à la guerre qui s'y est  déroulée, il convient donc d'annoter cette entité comme non-literal (niveau 1), comme metonymic (niveau 2) ou comme place-for-event (niveau 3). De même, les occurrences de BMW dans les exemples suivants ne renvoient pas à l'entreprise mais à l'action de l'entreprise pour la première (org-for-index) et au produit de cette entreprise pour la seconde (org-for-product). Les trois niveaux d'annotation pour les noms d'entreprise et pour les noms de pays sont représentés ci-après dans le tableau 1 .  Notre participation à la tâche de résolution de métonymie pour les noms de pays et d'entreprises  (Brun et al., 2007) a consisté en l'élaboration d'un système automatique hybride reposant sur la combinaison d'un composant symbolique et d'un composant distributionnel. Nous présenterons successivement ces deux composants.  Catégorie :  coarse medium fine  Catégorie :  coarse medium fine  Analyse syntaxique robuste avec XIP  L'élément fondamental sur lequel repose notre approche est l'analyseur syntaxique robuste (Aït-Mokhtar & Chanod, 1997), (Aït-Mokhtar et al. , 2002). Xerox Incremental Parser prend en entrée du texte tout venant et produit en sortie de façon robuste une analyse syntaxique profonde. À partir d'un ensemble de règles, l'analyseur est capable de faire de la désambiguïsation de catégories, de construire des syntagmes noyaux et d'extraire des relations de dépendances syntaxiques entre unités lexicales simples et/ou complexes. En plus de l'analyse des relations syntaxiques de surface, effectue également une analyse syntaxique dite " profonde " ou " normalisée " (prise en compte des sujets et objets de verbes non finis, normalisation de la forme passive en forme active, etc (Hagège & Roux, 2003)), l'exploitation d'information de sémantique lexicale, avec les classes verbales de Levin (Levin, 1993) et quelques éléments de Framenet (Ruppenhofer et al., 2006). Ci-dessous un exemple de sortie (avec l'arbre des chunks et les relations de dépendance) pour la phrase suivante :  Iran wanted the two centers to generate part of its electricity needs.   L'analyseur décrit ci-dessus contient déjà un module de reconnaissance d'entités nommées  (Brun & Hagège, 2004), mais ce dernier ne permet pas le traitement de la métonymie ; il a fallu procéder à son adaptation.  Adaptation à la tâche de résolution de métonymie  Pour ce faire, nous avons étudié les corpus d'entraînement à l'aide de , en tenant compte des directives d'annotation. Pour les noms de pays et d'entreprises, notre attention s'est focalisée sur les types de relations grammaticales dans lesquelles étaient impliquées les unités à étudier et sur les informations lexicales ou sémantiques attachées aux arguments de ces relations. Pour chaque patron métonymique, nous avons donc analysé l'ensemble de ses occurrences (attachées à une unité lexicale) dans le corpus d'entraînement pour dégager des configurations grammaticales et lexicales jouant le rôle d' " amorces " d'interprétations métonymiques. Au terme de cette étude de corpus, il fut possible de prendre en compte l'ensemble des indices récoltés et d'élaborer un module de résolution de métonymie dans . Intervenant à la fin de la chaîne de traitements de l'analyseur, cette adaptation consiste en l'écriture de règles traduisant les configurations discriminantes relevées pour tel ou tel patron d'une part, et à l'ajout de lexique d'autre part. À titre d'exemple, prenons l'hypothèse suivante : " Si un nom de pays est sujet d'un verbe renvoyant à une action économique, alors le patron loc-for-people doit s'appliquer " ; cette hypothèse se retrouve dans sous la forme de règle :  if  ( (#1) & (#2[v_econ],#1)) (#1)  Règle qui se lit ainsi : si le parseur a détecté un nom de pays (#1) qui est le sujet d'un verbe (#2)  portant le trait " v_econ ", alors il créée un relation unaire pour le nom de pays. En sus des indices récoltés lors de l'étude de corpus, nous avons exploité des informations lexicales déjà codées dans , comme par exemple les traits attachés aux verbes de communication (say, deny, comment) et les catégories relevant du cadre " experiencer " de Framenet, à savoir des verbes tels que feel, sense, see, les noms despair, compassion, adoration ou les adjectifs synpathetic, sad, etc. En effet, eu égard au fait que ce cadre " experiencer " renvoie à des personnes ou à des groupes de personnes, dès lors qu'un nom de pays ou d'entreprise a ce rôle, il peut être annoté en tant que loc-for-people ou organisation-for-members. Ci-dessous un exemple de sortie de l'analyseur avec le nouveau développement : It was the largest Fiat everyone had ever seen .  Dans cet exemple, la présence de la relation  entre le nom d'entreprise Fiat et l'adjectif largest, renforcée par la présence d'un article défini, conduit à l'annotation en tant que _ _ . Ce composant symbolique constitue le premier volet de notre méthode de résolution de métonymie, il est complété par un composant distributionnel, qu'il convient à présent de détailler. Intervient en " deuxième passe " de notre système, un composant distributionnel. L'idée principale de cette combinaison est d'exploiter deux méthodes relevant d'approches différentes mais complémentaires, autrement dit de pallier les manquements de l'analyse symbolique, focalisée sur des données précises nécessitant une étude minutieuse, par une analyse distributionnelle, apte à récolter des informations à grande échelle sur d'importantes données textuelles. Le principe est donc, lorsqu'une unité n'a pu être traitée par le composant symbolique, d'essayer de trouver son annotation en exploitant les informations présentes à propos de cette unité ou d'une unité de même type dans un grand corpus. Nous présentons rapidement l'analyse distributionnelle avant de détailler sa mise en oeuvre pour la résolution de métonymie.  L'analyse distributionnelle  La notion d'analyse distributionnelle a été introduite par Z. S. Harris. En linguistique de corpus, cette méthode est aujourd'hui largement exploitée, notamment dans les travaux de terminologie, de structuration de terminologie et de construction d'ontologies (Faure & Nedellec, 1999) (Assadi, 1998) (Bourigault, 2002). L'hypothèse est la suivante : il serait possible, à partir de régularités syntaxiques observées pour un ensemble de mots, de déduire des propriétés sémantiques pour ces mots. Concrètement, il s'agit d'étudier la distribution des mots, c'est à dire les contextes lexico-syntaxiques dans lesquels ils apparaissent, pour ensuite tenter de dégager des parentés sémantiques. S'inscrivant dans ce cadre, G. Jacquet et F. Venant ont élaboré une méthode automatique de désambiguïsation du sens d'un mot en contexte, reposant sur la prise en compte de l'influence des éléments syntaxiques et lexicaux présents dans l'énoncé (Jacquet & Venant, 2003). Ainsi, il ne cherchent plus seulement à créer des classes de mots relevant du même champ sémantique " mais des classes de mots dont le comportement sémantique influence de la même façon un contexte donné ". Le composant distributionnel élaboré pour la résolution de métonymie s'inscrit dans la perspective de ces travaux.  Méthode distributionnelle pour la résolution de métonymie  L'objectif ici est de rapprocher des contextes et d'exploiter les résultats du composant symbolique. Cette méthode comporte deux processus. Il s'agit d'une part de construire un espace distributionnel pour être en mesure de rapprocher des contextes en fonction d'une entité donnée et, d'autre part, de capitaliser l'information du composant symbolique sous la forme d'une sorte de " base de donnée " de contextes avec annotation. Nous détaillons ces deux processus successivement. Construction de l'espace distributionnel et rapprochement des contextes Ce premier processus comporte 5 étapes. Le point de départ est le corpus dans son entier (100 millions de mots), duquel on été extraits les corpus d'entraînement et de test de la tâche de résolution de métonymie.  La première étape correspond à l'analyse syntaxique de ce corpus (à l'aide de l'analyseur  ) afin d'en extraire des dépendances syntaxiques. C'est à partir de ces dépendances que sont construits les contextes et les unités lexicales. Prenons un exemple, avec la proposition provide Albania with food aid . Les dépendances extraites par sont les suivantes :  Où l'on peut voir que les arguments des dépendances sont de simples unités lexicales (aid) ou  des syntagmes (food aid).  La deuxième étape de ce processus est la construction d'un espace distributionnel à partir de  ces dépendances. Cet espace distributionnel est l'inverse de celui habituellement construit en analyse distributionnelle : puisque l'objectif est de rapprocher des contextes, chaque point de l'espace est une contexte syntaxique et chaque dimension est une unité lexicale. Cet inversion constitue une première différence avec l'approche de G. Jacquet et F. Venant (Jacquet & Venant, 2003). Chaque dépendance obtenue lors de l'étape précédente permet de construire plusieurs contextes simples et/ou composés. Un contexte syntaxique comporte une relation et une unité lexicale. La méthode prévoit également de construire des contextes composés (autre différence par rapport à (Jacquet & Venant, 2003)), soit des contextes combinant plusieurs contextes, dont le premier comporte nécessairement un syntagme verbal et le second a pour recteur ce même syntagme. Pour la phrase analysée ci-dessus, les unités lexicales, les contextes simples (1. pour recteur et 2. pour régi) et les contextes composés sont les suivants :  Unités lexicales  Contextes simples Contextes composés  Une heuristique permet de filtrer ces données en fonction de leur productivité : chaque unité  lexicale doit être présente au moins 100 fois dans le corpus, tout comme les contextes (y compris les contextes composés). Avec le corpus de 100 millions de mots, on obtient au final 60 849 unités lexicales et 140 634 contextes. Il est donc possible de construire un espace distributionnel comportant 140 634 points (les contextes) et 60 849 dimensions (les unités lexicales). Cet espace est le matériau de base à partir duquel les autres traitements viennent s'effectuer.  À partir de la troisième étape intervient la prise en compte d'une unité lexicale précise, pour  laquelle le composant symbolique n'a pu trouver d'annotation. En fonction de cette unité et de son contexte d'apparition (soit telle qu'elle apparaît dans un extrait de SemEval), il s'agit tout d'abord de construire un sous-espace, de la manière suivante :  Pour un couple donné formé d'un contexte i et d'une unité lexicale j :  - Le sous-espace des contextes équivaut à la liste des contextes occurrant avec l'unité lexicale j . S'il y a plus de k contextes, alors on ne garde que ces k contextes les plus fréquents ; - Le sous-espace des dimensions équivaut à la liste des unités lexicales occurrant avec au moins un des contextes du sous-espace des contextes. S'il y a plus de n unités, alors on ne garde que ces n unités les plus fréquentes.  La quatrième étape consiste à réduire les dimensions de ce sous-espace, à l'aide d'une analyse  factorielle des correspondances (AFC ; équivaut à une ACP avec la métrique du Chi2).  Enfin, la cinquième étape consiste à rapprocher les contextes restants, c'est à dire ayant passés  le filtre des deux étapes précédentes. Ce rapprochement est calculé à l'aide de la distance euclidienne. On obtient ainsi, au final, une liste des contextes proches de celui de l'unité considérée.  Pour l'unité Albania dans le contexte provide, les contextes les plus proches sont présentés dans  la première colonne du tableau 2.  Pour pouvoir utiliser cette liste de contextes, encore faut-il savoir s'ils ont reçu ou non une  annotation par le composant symbolique. Intervient alors le second processus. Capitalisation de l'information du composant symbolique Ce second processus a pour objectif de construire une sorte de base de données de contextes avec annotations. Deux étapes sont nécessaires. Le corpus est analysé avec , augmenté cette fois-ci du module de résolution de métonymie. Cette analyse permet d'obtenir des dépendances syntaxiques mettant en jeu des noms de pays et des noms d'entreprise avec leurs annotation métonymique (application du module de résolution de métonymie sur les entités nommées reconnues par l'analyseur, indépendamment des données de SemEval). Le résultat de cette première étape est donc une série de contextes impliquant des unités lexicales avec leur annotation. La deuxième étape correspond à la sélection de contextes discriminants au regard des annotations. Par exemple, si le contexte :allow. se retrouve pour 10% des cas avec une unité comportant l'annotation literal et pour 90% des autres avec une unité comportant l'annotation loc-for-people, alors le contexte est considéré comme discriminant vis-à-vis de cette dernière annotation. En revanche, si un contexte se trouve dans 50% des cas avec telle annotation et 50% des cas avec telle autre, alors il n'est pas conservé. À l'issue de cette sélection de contextes discriminants, on dispose alors d'un stock de contextes avec leurs annotations, pouvant être exploité en parallèle avec le processus précédent.  Annotation d'une unité  Le premier processus permet de déterminer une liste de contextes plus ou moins proches du contexte dans lequel apparaît une unité lexicale non annotée. Le second permet de collecter un certain nombre de contextes avec leur annotation. Ces deux types de données peuvent dès lors être croisées pour permettre l'annotation d'une unité.  Ci-dessous (tableau de gauche) la liste de contextes proches du contexte  :provide. pour la proposition provide Albania with food aid, avec l'indication de leur distance et de leur annotation correspondante dans la base de données de contextes :  Contexte  Distance Annotation Annotation Score  Pour pouvoir déterminer une annotation pour le contexte provide.  , il faut regarder les annotations attribuées à ses contextes les plus proches et examiner si elles sont pertinentes ou non. Pour ce faire, il importe de calculer un score pour chaque annotation, valorisant sa  présence dans les contextes de " tête de liste : le score d'une annotation donnée est égal à  l'inverse de la somme des distances des contextes portant cette annotation. Pour notre cas, les scores sont présentés dans le tableau ci-dessus à gauche ; il est alors possible, en fonction de ces scores, d'attribuer l'annotation à l'unité Albania dans la proposition provide Albania with food aid . Ci-dessous les taux de précisions pour l'ensemble des participants pour les noms de lieux (tableau 3) et les noms d'entreprises (tableau 4). Tâche Systèmes  Malgré certaines imperfections,  est relativement bien placé au sein des autres systèmes ayant participé à l'évaluation (cf tableaux 3 et 4), avec notamment une seule erreur de plus pour la classe par rapport au système le plus performant . Cinq systèmes ont participé à la tâche sur les et trois à celle sur les , pour tous les niveaux de granularité à chaque fois. Hormis , les systèmes reposaient sur des méthodes statistiques par apprentissage, mais surtout, notre système est le seul à ne pas avoir utilisé les annotations syntaxiques manuelles fournies par les organisatrices. Deux systèmes ne sont pas parvenus à atteindre la baseline pour les noms de lieux.  Dans cet article, nous avons décrit un système hybride pour la résolution de métonymies. Notre  approche, quoique perfectible, a d'ores et déjà montré des résultats encourangeants lors de la compétition SemEval. Les perspectives de développement sont nombreuses, pour notre système tout comme pour la tâche de résolution de métonymie en général. À notre échelle, nous envisageons de poursuivre le travail entrepris afin d'améliorer les performances du système pour les glissement de sens déjà pris en compte et d'étendre ce traitement à d'autres types d'entités nommées.  
