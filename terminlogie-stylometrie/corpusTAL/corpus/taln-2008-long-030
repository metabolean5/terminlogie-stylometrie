La recherche d'information dans une collection de documents qu'elle soit spécialisée (e.g. Legifrance , ) ou non (e.g. Internet) nécessite une indexation des documents. L'index ainsi créé est ensuite utilisé pour évaluer la pertinence de chacun des documents de la collection pour les requêtes des utilisateurs. Dans le cadre de documents textuels, on distingue usuellement deux types d'indexation : l'indexation libre, qui permet d'utiliser sans limitation des séquences de mots quelconques, et l'indexation contrôlée qui utilise de manière contrainte les concepts répertoriés dans une liste prédéfinie. On parle alors de vocabulaire contrôlé ; c'est dans ce cadre que se situe notre travail.  Dans le domaine biomédical, le thésaurus MeSH  (Medical Subject Headings) développé par la U.S. National Library of Medicine (NLM) est l'outil de prédilection pour indexer la littérature. Ainsi, la base recense plus de 17 millions d'articles scientifiques du domaine et reçoit 3 millions de requêtes par jour. Ces articles sont référencés à l'aide de notices descriptives, ou « citations », contenant notamment une quinzaine de mots-clés représentant les concepts abordés par les auteurs parmi les quelque 24 000 du thésaurus (e.g. aphasia, patient care, hand. . .), organisés hiérarchiquement (e.g. thumb est un descendant de hand dans l'arborescence Anatomy ). Le cas échéant, ces mots-clés doivent ensuite être précisés à l'aide des 83 qualificatifs (e.g. surgery, pharmacology). Pour chaque mot-clé, le MeSH définit un sous-ensemble de qualificatifs « affiliables », de sorte que seules certaines paires peuvent être formées. Par exemple, les paires aphasia/metabolism ou hand/surgery sont autorisées, mais pas hand/metabolism.  L'augmentation constante du nombre de publications à indexer dans  (environ 3 000 par jour) a conduit au développement d'outils automatiques tels que (Aronson et al., 2004) destinés à aider les indexeurs en leur proposant des mots-clés jugés pertinents pour chacun des documents traités. La complexité de la tâche d'indexation et le volume croissant de données à traiter fait du perfectionnement des outils existant une nécessité. En particulier, en ce qui concerne l'indexation MeSH, un progrès notable repose sur l'extraction par des outils automatiques de paires mot-clé / qualificatif et non seulement des mots-clés isolés. Des travaux récents (Névéol et al., 2007) menés dans le cadre du projet « Indexing 2015 » de la NLM ont montré que l'utilisation de règles d'indexation appliquées à partir des mots-clés isolés est une bonne méthode pour l'extraction de paires. Pour quelques qualificatifs, des règles régissant leur emploi ont été trouvées manuellement. Les performances obtenues à l'aide de ces règles manuelles sont satisfaisantes au niveau de la précision, mais le rappel reste faible et le développement manuel de nouvelles règles est à la fois complexe et coûteux.  L'objectif du travail présenté dans cet article est de dépasser ce cadre manuel en  inférant automatiquement de nouvelles règles d'indexation impliquant des qualificatifs pour compléter les résultats de . Pour ce faire, nous adoptons une approche originale en utilisant une méthode d'apprentissage symbolique particulière, la programmation logique inductive (PLI), que nous adaptons aux spécificités des données afin d'obtenir des règles pertinentes permettant de traiter efficacement une grande quantité de données. Ces règles, que nous cherchons à inférer, sont du type :  L'indexation de textes du domaine biomédical à l'aide de descripteurs MeSH a donné lieu à de  nombreux travaux aussi bien en anglais que dans d'autres langues européennes. Les méthodes utilisées pour l'indexation relèvent aussi bien du TAL (Névéol et al., 2006) que de l'apprentissage (Lin & Wilbur, 2007; Rak et al., 2007) ou d'une combinaison des deux (Markó et al., 2003; Aronson et al., 2004). Cependant, du fait de la complexité du problème de l'indexation MeSH (nombre de descripteurs, multiples combinaisons possibles...), la plupart de ces travaux, même récents, se focalisent sur l'indexation à l'aide de mots-clés MeSH isolés et ne prennent pas en compte le rôle des qualificatifs. Ainsi, nos travaux prennent appui sur ceux de Névéol et al. (2006; 2007) pour proposer une avancée innovante dans ce domaine. Bien que la formalisation de règles d'indexation MeSH n'ait pas fait l'objet de travaux en indexation automatique, cette question a été abordée dans le cadre de la recherche d'information par Soualmia (2004) qui proposait l'application de règles d'association pour l'expansion de requêtes. Cependant, peu de règles avaient été obtenues du fait de la complexité de la description du problème d'apprentissage par des techniques standard (cf. section suivante). La technique d'apprentissage artificiel que nous utilisons pour aborder ce problème, la PLI, doit nous permettre de contourner ces difficultés. La PLI a déjà été employée pour certains travaux en TAL ; par exemple pour inférer des patrons d'extraction (Claveau et al., 2003), des règles d'alignement (Ozdowska & Claveau, 2006), faire de l'étiquetage et d'autres tâches (Cussens & Deroski, 2000). Dans tous ces travaux, c'est principalement l'expressivité de la PLI qui est exploitée, notamment sa capacité à représenter simplement des problèmes relationnels, et à produire des règles interprétables. Cette capacité à traiter des problèmes impliquant des représentations complexes se traduisent en revanche souvent par des complexités calculatoires prohibitives pour travailler sur de grandes quantités de données. Il est donc important de bien contrôler ces aspects, comme nous le décrivons en section 3.3.  Dans cette section, nous présentons brièvement les principes de la PLI ; nous invitons le lecteur  intéressé à consulter (Muggleton & Raedt, 1994) pour une description étendue. Nous détaillons ensuite l'intérêt de cette méthode pour l'indexation MeSH et décrivons comment nous l'avons adaptée pour prendre en compte les spécificités de notre problème.  La PLI est une technique d'apprentissage symbolique supervisée permettant d'inférer des  règles, exprimées sous forme de clauses logiques (clauses Prolog), à partir d'exemples, eux aussi décrits en Prolog. Formellement, étant donnés les ensembles d'exemples E et de contreexemples E , un ensemble d'informations sur le monde B (background knowledge), le but d'un programme de PLI est de trouver un ensemble de règles H tel que ( représente faux) : B  H  E |= et B  H |= E .  En pratique, ces deux conditions sont assouplies : on cherche un ensemble de règles couvrant  (expliquant) la plupart des exemples positifs et rejetant la plupart des exemples négatifs. Cela permet de travailler avec des données imparfaites ou bruitées - ce qui est souvent le cas avec des  problèmes réels - et d'obtenir des règles plus génériques quitte à accepter quelques exceptions.  La plupart des algorithmes de PLI abordent l'inférence de règles comme un problème de recherche dans un espace d'hypothèses (noté E ). L'algorithme 1 illustre ce type de fonctionnement ; c'est ce même algorithme qui est au coeur d' (Srinivasan, 2001), l'outil de PLI que nous utilisons pour nos expériences. L'organisation et le parcours de l'espace E est un point crucial pour l'efficacité de la phase d'inférence (cf. section 3.3). La fonction de score Sc prend généralement en compte le nombre d'exemples positifs et négatifs couverts (respectivement P et N ) pour juger de la qualité d'une hypothèse ; dans notre cas, Sc = .  Algorithme 1 Algorithme d'   Itération jusqu'à  E =  1. choisir aléatoirement un exemple positif e dans E ; 2. construire la clause la plus spécifique  couvrant e ; 3. générer et parcourir l'espace de recherche E basé sur  à la recherche de la clause h maximisant une fonction de score Sc ; 4. ajouter h à l'ensemble H et ôter de E les exemples couverts par h. Fin itération  Dans notre cadre, la PLI doit permettre d'inférer des règles d'adjonction de qualificatifs à partir  d'exemples d'articles recensés dans et préalablement annotés à l'aide de descripteurs MeSH. Pour un qualificatif donné, on cherche à obtenir les règles indiquant à quel mot-clé il doit être associé selon le contexte de ce mot-clé.  Ce problème peut être vu comme un simple problème de recherche de règles d'association  pour lequel il existe des algorithmes qui peuvent sembler moins lourds que la PLI (Agrawal et al. , 1993). Cependant, le choix de la PLI pour ce problème n'est pas un hasard. En effet, une technique de recherche de règle d'association (e.g. ) nécessiterait de décrire chaque exemple par un tuple indiquant quel mot-clé est examiné (celui pour lequel on peut vouloir ajouter le qualificatif étudié) et quels autres mots-clés apparaissent dans le reste de la description. Sans autre subtilité de représentation, cela produirait un tuple de dimension 24 000 x 24 000. La recherche de représentations plus légères se heurte tout de même à deux problèmes (Soualmia, 2004) : le nombre variable de mots-clés par article et la prise en compte des relations hiérarchiques entre mots-clés. Ces deux problèmes propres aux méthodes propositionnelles (i.e. décrivant les problèmes sous forme de tuples attributs-valeurs) sont naturellement résolus par l'emploi de la PLI. En effet, grâce à l'expressivté de Prolog, la PLI permet de décrire de tels problèmes relationnels simplement. Le tableau 1 présente par exemple la notice d'un article et son encodage en Prolog. Un exemple positif est une occurrence d'un mot-clé associé au qualificatif dont nous cherchons à modéliser l'utilisation. Supposons que l'on s'intéresse aux règles d'indexation impliquant le qualificatif pharmacology ; d'après la notice du tableau 1, on ajoute à E l'exemple : Les exemples négatifs sont des occurrences de mots-clés auxquels le qualificatif recherché n'est pas associé bien qu'il soit autorisé pour ces mots-clés.  Extrait de la notice d'un article  Extrait de l'encodage de l'article dans B ... ...  La phase de construction des exemples, nécessaire pour notre technique supervisée, est donc  entièrement automatique. Les règles qui en sont inférées manipulent les différents prédicats que nous venons de décrire. Voici un exemple de règle qui pourrait être inférée à partir de l'exemple et qui correspond à la règle donnée en introduction : La contrepartie à l'expressivité de la PLI est la grande complexité de l'inférence des règles. L'espace de recherche E est généralement très grand, voire infini dans certains cas. Par ailleurs, le calcul du score Sc repose sur le nombre d'exemples positifs et négatifs couverts par l'hypothèse examinée, ce qui implique de confronter tous les exemples à la clause. C'est cette partie qui est la plus coûteuse en PLI. Il est donc essentiel de bien contrôler cette phase de recherche pour s'assurer à la fois d'un temps de calcul praticable et de la production de règles pertinentes pour notre problème. Heureusement, E peut être organisé et parcouru hiérarchiquement ; la relation d'ordre usuellement utilisée est la -subsomption.  Définition 1 (-subsomption) Une clause C  -subsume une clause C ( C C ) si et seulement si (ssi) il existe une substitution  telle que C   C (en considérant les clauses comme des ensembles de littéraux).  Par exemple, la clause p(a, b)  r(b, a) est subsumée par la clause p(Y  , Y )  r(Y , Y ). En effet, on a bien {p(Y , Y ), ¬r(Y , Y )}  {p(a, b), ¬r(b, a)} avec  = {Y /a, Y /b}. Grâce à cette relation hiérarchique, l'espace peut être généré et exploré efficacement, par exemple de la clause la plus générale à la plus spécifique selon la -subsomption. À partir d'une clause C , on peut générer des clauses plus spécifiques qui ont notamment pour propriété de ne couvrir que des sous-ensembles des exemples couverts par C . Le calcul du score des clauses plus spécifiques que C s'en trouve grandement accéléré. De même, on peut éviter de générer une clause que l'on considère comme ne couvrant pas assez d'exemples dès lors que son ancêtre ne couvre lui-même pas assez d'exemples. Cependant, la -subsomption n'est pas parfaitement adaptée à notre problème car la hiérarchie entre termes MeSH n'est pas prise en compte. Ainsi, la clause n'est pas subsumée par bien que Mutation soit un ancêtre de Frameshift Mutation dans la hiérarchie MeSH. Nous proposons donc une autre notion de subsomption en nous inspirant des travaux de Buntine (1988) :  Définition 2 Une clause C   -subsume une clause C ( C C ) relativement au background knowledge B ssi il existe une substitution  et une fonction f telles que f (C)  D, où f est telle que l  C, B, f (l) |= l, avec f ({l , l , ..., l }) signifiant {f (l ), f (l ), ..., f (l )}.  La fonction f permet donc de prendre en compte les informations du background knowledge,  c'est-à-dire l'organisation hiérarchique des mots-clés du MeSH. Cette subsomption, que nous avons mise en oeuvre en modifiant , est cohérente avec la notion de couverture. Il est aisé de montrer qu'elle induit un ordre partiel entre les clauses et structure donc l'espace E en treillis, ce qui facilitera son parcours. Parfaitement adaptée à notre problème, elle va nous permettre d'inférer efficacement des règles d'indexation à partir de grandes quantités d'exemples et contre-exemples (cf. section 5) en évitant l'impasse calculatoire qui aurait consisté à considérer indépendamment les 24 000 mots-clés du MeSH. Il est intéressant de noter que cette subsomption est en fait adaptée à tous les problèmes de recherche de régularités impliquant des connaissances structurées (e.g. ontologies).  Comme nous l'avons expliqué, les méthodes simples de recherche de règles d'association ne  peuvent pas traiter directement nos données. Pour néanmoins donner une base de comparaison aux performances de notre approche, nous implémentons une simple baseline. Celle-ci consiste à former aléatoirement des paires mot-clé/qualificatif en respectant la distribution statistique de l'ensemble des paires dans la base . Ainsi, nous avons estimé que la probabilité d'apparition P d'une paire mot-clé/qualificatif était égale au nombre d'occurrences de cette paire dans divisé par le nombre total d'occurrences du mot-clé dans , qu'il soit affilié à un qualificatif ou non. Le tableau 2 présente par exemple la distribution complète du mot-clé Irritable Mood et un extrait de la distribution du mot-clé Lung.  Irritable Mood  Lung (extrait) 5 qualificatifs affiliables 26 qualificatifs affiliables Qualificatif P Qualificatif P sans qualificatif 0.758 sans qualificatif 0.047 classification 0.008 classification 0 drug effect 0.129 drug effect 0.082 ethics 0 metabolism 0.117 physiology 0.101 pathology 0.171 radiation effect 0.004 radiation effect 0.011  En pratique, on voit d'après l'exemple de règle d'indexation donné en introduction que des  mots-clés isolés servent de point de départ à la recommandation de paires. Pour l'anglais, le logiciel (Aronson et al., 2004) développé à la NLM permet de générer automatiquement des recommandations d'indexation pour des mots-clés isolés. Il faut remarquer que les motsclés recommandés par ont, sur le corpus de test, un rappel de 45 % par rapport aux termes sélectionnés par les indexeurs . Ainsi, un écart est attendu entre les performances théoriques des règles d'indexation obtenues par PLI et les performances obtenues à partir de l'application de ces mêmes règles sur les mots-clés isolés recommandés par , c'est-à-dire dans un environnement pratique d'indexation automatique. Les règles d'indexation obtenues par PLI sont évaluées sur le corpus de test, l'indexation servant de référence. Ces performances sont comparées à celles de règles d'indexation similaires obtenues manuellement par un expert du domaine et à celles de la baseline décrite en 4.1.  Pour chacune des méthodes (PLI, manuelle, baseline) seules les paires constituées à partir  de mots-clés extraits par et figurant dans sont prises en compte. Les mesures de performances utilisées sont la précision, le rappel et la F-mesure. La précision correspond au nombre de paires mot-clé/qualificatif recommandées utilisées dans divisé par le nombre total de paires recommandées. Le rappel correspond au nombre de paires recommandées utilisées dans divisé par le nombre total de paires figurant dans l'indexation . La F-mesure correspond à la moyenne harmonique de la précision et du rappel.  Nous ne présentons ici que les résultats obtenus sur quelques qualificatifs, notamment ceux  pour lesquels il existe des règles manuelles qui nous permettent d'effectuer une comparaison. Ces résultats sont discutés dans la section suivante.  Le tableau 3 présente les performances théoriques obtenues en appliquant les règles PLI sur les  mots clés contenus dans les notices . Nous indiquons également les temps de calcul obtenus sur une machine de bureau (linux Intel Xeon 3 GHz) au regard du nombre d'exemples utilisés.  Qualificatif  |E | |E | Temps de Précision Rappel F-mesure calcul (%) (%) (%) Administration & dosage 5 300 40 000 75 mn 41.4 53 46.5 Metabolism 4 500 21 000 37 mn 42.4 60.2 49.7 Pharmacology 5 000 22 000 45 mn 48.8 53.9 51.2 Physiology 5 200 34 000 46 mn 41.4 41.5 41.5  Qualificatif  Méthode Nb. règles Précision (%) Rappel(%) F-mesure(%) Administration PLI 166 38 29 33 & dosage Manuelle 1 54 1 1 Baseline 26 9 13 Metabolism PLI 134 49 38 43 Manuelle 61 58 20 30 Baseline 37 12 18 Pharmacology PLI 217 47 28 35 Manuelle 7 67 3 5 Baseline 28 12 17 Physiology PLI 70 46 24 32 Manuelle 0 Baseline 28 10 15  Performances. Comme attendu, l'utilisation de l'outil  pour produire dans un premier temps des recommandations de mots-clés fait que le rappel en situation réelle des règles inférées par PLI est inférieur à celui mesuré sur les notices. Malgré cela, les performances des règles PLI sont bien supérieures à celles de la baseline et produisent toujours la meilleure F-mesure  avec une différence de précision modérée par rapport aux règles manuelles. Ces dernières sont  beaucoup plus ciblées, ce qui produit de très bons taux de précision mais des rappels généralement faibles, inférieurs non seulement à la PLI mais aussi à la baseline (sauf dans le cas de metabolism ). Dans le cadre d'une utilisation combinée avec d'autres méthodes d'indexation, il est probable que le gain significatif en rappel apporté par les règles PLI contribue à une amélioration globale du rappel des recommandations sans perte de précision. Par ailleurs, grâce à notre notion de subsomption adaptée au problème, les temps de calcul de la phase d'inférence sont tout à fait raisonnables, notamment au regard des temps de développement de règles manuelles. Sans la modification de subsomption, des expériences préliminaires ont montré que la PLI ne pouvait guère manipuler ces quantités d'information (temps de calcul dépassant plusieurs jours, dépassement mémoire). Règles PLI vs. manuelles. Avec les modifications apportées, la PLI permet donc d'obtenir rapidement un grand nombre de règles. En examinant ces règles, il apparaît parfois que des règles un peu différentes obtenant des performances proches semblent sémantiquement meilleures pour un expert du domaine. De même, certaines règles PLI peuvent permettre à un expert de créer manuellement une nouvelle règle qui n'aurait pas pu être inférée à partir du corpus d'entraînement. Ainsi, il pourrait être possible d'optimiser la production de règles d'indexation en envisageant une relecture des règles PLI par un expert afin d'améliorer la lisibilité et les performances des règles tout en minimisant le temps passé à la production des règles. . Outre la baisse globale de rappel observée avec l'application des règles PLI sur les motsclés extraits par , on constate en observant les performances individuelles de chaque règle que les variations sont hétérogènes en fonction des mots-clés mis en jeu ; ce qui reflète les performances de pour l'extraction des mots-clés. Ainsi, il est envisageable de filtrer automatiquement les règles les moins performantes dans notre cadre applicatif précis.  Nous avons montré qu'il était possible d'exploiter des régularités dans les descriptions des  articles biomédicaux indexés dans pour proposer automatiquement des qualificatifs à affilier aux mots-clés lors du traitement d'un nouvel article. L'automatisation de cette tâche jusqu'alors manuelle - problème peu abordé auparavant - a été possible par l'utilisation de la PLI et sa capacité à gérer des problèmes impliquant des représentations complexes. Il a néanmoins été nécessaire d'implémenter une notion de subsomption entre clauses permettant de prendre en compte les spécificités de la tâche ; cela nous a permis d'obtenir des temps de calcul praticables tout en traitant un nombre de données suffisamment important pour obtenir des résultats fiables. Cette approche est d'ailleurs transposable à d'autres problèmes impliquant des recherche de régularités dans des connaissances organisées (thésaurus, ontologies...). Enfin, ces résultats sont d'autant plus remarquables qu'ils n'exploitent que des régularités implicites des descriptions et non le contenu de l'article et permettent ainsi d'envisager l'utilisation d'autres stratégies de recommandations de qualificatifs basées cette fois sur le corps de l'article à indexer.  Plusieurs perspectives sont envisagées à la suite de ce travail. Tout d'abord, il sera nécessaire de  l'étendre à l'ensemble des 83 qualificatifs afin d'obtenir un jeu complet de règles d'indexation. Par ailleurs, nous envisageons une amélioration des performances et de la lisibilité grâce à un filtrage automatique ou à une relecture manuelle comme indiqué en 6. Enfin, nous anticipons l'intégration du jeu de règles obtenues au module d'affiliation de qualificatifs de . Ce travail a été effectué dans le cadre de la participation d'A. Névéol au programme de recherche postdoctorale de la National Library of Medicine administré par ORISE. Les auteurs remercient A. Aronson, J. Mork et S. Shooshan pour de nombreuses discussions sur les aspects théoriques et techniques de cette étude.  
