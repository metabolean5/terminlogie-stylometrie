Cet article propose une méthode pour extraire une analyse en dépendances d'un  énoncé à partir de son analyse en constituants avec les grammaires d'interaction. Les grammaires d'interaction sont un formalisme grammatical qui exprime l'interaction entre les mots à l'aide d'un système de polarités. Le mécanisme de composition syntaxique est régi par la saturation des polarités. Les interactions s'effectuent entre les constituants, mais les grammaires étant lexicalisées, ces interactions peuvent se traduire sur les mots. La saturation des polarités lors de l'analyse syntaxique d'un énoncé permet d'extraire des relations de dépendances entre les mots, chaque dépendance étant réalisée par une saturation. Les structures de dépendances ainsi obtenues peuvent être vues comme un raffinement de l'analyse habituellement effectuée sous forme d'arbre de dépendance. Plus généralement, ce travail apporte un éclairage nouveau sur les liens entre analyse en constituants et analyse en dépendances. This article proposes a method to extract dependency structures from phrasestructure level parsing with Interaction Grammars. Interaction Grammars are a formalism which expresses interactions among words using a polarity system. Syntactical composition is led by the saturation of polarities. Interactions take place between constituents, but as grammars are lexicalized, these interactions can be translated at the level of words. Dependency relations are extracted from the parsing process : every dependency is the consequence of a polarity saturation. The dependency relations we obtain can be seen as a refinement of the usual dependency tree. Generally speaking, this work sheds new light on links between phrase structure and dependency parsing. Analyse syntaxique, grammaires de dépendances, grammaires d'interaction, polarité. Syntactic analysis, dependency grammars, interaction grammars, polarity.  Les grammaires de constituants et les grammaires de dépendances sont souvent présentées  comme orthogonales : les premières organisent les groupes de mots en syntagmes alors que les secondes mettent la dépendance entre mots au centre de la structure syntaxique. Avec les grammaires de constituants lexicalisées, telles que les grammaires d'arbres adjoints (TAG) et les grammaires catégorielles (CG), où chaque élément de la grammaire est associé à un mot, la composition syntaxique lors de l'analyse met en évidence des liens entre les mots. Ces liens présentent des similitudes avec les relations de dépendances et ont fait l'objet de différentes études. A. Dikovsky et L. Modina ont étudié du point de vue formel le passage d'une analyse en constituants à une analyse en dépendances et vice versa (Dikovsky & Modina, 2000). O. Rambow et A. Joshi ont expliqué comment retrouver une analyse en dépendances à partir d'une analyse dans les TAG où les substitutions et les adjonctions sont vues comme des relations de dépendances entre les mots (Rambow & Joshi, 1997). Enfin, l'article (Clark et al., 2002) propose une méthode similaire pour les grammaires catégorielles combinatoires où l'application des règles combinatoires donne lieu à des relations de dépendances entre les mots.  Les grammaires d'interaction (IG) sont des grammaires de constituants lexicalisées qui étendent  par un système de polarités plus riche le système besoins/ressources employé dans les grammaires catégorielles. Dans cet article, nous généralisons, les résultats (Clark et al., 2002) cités plus haut pour les CG au cas des IG, en révisant la méthode : en effet, cette dernière impose d'étendre les entrées lexicales avec des marqueurs pour aider à la construction des dépendances lors de l'analyse, et produit trop de dépendances, alors que notre méthode s'appuie plus simplement sur le lien entre polarités et dépendances.  Dans la section 2, les IG sont présentées et illustrées par un exemple. La section 3 décrit la  méthode d'extraction des dépendances à partir d'une analyse avec une IG. Finalement, dans la section 4, nous étudions les structures de dépendances obtenues et nous mettons en perspective avec d'autres travaux.  Les grammaires d'interaction (Perrier, 2003) sont un formalisme grammatical s'appuyant sur  la notion de description d'arbres. Cette notion a été introduite par M. Marcus, D. Hindle et M. Fleck en 1983 (Marcus et al., 1983), et K. Vijay-Shanker l'a utilisée pour représenter de façon monotone l'opération d'adjonction des TAG (Vijay-Shanker, 1992).  Une description d'arbres est définie par un ensemble de noeuds et de relations d'ascendance,  de parenté et de précédence entre ces noeuds. Les noeuds représentent des syntagmes (éventuellement vides) et les relations expriment les dépendances entre ces syntagmes. Les propriétés morpho-syntaxiques de ces syntagmes sont décrites par des structures de traits. Cette approche flexible est bien adaptée à l'ambiguïté des langues naturelles. Cependant, l'analyse syntaxique fondée sur des descriptions d'arbres est très coûteuse (Koller et al., 1998). En effet, dans cette approche, l'analyse syntaxique consiste à chercher des modèles de descriptions d'arbres sous forme d'arbres syntaxiques complètement spécifiés, ce qui est un problème NP-complet. Dans les formalismes opérationnels fondés sur les descriptions d'arbres (comme les D-tree substitution grammars (Rambow et al., 2001) ou les TT-MCTAG (Kallmeyer, 2005)), cet indéterminisme est limité en contraignant la syntaxe des descriptions et le mécanisme de composition syntaxique. L'originalité des grammaires d'interaction est de proposer un mécanisme de composition syntaxique très souple qui consiste à superposer les descriptions d'arbres mais qui est guidé par une contrainte de saturation de polarités. Cette contrainte fait référence à l'idée de valence de Tesnière (Tesnière, 1934) et est essentielle dans les CG : chaque mot est équipé d'une valence exprimant ses possibilités d'interaction avec les autres mots. La composition syntaxique est contrôlée pas une dualité besoins/ressources : certaines ressources munies de polarités négatives sont attendues alors que d'autres, munies de polarités positives, sont disponibles. Dans les IG, cette idée de valence est reprise et généralisée.  Contrairement aux CG, les IG attachent les polarités aux traits qui décorent les noeuds. Mais  nous nous en tiendrons ici à une version simplifiée des IG où les polarités sont accrochées aux noeuds. Une autre différence avec les CG est que le système de polarités est plus riche. En effet, les IG proposent deux types d'interaction à base de polarités : - les interactions linéaires : chaque noeud portant une polarité positive (notée +) doit fusionner avec exactement un noeud portant une polarité négative (notée ) et réciproquement. - les interactions non-linéaires : chaque noeud portant une polarité virtuelle (notée ) doit fusionner exactement, soit avec un noeud positif et un noeud négatif, soit avec un noeud portant la polarité saturée (notée =). En revanche, un nombre quelconque de noeuds virtuels peuvent fusionner avec le même couple positif/négatif ou avec le même noeud saturé.     + =    + =   = + + = = = Lors de la fusion de deux noeuds, le noeud résultant porte la polarité issue de la composition des polarités des noeuds initiaux. La composition d'une polarité positive et d'une polarité négative donne une polarité saturée alors que la polarité virtuelle est l'élément neutre de cette opération. Toute autre composition provoque l'échec de la fusion (cf. tableau ci-contre). L'opération de composition est associative et commutative, l'ordre de fusion des noeuds n'a donc pas d'importance dans le processus de composition syntaxique.  La structure syntaxique élémentaire manipulée dans les IG est appelée description d'arbre  polarisée (DAP). Une IG particulière est définie par un ensemble de DAP ; chaque DAP est associée à un mot . La grammaire est ainsi un lexique où un mot peut avoir plusieurs entrées. Pour analyser une phrase, il faut choisir pour chaque mot l'une des DAP associée à ce mot. Un tel choix est appelée une sélection lexicale. L'analyse consiste ensuite à composer ces DAP pour obtenir un arbre d'analyse.  L'opération atomique de composition syntaxique consiste à superposer deux noeuds pour saturer   leurs polarités. On itère l'opération de saturation de noeuds pour construire progressivement  l'analyse de la phrase sous forme d'un arbre.  Les DAP d'une sélection lexicale pour la phrase "Jean en connaît la couleur" sont représentées  sur la figure 1.  La DAP représentant le mot "en" décrit l'intuition linguistique suivante : le pronom "en"  est utilisé comme complément du nom "couleur" mais il vient s'adjoindre devant le verbe "connaît" qui admet "la couleur" comme objet direct. La DAP montre à droite du noyau verbal C2 un syntagme objet D2 attendu comportant un complément du nom J2 qui est déjà complètement saturé mais sans réalisation phonologique. Le noeud I2 renseigne la positionnement du nom dans le syntagme H2. Au niveau du noyau verbal C2, le pronom "en" E2 est positionné à gauche du verbe F2.  À partir de l'ensemble des DAP de la figure 1, on peut construire l'arbre syntaxique saturé  représenté sur la figure 2. Sur chaque noeud de l'arbre est indiqué l'ensemble des noeuds des DAP qui ont été superposés. Par exemple le noeud A2-A3 représente la superposition du noeud A2 de la DAP de "en" et du noeud A3 de la DAP de "connaît".  Pour valider le formalisme, nous avons développé une grammaire du français (Perrier, 2007).  Cette grammaire a été évaluée sur la TSNLP (Lehmann et al., 1996) qui contient 1690 énoncés  grammaticaux et 1935 énoncés agrammaticaux. Ce jeu de tests ne couvre pas toute la langue  française, il y a peu de phrases complexes mais il insiste sur certains phénomènes comme la coordination ou la position des compléments adverbiaux. Cependant, notre grammaire couvre d'autres phénomènes dont la TSNLP ne tient pas compte, comme par exemple : la voix passive, la sous-catégorisation des noms et des adjectifs prédicatifs, le contrôle du sujet des compléments infinitifs, les propositions relatives et interrogatives. 88% des 1690 phrases grammaticales sont modélisées et 85% des 1935 phrases agrammaticales sont rejetées. Les 15% d'énoncés agrammaticaux sont acceptés car la grammaire ne modélise pas les règles phonologiques et la sémantique. Les raisons pour lesquelles 12% des énoncés grammaticaux ne sont pas analysés sont diverses (phrases retranscrites de l'oral, expressions figées, causatifs, superlatifs). L'analyse syntaxique est obtenue par superposition des DAP d'une sélection lexicale. La superposition est guidée par la fusion des noeuds portant des polarités se saturant. Au niveau d'une DAP, ces polarités représentent les besoins/ressources du mot dans un énoncé. La saturation de ces dernières peut alors se voir comme la résolution d'une dépendance entre ces mots. On peut alors retrouver les relations de dépendances d'une phrase à partir de l'ensemble des DAP associées aux mots de la phrase et de son analyse.  Nous nous intéressons dans un premier temps au cas simple de la saturation linéaire de deux  polarités + et . Par exemple, dans la phrase "Jean en connaît la couleur" (Figure 2), la DAP représentant le déterminant "la" possède un noeud G4 portant une polarité positive et étiqueté par la catégorie syntaxique DET. La DAP du nom "couleur" comporte quant à elle un noeud G5 portant une polarité négative qui est aussi étiqueté par DET.  Lors de l'analyse, ces deux noeuds fusionnent pour obtenir un noeud saturé, la DAP résultante  représentant une analyse partielle de "la couleur". La saturation de ces deux noeuds peut être vue comme la réalisation d'une relation de dépendances entre les deux mots correspondants.  L'opération de saturation représente la satisfaction d'une contrainte de besoins/ressources. Un  élément qui se présente comme nécessitant une ressource est considéré comme le gouverneur de la relation de dépendances, tandis qu'un élément qui se présente comme fournissant une ressource se retrouve comme le dépendant de cette relation. Ainsi, en cas d'interaction linéaire, le mot dont la DAP contient le noeud négatif est le gouverneur et le mot dont la DAP contient le noeud positif est le dépendant de la relation de dépendances. Les relations de dépendances engendrées par la saturation des noeuds portant des polarités opposées seront appelées dépendances linéaires. Dans la grammaire actuelle du français, elles représentent les relations tête-complément et tête-spécifieur. Dans l'exemple "Jean en connaît la couleur", les dépendances linéaires obtenues sont représentées sur la figure 3 (les arcs portent la catégorie qui a fait l'objet d'une saturation ).  Cette analyse possède un noeud "en" isolé. La DAP du pronom "en" ne porte en effet pas de  polarité positive ou négative et ainsi ne produit pas de relation de dépendances linéaires avec le reste de la phrase. La saturation des polarités positives et négatives ne suffit donc pas pour exprimer toutes les relations de dépendances d'une phrase. Nous allons donc voir comment certaines relations de dépendances peuvent être produites pas des interactions non-linéaires. Dans la grammaire actuelle, la DAP pour l'adjectif "belle" dans le groupe nominal "la belle couleur" est donnée par la figure ci-contre. De façon habituelle en dépendances, on considère qu'il y a une dépendance de "belle" vis à vis de "couleur" . Deux noeuds sont non-saturés (H6 et I6) et ils portent tous les deux une polarités virtuelle, c'est donc la saturation de l'une de ces deux polarités qui doit induire la dépendance. Dans ce cas, les deux polarités peuvent être à l'origine de la dépendance. Cependant, il ne doit être produit qu'une seule relation de dépendances, il faut choisir alors quelle polarité engendrera une dépendance lors de sa saturation. Un autre exemple d'usage des polarités virtuelles dans la grammaire du français est illustré par l'exemple "Jean le connaît". Dans cette phrase, le pronom "le" (ci-contre) est l'objet direct du verbe "connaît" : cette relation de dépendances est produite par la saturation linéaire des polarités du noeud D7 de la DAP du pronom "le" et du noeud D3 de la DAP du mot "connaît" . Mais la DAP du pronom "le" possède trois noeuds A7, C7, F7 portant une polarité virtuelle dont la saturation non-linéaire n'apporte aucune information de dépendances entre les mots "le" et "connaît". Ces polarités contrôlent simplement la place des syntagmes lors de la superposition des deux DAP et gèrent le fait que le pronom "le" se place avant le verbe alors que la place canonique du groupe nominal objet dans la phrase est après le verbe. Dans l'arbre d'analyse de "Jean le connaît" les trois noeuds virtuels A7, C7, F7 sont saturés, respectivement, par les trois noeuds A3, C3, F3 de la DAP du mot "connaît".  Les deux derniers exemples montrent bien qu'il y a deux usages distincts des polarités virtuelles  qui ne se comportent pas de la même manière pour la production de relation de dépendances : - les polarités virtuelles de dépendances qui portent une information sur les relations de dépendances d'un mot avec son environnement ; - les polarités virtuelles de contexte qui imposent des contraintes sur le contexte syntaxique d'un mot. Il n'est pas possible de distinguer automatiquement, dans une grammaire donnée, les deux types de polarités virtuelles. C'est donc à l'auteur de la grammaire de se baser sur des critères linguistiques pour distinguer ces deux usages. Cependant, dans la pratique, l'utilisation de méta grammaires (notre grammaire, par exemple, est construite avec XMG (Duchier et al., 2005))  permet de faire ce travail rapidement, de façon cohérente sur l'ensemble de la grammaire. Cela concerne uniquement les mots jouant le rôle de modificateurs (adjectifs épithètes, adverbes, prépositions introduisant des compléments adjoints, pronoms relatifs dans leur rôle par rapport à leur antécédent, pronom clitique &#34;il&#34; utilisé en redoublement du sujet, etc.). Il s'agit, dans la DAP associé au mot concerné de marquer le noeud considéré comme noeud privilégié de rattachement au mot qui est modifié. Le travail a été effectué sur notre grammaire du français à large couverture en moins d'une heure.  Ainsi, dans la DAP de "en" (figure 1), toutes les polarités virtuelles des noeuds A2, C2, D2 et  F2 sont des polarités virtuelles de contexte qui gèrent le positionnement de "en". Pour rendre compte du fait que "en" dépend de "couleur", il faut que l'une des deux polarités virtuelles H2 ou I2 soit une polarité virtuelle de dépendances. Dans notre cas, nous avons choisi arbitrairement la polarité H2.  Dans le cas où une relation de dépendances est produite, le dépendant est le mot dont la DAP  porte le noeud virtuel de dépendances. La polarité virtuelle peut être saturé : - soit par un noeud portant la polarité =, dans ce cas ce noeud est le gouverneur ; - soit par un couple de noeud (un positif et un négatif), dans ce cas le gouverneur est le noeud portant la polarité positive. Les relations ainsi engendrées sont appelées dépendances non-linéaires. En effet, un noeud saturé pouvant se composer avec zéro ou plusieurs noeuds virtuels, plusieurs relations de dépendances peuvent avoir comme gouverneur le même mot. Ces relations de dépendances expriment généralement une relation modifieur-modifié.  Dans les structures de dépendances (figures 4 ci-dessous et 5 plus loin) les dépendances linéaires  sont représentées au-dessus de la phrase et les non-linéaires au-dessous.  La procédure d'extraction des dépendances se résume ainsi :   - La saturation de polarités opposées engendre une relation de dépendances linéaire entre les  mots ; la relation va de la polarité négative vers la polarité positive. - La saturation d'une polarité virtuelle de dépendances avec une polarité positive ou saturée engendre une relation de dépendances non linéaire entre les mots ; la relation va de la polarité saturée ou positive vers la polarité virtuelle de dépendances.  Cette procédure permet d'obtenir l'analyse en dépendances de "Jean en connaît la couleur"  représentée figure 4.  Pour garantir que les structures de dépendances sont connexes (chaque mot est en relation  avec au moins un autre mot de l'énoncé), il suffit d'imposer que chaque DAP de la grammaire contienne au moins un noeud positif, un noeud négatif ou un noeud portant une polarité virtuelle de dépendances. C'est la cas de la grammaire actuellement implantée pour le français.  Le choix du type de structures pour représenter les dépendances d'une phrase est une question  épineuse qui divisent les linguistes. L'idée de départ des grammaires de dépendances est de considérer que chaque mot de la phrase (sauf le verbe principal) est gouverné par exactement un autre mot de la même phrase. Cette hypothèse conduit à considérer que les bonnes structures de dépendances sont les arbres, nous allons voir ce qu'il en est avec notre méthode qui permet d'observer, sans a priori, les structures obtenues.  De façon générale, la structure en dépendances que l'on obtient est un graphe orienté ; de plus,  avec la restriction imposée sur les DAP de la grammaire, on sait que ce graphe est connexe.  L'analyse en dépendances pour la phrase "Jean en connaît la couleur" donnée par la figure 4 est  un arbre ; en effet, tous les mots, sauf "connaît", ont un et un seul gouverneur. Il existe cependant des exemples pour lesquels la structure de dépendances n'est pas un arbre. L'application de notre méthode à la phrase "la fille que Jean aime vient" produit l'analyse de la figure 5. Cette structure n'est pas un arbre car elle contient un cycle et le pronom relatif "que" a deux gouverneurs.  On retrouve ainsi avec notre méthode le problème qui se pose habituellement en grammaire de  dépendances pour gérer les phénomènes d'extraction. Par exemple, si nous reprenons la phrase "la fille que Jean aime vient" , le mot "que" remplit ici deux rôles, il est l'objet anaphorique de "aime" et subordonne la relative à l'antécédent. Ce double rôle suppose naturellement deux relations de dépendances distinctes qui contredisent le principe de représentation en arbre, alors que l'analyse présentée figure 5 rend bien compte de ce double emploi. D'autres approches d'analyses en dépendances utilise également des structures qui ne sont pas des arbres : S. Kahane (Kahane, 2000) propose une analyse dans laquelle un pronom relatif a deux gouverneurs ; R. Hudson (Hudson, 1990) utilise également souvent des structures dans lesquelles un mot peut avoir plusieurs gouverneurs. Une autre question récurrente à propos des structures de dépendances à considérer pour la description de la langue est celle de la projectivité. En effet une structure projective induit que les  relations de dépendances restent à un niveau local, ce qui permet une analyse simple et efficace.   Cette notion initialement définie pour les arbres peut se transposer sur les graphes : une structure  de dépendances est dite projective si pour tout mot donné, l'ensemble des noeuds atteignables depuis ce mot dans la structure de dépendances (qu'on appellera emprise du mot) correspond à un segment continu de l'énoncé. Par exemple la structure de la figure 5 est projective alors que celle de la figure 4 ne l'est pas : dans cette analyse, l'emprise du mot "couleur" est formé de deux segments "en" et "la couleur" séparés par le mot "connaît". R. Debusmann and M. Kuhlmann proposent des critères qui permettent de classer plus finement les analyses non-projectives. Il obtiennent ainsi une hiérarchisation en classes du pouvoir expressif que permettent les différentes structures de dépendances (Debusmann & Kuhlmann, 2009). La notion de degré de discontinuité (block-degree) associe à une structure un entier qui est le nombre maximum de segments continus disjoints dans l'emprise d'un mot (un degré de discontinuité de 1 correspond exactement à la projectivité). Pour les structures dont le degré de discontinuité est au moins 2, ils distinguent celles qui sont bien imbriquées (well-nestedness) c'est-à-dire celle qui sont telles que les emprises des deux mots ne se croisent pas (soit elles sont disjointes, soit l'une est entièrement incluse entre deux segments de l'autre). Sur le Prague Dependency Treebank, les auteurs montrent que 99,5% des analyses sont bien imbriquées et de degré de discontinuité au plus deux (ce qui est équivalent à être dans la classe de langages des TAG).  L'application de notre méthode à cette grammaire du français sur la TSNLP ne produit pas  d'analyse mal imbriquées. On obtient dans la plupart des cas des structures de dépendances projectives. Les exemples pour lesquels le degré de discontinuité est de 2 sont dûs principalement au placement de l'auxiliaire dans le noyau verbal. Les mots "en" ou "y" ainsi que l'inversion sujet/verbe lors de l'emploi de pronoms interrogatifs sont d'autres sources de discontinuité, mais nous n'avons pas trouvé d'exemple qui aille au-delà d'un degré de discontinuité de 2.  Dans cet article, nous avons proposé une méthode pour construire une analyse en dépendances  d'un énoncé à partir de son analyse en constituants dans les IG. Cette méthode, basée sur la saturation des polarités, a mis en évidence deux types de dépendances : les dépendances linéaires qui représentent les relations tête-complément ou tête-spécifieur et les dépendances non-linéaires qui représentent les relations modifieur-modifié.  Les structures de dépendances obtenues par cette méthode sont des graphes orientés, elles sont  plus riches que les structures obtenues habituellement par des grammaires de dépendances. Cette représentation permet de gérer simplement les phénomènes linguistiques posant habituellement des difficultés dans les grammaires de dépendances.  Pour la suite du travail, nous souhaitons étudier dans quelle mesure il est possible de transposer  les méthodes d'analyses d'un formalisme à l'autre. Par exemple, Nous avons remarqué que très peu d'analyses sont non-projectives ; on pourrait donc isoler les cas non-projectifs et adapter un algorithme d'analyse des grammaires de dépendances qui servirait de guide à l'analyse dans les  IG. Il serait également intéressant d'étudier l'application de nos méthodes d'analyse spécifiques  aux IG à l'analyse pour des grammaires de dépendances lexicalisées.  
