La phonétisation est le processus qui associe à une séquence mots une ou plusieurs façons de  la prononcer. C'est une étape essentielle pour le traitement de l'oral (transcription de la parole, synthèse de la parole, indexation de documents audios...). Les approches dictionnaire des premiers systèmes de traitement de l'oral ayant rapidement montré leurs limites, beaucoup ont cherché à développer des systèmes de phonétisation capables de manipuler des mots inconnus. Dans le contexte de la phonétisation de mots isolés à laquelle nous nous intéressons ici, l'approche la plus commune pour résoudre ce problème est de s'appuyer sur la forme graphique des mots pour deviner leur prononciation. En pratique, cela consiste à faire correspondre à un mot-forme (représenté par sa chaîne de caractère) une chaîne de symboles représentant une façon prototypique de prononcer ce mot-forme. C'est pourquoi cette tâche est aussi connue sous les noms de conversion lettre-phonème, conversion graphème-phonème, ou de phonémisation.  Dans notre cas, la phonétisation s'insère dans une problématique plus large d'indexation de  flux vidéo dans laquelle nous sommes amenés à manipuler des mots isolés inconnus de notre système de transcription (néologismes, noms propres, sigles, imports de langues de spécialité). Pour les traiter, nous voulons disposer d'une technique produisant des phonétisations de bonne qualité, mais qui soit également rapide, automatique et portable pour pouvoir être adaptée à plusieurs langues et éventuellement à plusieurs sous-groupes de mots ou même à un locuteur. L'approche que nous proposons - que nous appelons IrisaPhon - répond à ces différents critères et part du constat que ce problème de phonétisation peut être vu comme de la translittération. Nous avons donc adapté une technique d'apprentissage que nous avions développée initialement pour la translittération et la traduction de termes biomédicaux (Claveau, 2007; Claveau, 2009). Cette technique permet d'inférer très efficacement des règles de réécriture à partir d'exemples, c'est-à-dire dans notre cas à partir de mots-formes couplés à leur représentation phonétique. Elle n'utilise aucune autre connaissance linguistique que ces exemples, assurant ainsi sa portabilité.  Après une revue des principales approches existantes en phonétisation, nous décrivons notre  technique en section 3. Dans la section 4, nous présentons, comparons et discutons différents résultats d'évaluations. Quelques perspectives ouvertes par ce travail sont enfin présentées dans la dernière partie.  La phonétisation automatique de mot a déjà fait l'objet de nombreux travaux. La plupart adopte  le paradigme de conversion lettre-phonème : la phonétisation comme séquence de phonèmes est déduite de la séquence de caractères formant le mot. Les techniques automatiques s'appuient sur des exemples de mots couplés à leur représentation phonétique. Ces exemples sont le plus généralement alignés lettre à lettre, souvent par des relations 1-1 (Black et al., 1998; Damper et al., 2005) mais de meilleures performances ont été obtenues en tenant compte d'alignements multiples (Bisani & Ney, 2002; Jiampojamarn et al., 2007) qui rendent mieux compte du fait que plusieurs lettres peuvent être représentées par un phonème, et une lettre par plusieurs phonèmes. À partir de ces exemples, certains ont utilisé, et éventuellement adapté, des techniques d'apprentissage classiques comme les arbres de décision (Black et al., 1998; Daelemans & Bosch, 1997) ou des techniques lazy learning (Bosch & Daelemans, 1998). D'autres ont mis l'emphase sur l'aspect séquentiel du problème et utilisent par exemple des HMM (Taylor, 2005) ou des techniques par analogie (Yvon, 1996; Marchand & Damper, 2000, inter alia). Enfin, certains ont tenté de mettre en oeuvre des approches s'inspirant à la fois de l'apprentissage tout en tenant compte des aspects séquentiels. C'est le cas du système CSInf (2006) ou des approches de Jaimpojamarn et al. (2007; 2008) basés sur des SVM modifiés ou des HMM. Ces dernières approches qui intègrent bien les aspects séquentiels sont parmi les plus performantes. Nous revenons sur les performances de quelques-uns de ces systèmes dans la partie évaluation.  Comme nous l'avons annoncé précédemment, notre approche IrisaPhon prend ses racines dans  un système d'apprentissage de règles de réécriture initialement développé pour la translittération de termes biomédicaux. Nous en rappelons les principes ci-dessous ; le lecteur intéressé peut se reporter à Claveau (2009) pour une description plus développée et son utilisation en traduction de termes biomédicaux.  Pour phonétiser un mot-forme inconnu, IrisaPhon lui applique des règles de réécriture et choisit  la phonétisation la plus probable parmi les candidats générés à l'aide d'un modèle de langue. Les règles et le modèle de langue sont appris à partir de données d'entraînement, c'est-à-dire des listes de mots-formes (chaînes de caractères) couplés à leur représentation phonétique (chaînes de symboles phonétiques).  La technique permettant d'inférer les règles de réécriture à partir des exemples est relativement  simple. Une liste de mots couplés à leur représentation phonétique est donnée en entrée du système ; à chaque mot et représentation phonétique sont ajoutés deux caractères pour représenter le début et la fin de la chaîne de caractères (resp. # et $).  L'algorithme 1 décrit le processus qui permet d'inférer des règles à partir de cette liste  d'exemples. La première étape, l'alignement, est réalisée à l'aide de DPalign ( ). Des caractères vides (notés '_') peuvent être insérés au besoin. Par la suite, le mot-forme en entrée (respectivement la phonétisation en sortie) d'une telle paire alignée p est noté input(p) (resp. output(p)) ; de plus, align(x, y) indique que la sous-chaîne x est alignée avec la sous-chaîne y dans la paire de termes considérée. Pour  Algorithme 1 Apprentissage des règles de réécriture  aligner les paires au niveau des lettres, mettre le résultat dans L for all paire W dans L do for all alignement de lettres dont les 2 lettres diffèrent dans W do trouver la meilleure hypothèse de règles r dans l'espace de recherche E ajouter r à l'ensemble de règles R end for end for  chaque différence entre deux lettres alignées, notre algorithme doit générer la règle de réécriture  jugée la meilleure selon un certain score. Beaucoup de règles sont éligibles ; considérons par exemple la différence o/@ dans le couple #phonolog_y$ / #f @nAl@dZi$. Les règles o  @, pho  f @, #phono  #f @nA, etc., sont par exemple possibles.  Le score d'une règle est calculé sur la liste L comme le ratio entre le nombre de fois où la  règle peut effectivement s'appliquer et le nombre de fois où la prémisse de la règle correspond à une sous-chaîne d'un mot-forme. Parmi toutes les règles possibles sur cet exemple, la règle maximisant ce score est donc retenue, et l'algorithme passe à une nouvelle différence entre l'input et l'output ou à un nouveau couple de L. La recherche de la meilleure règle parmi toutes celles possibles est l'étape clé de notre algorithme. Pour choisir cette règle dans notre espace de recherche de la manière la plus efficace possible, nous définissons une relation hiérarchique entre règles. Cette relation est notée par le symbole (si r r , alors r est dite plus générale que r ).  Définition 1 (Relation hiérarchique)  Soit r et r deux règles, alors r r  (input(r )  input(r )  output(r )  output(r )).  Cette relation est réflexive, transitive et anti-symétrique ; elle définit un ordre partiel sur l'espace  de recherche E qui peut donc s'organiser sous forme de treillis. La figure 1 présente un extrait  du treillis de recherche construit à partir de la différence o/@ dans l'alignement #phonolog_y$  / #f @nAl@dZi$. En pratique, ces treillis sont explorés de haut en bas : les règles sont générées à  la volée avec un opérateur très simple qui produit, pour une règle donnée, toutes les règles qui  sont immédiatement plus spécifiques. En choisissant une fonction de score qui soit consistante avec cet opérateur de spécialisation et la structure de treillis qu'il sous-tend, il nous est possible de choisir rapidement la meilleure règle selon ce score (Claveau, 2009). Lorsqu'un mot nouveau doit être phonétisé, on lui applique toutes les règles de réécriture collectées, ce qui génère usuellement un grand nombre de phonétisations possibles. Il est important de noter que par construction, ces phonétisations sont alignées avec le mot de départ. Toutes ces alternatives sont conservées et la plus probable va être proposée. Cette probabilité est calculée de manière classique par un modèle de langue portant le couple mot/phonétisation. L'information de base (unigramme) de ce modèle de langue est donc une lettre alignée avec un symbole  phonétique, que l'on note (par exemple) :  s z . Avec les notations standard, pour un mot m ali gné avec sa représentation phonétique f composés respectivement des lettres (y compris les  vides _ ajoutés pour l'alignement) l , l , ..., l et k , k , ..., k , la probabilité se calcule par l'équation 1. En pratique, un historique de quelques lettres est suffisant. Dans les expériences présentées ci-dessous, cet historique est fixé à 6 lettres, et un lissage de Kneiser-Ney modifié est appliqué.  P  m f = P l k l k , ..., l k (1)  Corpus  IrisaPhon M-M Joint CSInf PbA _ HMM n-gram Néerlandais CELEX 95.58 95.32 91.69 - 94.5 - - Allemand CELEX 93.60 93.61 90.31 92.5 - - - Anglais NETtalk 71.25 67.82 59.32 64.6 - 65.35 - Anglais CMUDict 74.40 71.99 65.38 - - - - Français Brulex 94.75 94.51 89.77 89.1 - - -  Pour évaluer notre approche, nous utilisons plusieurs jeux de données couvrant plusieurs  langues et plusieurs jeux de phonèmes. Ces données sont celles proposées dans le cadre du Letter-to-Phoneme Conversion Challenge (Pronalsyl) du réseau Pascal . Parmi les jeux de données disponibles, nous nous sommes concentrés sur ceux pour lesquels il existait des résultats publiés pour nous y comparer. Tous ces jeux de données comportent plusieurs milliers de paires réparties en 10 listes sur lesquelles les évaluations se font en validation croisée en 10 plis.  La mesure d'évaluation que nous utilisons est la précision en mot (moyennée sur les 10 tours  de validation croisée) : nombre de mots parfaitement et entièrement phonétisés sur le nombre de mots donnés à phonétiser. C'est la mesure utilisée par les systèmes participant au challenge Pronalsyl.  Le tableau 1 présente la précision obtenue par IrisaPhon sur les différents jeux de données. À  des fins de comparaison, nous indiquons également les résultats obtenus sur les mêmes jeux de données, lorsqu'ils sont disponibles, par différents systèmes de l'état de l'art. Ces systèmes sont : (Jiampojamarn et al., 2008), M-M HMM (Jiampojamarn et al., 2007), Joint n-gram (Demberg et al., 2007), CSInf (Bosch & Canisius, 2006), PbA (Marchand & Damper, 2006), _ (Béchet, 2001). Nous indiquons en gras les meilleurs résultats obtenus pour un jeu de test donné. Le résultat est tout à fait satisfaisant puisqu'IrisaPhon obtient les meilleurs résultats sur quasiment tous les jeux de données. Il semble en particulier assez robuste aux jeux de données difficiles (NETtalk et CMUDict), bien qu'une large marge de progression subsiste. La parti-pris de notre approche qui a été de considérer la phonétisation de mot comme un problème de translittération porte clairement ses fruits. Notre système IrisaPhon se compare avantageusement aux systèmes de l'état de l'art, aussi bien en terme de précision qu'en terme de temps de calcul. Bien sûr, les performances mesurées ici sur des données divisées artificiellement en jeu d'entraînement et jeu de test doivent être considérées comme des maxima, et des évaluations de notre système dans un contexte réel restent à mener. L'intégration de ce système dans notre problématique plus large d'indexation de document vidéo permettra de répondre en partie à ce soucis d'évaluation.  
