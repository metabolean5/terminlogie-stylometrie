Cet article présente une technique d'analyse syntaxique statistique à la fois en constituants et en dépendances. L'analyse procède en ajoutant des étiquettes fonctionnelles aux sorties d'un analyseur en constituants, entraîné sur le French Treebank, pour permettre l'extraction de dépendances typées. D'une part, nous spécifions d'un point de vue formel et linguistique les structures de dépendances à produire, ainsi que la procédure de conversion du corpus en constituants (le French Treebank) vers un corpus cible annoté en dépendances, et partiellement validé. D'autre part, nous décrivons l'approche algorithmique qui permet de réaliser automatiquement le typage des dépendances. En particulier, nous nous focalisons sur les méthodes d'apprentissage discriminantes d'étiquetage en fonctions grammaticales. This paper describes a technique for both constituent and dependency parsing. Parsing proceeds by adding functional labels to the output of a constituent parser trained on the French Treebank in order to further extract typed dependencies. On the one hand we specify on formal and linguistic grounds the nature of the dependencies to output as well as the conversion algorithm from the French Treebank to this dependency representation. On the other hand, we describe a class of algorithms that allows to perform the automatic labeling of the functions from the output of a constituent based parser. We specifically focus on discriminative learning methods for functional labelling. Analyseur syntaxique statistique, analyse en constituants/dépendances, étiquetage en fonctions grammaticales. Statistical parsing, constituent/dependency parsing, grammatical function labeling.  Le problème que nous nous posons ici est de produire une analyse syntaxique statistique à la  fois en constituants et en dépendances pour le Français. Si les constituants permettent d'exprimer des généralisations structurales évidentes, les dépendances ont l'avantage de permettre une extraction plus directe des structures argumentales. Elles constituent également un format linguistiquement plus neutre pour l'évaluation de la tâche d'analyse syntaxique, qu'il s'agisse d'une évaluation entre analyseurs ou d'une évaluation intrinsèque : la mesure Parseval habituellement utilisée pour les constituants (on y compte rappel et précision sur les constituants, où un constituant est correct si son type et ses frontières sont correctes) est connue comme très sensible au schéma d'annotation et au ratio nombre de terminaux / nombre de non-terminaux (Lin, 1995). Une motivation supplémentaire pour obtenir à la fois des constituants et des dépendances est d'ordre pratique : dans la littérature de parsing statistique de l'anglais, l'extraction de dépendances non typées à partir d'arbres de constituants semble plus performante que la production directe d'arbres de dépendances (McDonald et al., 2005). Pour la production d'arbres de dépendances typées, on manque de comparaison entre production directe et production via une analyse en constituants.  L'approche pratique pour obtenir cette analyse statistique est de s'appuyer sur un analyseur  statistique en constituants, décrit par (Crabbé & Candito, 2008), entraîné sur le French Treebank (Abeillé et al., 2003) ci-après F . Un module supplémentaire prend en entrée les sorties en constituants de cet analyseur et les convertit en dépendances typées comme illustré en Figure 1.  Les structures syntagmatiques fournies par l'analyseur statistique en constituants suivent le  schéma d'annotation du F , moins les annotations fonctionnelles. Or, sans ces annotations, la fonction des dépendants n'est pas directement déductible de la forme des arbres (par exemple, dans la Figure 1, le NP postverbal la semaine dernière est un modifieur temporel mais pourrait structurellement être un objet). C'est bien pour cette raison que les auteurs du F ont encodé sur les constituants la fonction des dépendants de verbes, les autres cas étant considérés comme déductibles de la seule structure syntagmatique (Abeillé & Barrier, 2004).  Le propos de cet article est de montrer comment tirer parti de cette information supplémentaire  pour extraire une analyse en dépendances à partir de l'analyse en constituants. Nous spécifions en section 2 la représentation en dépendances visées, et la procédure de conversion du F vers des dépendances. La section 3 détaille l'architecture d'analyse, et motive un processus en deux étapes. La section 4 présente plus particulièrement la tâche d'étiquetage fonctionnel. Nous terminons avec des comparaisons avec l'existant et des perspectives d'amélioration. Il existe de multiples schémas d'annotation en dépendances, comme le schéma EASy (Paroubek et al., 2005), ou des standards internationaux tels le schéma GR (Carroll et al., 1998), défini comme un format plus adapté à l'évaluation de parsers, le schéma Stanford Dependencies (catherine De Marneffe et al., 2006), issu d'une conversion automatique du Penn TreeBank, ou le schéma PARC 700 (King et al., 2003), inspiré des structures fonctionnelles de LFG. La multiplicité de ces schémas d'annotation tient pour partie à des choix linguistiques et pratiques différents, notamment sur le caractère surfacique ou pas des dépendances. Ainsi par exemple les  relations de contrôle sont sensées être encodées pour les 4 formats cités, mais les dépendances  sur mots sémantiquement vides n'apparaissent que pour GR et Stanford. Nous avons préféré définir un schéma d'annotation uniquement en dépendances, et en dépendances purement de surface, dont le format soit un pivot convertible vers les différents standards cités, et un pivot enrichissable ou convertible en dépendances plus profondes.  L'objectif pratique à court terme était de convertir vers ce format en dépendances les arbres  syntagmatiques du F , et plus généralement les analyses fournies par les parsers appris sur le F , ce qui permet d'évaluer les dernières sur les premières. Nous décrivons ici le schéma d'annotation en dépendances choisi, la procédure de conversion du F vers ce schéma, et l'écart entre l'annotation visée et l'annotation obtenue automatiquement. Caractéristiques linguistiques générales : On entend ici spécifier des dépendances : la dépendance syntaxique représente le fait que la présence d'un mot est légitimée par un autre mot, son gouverneur . De plus il s'agit de dépendances "surfaciques", c'est-à-dire des relations entre formes fléchies, où toute forme fléchie, même sémantiquement vide, est représentée, et a un et un seul gouverneur, sauf pour la forme tête de la phrase . Donc, par exemple, les relations de contrôle ne sont pas encodées dans ce schéma.  Caractéristiques formelles : Formellement, ces caractéristiques linguistiques impliquent que  la structure de dépendance associée à une phrase est un arbre orienté - un graphe acyclique et connexe - dont les noeuds correspondent aux tokens de la phrase, et dont les arcs correspondent aux dépendances et sont étiquetés par une relation de dépendance. Les noeuds sont étiquetés par une forme fléchie, un lemme et sa catégorie syntaxique. Les catégories sont celles du F . L'ordre linéaire de la phrase est encodé par un identifiant sur les noeuds, de type entier, local à chaque phrase. A noter que le schéma d'annotation n'impose pas la projectivité : la projection d'un noeud peut correspondre à un segment discontinu de la phrase. L'arbre de dépendances pour une phrase est encodé avec un format parenthésé, où les dépendances apparaissent sous la forme de triplets relation ( gouverneur~id linéaire , dépendant~id linéaire ).  Spécifications pour le français : Nous définissons un schéma d'annotation en dépendances de  surface pour le français (ci-après l'annotation deps), qui suit largement l'annotation en constituants préconisée dans le F , avec toutefois quelques cas où l'annotation en constituants n'est pas assez précise, et des cas de divergences . En comparaison du format standard français EASy (Paroubek et al., 2005), le propos est d'obtenir un format entièrement en dépendances, et clairement de surface.  La liste des relations utilisées comprend les fonctions définies dans le F  (où les fonctions ne sont annotées que pour les dépendants de verbes). Nous étendons l'utilisation de ces fonctions dans deux cas, non annotés dans le F : (i) les dépendants dans une participiale passée et (ii) les dépendants adverbiaux réduits à un seul mot comme dans ils sont là. On ajoute par ailleurs  les relations aux_tps, aux_pass, aux_caus pour les auxiliaires et aff pour les clitiques figés.   Pour les autres catégories de gouverneurs, on utilise les relations mod, mod_rel, coord, arg,  arg_coord, arg_comp, arg_cons, det et ponct. On ne gère pas la sous-catégorisation des têtes non verbales. Donc, dans le cas de dépendants prépositionnels, pour un gouverneur non verbal, on ne distingue pas les arguments et les ajouts, et on utilise la relation générique dep par défaut. On choisit pour la coordination un schéma où le premier conjoint gouverne le coordonnant, et le coordonnant gouverne la suite de la coordination (Exemple (d) en Figure 2). Concernant les prépositions, on choisit d'encoder la préposition comme gouverneur, que l'objet de la préposition soit nominal ou infinitival, et que la préposition soit sémantiquement pleine ou vide. A noter que le F encode comme préposition les cas de de ou à introduisant une infinitive directe, comme dans Paul promet de partir. Nous gardons la catégorie prep du F et codons obj(promet~1,de~2), obj(de~2,partir~3). Pour les conjonctions introduisant une phrase, on uniformise également le traitement, que la conjonction soit sémantiquement pleine ou vide : la conjonction est gouverneur du verbe de la phrase qu'elle introduit (ou autre catégorie de syntagme en cas d'ellipse), avec une dépendance de type obj.  Cas de non-projectivité : Les cas de non projectivité recensés actuellement sont au nombre  de quatre : Extraction : Dans A ces cinq départs, trois autres sont susceptibles de s'ajouter, le gouverneur de départs est ajouter ; Extraction hors du SN (clitique en ) : Pour afin d'en amé- liorer l'efficacité, le gouverneur de en est efficacité. Extraction hors du SN (relatif dont ) . Il y a non projectivité dans le cas où le SN est objet dans la relative : dans Lyonnaise Espana, dont le groupe français ne détiendra plus que 51%, le gouverneur de dont est %. Comparatives : on choisit de faire dépendre la comparative de l'adverbe comparatif. Aussi on aura non projectivité dès une discontinuité entre l'adverbe et la comparative : Dans La croissance est actuellement plus faible que ce qu'il prévoyait, le gouverneur de que est plus. Même principe pour les infinitives consécutives comme dans trop rapide pour être durable (exemple (a) en figure 2). TB  On décrit ici la conversion d'un arbre syntagmatique de type F  (on parlera dans la suite de type ftb-f ) vers le schéma deps défini ci-dessus. La conversion se fait en trois étapes, dont les deux premières sont automatiques et la troisième est manuelle. Pour faciliter la lecture, on nomme les formats intermédiaires, et on peut décrire la conversion par : ftb-f =auto  deps- ftb =auto  deps-ftb-f+ =manuel deps.  Isomorphie constituants/dépendances (ftb-f   deps-ftb) : Dans cette première étape on commence par un marquage automatique de la tête de chaque constituant, en utilisant une table de propagation de têtes (initialement proposée par (Magerman, 1995), nous utilisons une table modifiée à partir de (Arun & Keller, 2005)). Cette table contient des règles du type "pour un  constituant NP, la tête est le premier N en partant de la gauche s'il existe, sinon le premier A,  sinon ...". Ceci permet de remonter sur chaque noeud syntagmatique sa tête lexicale. Ensuite les dépendances peuvent être extraites ainsi : pour chaque constituant C, dont le fils tête est un noeud H, annoté avec la tête lexicale h, pour chaque noeud F, frère du noeud H, annoté avec la tête lexicale f, on extrait la dépendance dep(h, f). Si en outre le noeud F porte une étiquette fonctionnelle func, alors on type la dépendance extraite : func(h, f). Cette étape produit des dépendances partiellement sous-spécifiées (deps-ftb), i.e. où le type de dépendance n'est renseigné que pour les cas où une étiquette fonctionnelle est présente dans l'entrée syntagmatique.  Typage des dépendances non typées dans le F  (deps-ftb  deps-ftb-f+) : Une deuxième étape consiste à préciser les types de dépendances pour les cas non renseignés par l'étape précédente. Nous utilisons des heuristiques, initialement écrites par Mathieu Falco , utilisant simplement la structure syntagmatique et la structure de dépendances partielles.  Révision manuelle (deps-ftb-f  + deps) : Les deux étapes précédentes ne peuvent, en l'état actuel des heuristiques, coder certaines spécifications de l'annotation deps, notamment pour les cas de non projectivité cités supra : la conversion ne crée jamais de non-projectivité. Pour évaluer la qualité des dépendances produites automatiquement, et l'écart par rapport à l'annotation visée, et juger de l'opportunité d'une phase de révision manuelle de tout le corpus, nous avons corrigé manuellement la conversion de 120 phrases consécutives du F . Ce sous-corpus (ci-après 7-120) comporte 2894 mots sans compter la ponctuation.  Evaluation : L'évaluation consiste à calculer rappel, précision et F-score des dépendances  produites automatiquement par rapport à celles révisées manuellement, pour le sous-corpus 7-120. On ignore les cas où la dépendance dans la référence est de type ponct. On obtient F =98.00% en dépendances typées , et F =98.78% en dépendances non typées (i.e. en ignorant le type de dépendances pour compter les dépendances correctes, mais toujours en écartant les dépendances de type ponct). Cela permet de conclure que le 7-120 ne contient pas plus de 1,22% de dépendances non projectives . Les erreurs supplémentaires de typage sont dues au caractère trop grossier des heuristiques.  Le résultat de la conversion automatique du F  , et le sous-corpus manuellement validés sont disponibles sous réserve de licence du F . Le corpus complet, correspond à une "pseudoréférence" en dépendances de surface, qui, si l'on projette l'évaluation du 7-120, contient environ 2% d'erreurs.  Dans le cadre de l'analyse syntaxique automatique, on peut adapter la procédure de conversion  de treebank donnée précédemment en faisant produire à l'analyseur automatique une sortie analogue à l'entrée de la procédure de conversion en dépendances sur le French Treebank. Pour  cela, il faut pouvoir ajouter les étiquettes fonctionnelles sur les dépendants verbaux. Dans ce  qui suit nous utilisons le protocole expérimental décrit par (Crabbé & Candito, 2008) qui divise le corpus en trois parties : entrainement : 80% , développement 10% et test 10%. L'analyseur en constituants utilisé est l'analyseur faiblement lexicalisé de Berkeley (décrit pour le Français par (Candito et al., 2009) comme supérieur, en constituants et en dépendances non typées, aux analyseurs dits lexicalisés).  Analyse intégrée La manière la plus évidente de réaliser cela, c'est d'apprendre une grammaire  dont les symboles ne sont pas uniquement des constituants (comme NP ) mais des symboles intégrant l'information fonctionelle (comme NP-SUJ ) pour les noeuds comportant cette annotation dans le treebank. Cette approche, bien que simple et directe, donne un mauvais résultat : le FScore de l'analyse en constituants chute de 86.4 à 78.8. Cette dégradation de résultats est peut être due à deux facteurs : premièrement la division des symboles non terminaux comme NP en symboles plus raffinés (comme NP-SUJ, NP-OBJ,NP-MOD... ) entraîne une démultiplication du nombre de règles et par conséquent un accroissement des effets de dispersion de données. La seconde explication est que les informations fonctionnelles attachées aux dépendants verbaux encodent la sous-catégorisation verbale. La tête verbale a un rôle prépondérant pour décider de la fonction du dépendant. Or l'approche intégrée ne modélise pas la souscatégorisation, car la règle de grammaire supposée émettre les dépendants est émise indépendamment de la tête verbale, par définition de P et par configuration des arbres du treebank.  Analyse séquentielle Pour remédier à ces deux problèmes, on opte ici pour une analyse en  séquence : une première passe procède à l'analyse en constituants dépourvue d'étiquettes fonctionnelles en utilisant un modèle faiblement lexicalisé qui se révèle meilleur pour modéliser la constituance. Une seconde passe d'étiquetage fonctionnel procède à l'ajout des étiquettes de fonction en utilisant un modèle lexicalisé, c'est-à-dire un modèle où les fonctions sont émises en tenant compte (entre autres) de la tête verbale. L'analyse séquentielle permet de préserver un meilleur F-Score en constituants : ainsi le F-score obtenu avec le meilleur modèle séquentialisé décrit ci-dessous est de 83.3 comparé à 78.8 pour l'approche intégrée.  Cette section décrit un système automatique d'étiquetage en fonctions grammaticales qui opère  en aval de l'analyse en constituants. Ce système repose sur des méthodes d'apprentissage supervisé, en particulier des modèles discriminants. Ces modèles sont plus expressifs que P car ils permettent de prendre des décisions sur base de traits non locaux à une règle de grammaire.  Notre système cible les relations de dépendance entre un prédicat verbal et les syntagmes qui  apparaissent comme frères du noeud verbal dans le F . On appellera gouverneur (ou g) le verbe et dépendant (ou d) le noeud syntagmatique relié au verbe. Le F distingue huit types distincts de fonctions grammaticales, à savoir : SUJ , OBJ , A-OBJ , DE-OBJ , P-OBJ , MOD , ATS , ATO .  De manière générale, la tâche d'étiquetage fonctionnel consiste à prédire une séquence de n   fonctions grammaticales  {f , . . . , f } étant donné un gouverneur g et une séquence de n dépendants {d , . . . , d }. Vu en termes probabilistes, le but de l'apprentissage revient à estimer la probabilité conditionnelle suivante : p ({f , . . . , f }|g, {d , . . . , d }). Il est bien entendu impossible d'estimer correctement de telles probabilités pour des problèmes évidents de dispersion des données. En pratique, on peut néanmoins simplifier le problème en faisant l'hypothèse d'indépendance suivante :  p  ({f , . . . , f }|g, {d , . . . , d })  p (f |g, d ) (1)  Ce qui revient à supposer que les étiquetages de chaque fonction f  grammaticale à un dépendant d se font indépendamment les unes des autres. La tâche d'étiquetage fonctionnel se réduit alors à un simple problème de classification (où chaque dépendant se voit assigner une fonction syntaxique unique). La tâche d'apprentissage revient, quant à elle, à apprendre une fonction de D dans F , où D représente l'ensemble des dépendants et F l'ensemble des 8 fonctions grammaticales mentionnées. Concrètement, chaque dépendant est représenté par un vecteur de traits, qui décrit le dépendant, son contexte, et sa relation au gouverneur. Les différents schémas de traits utilisés sont résumés dans le tableau 1. Le processus d'extraction de ces différents traits à partir des structures de consistuance est présenté dans la figure 3.  Les traits W  , W , C , C , C , W capturent des dépendances bilexicales entre le mot tête et le mot dépendant en incluant de la redondance, comme les catégories, pour obtenir des comptes de granularités variées analogues aux modèles de lissage de (Collins, 1999; Charniak, 2000) pour l'analyse en constituants de l'anglais reposant sur des modèles bayésiens. Ne disposant pas de lemmatiseur déterministe, nous avons procédé pour W et W à un stemmage brutal : à savoir, les 4 premiers caractères. Les hapax dans le corpus d'entraînement sont remplacés par un symbole unique, permettant ainsi de gérer les mots inconnus. Notons encore que les valeurs des traits dist et span ont été discrétisées également de manière à réduire la dispersion des données.  Les traits C  , LC , RC , dist, span, M , rank, wh, rel, etre, inv capturent, quant à eux, des informations configurationnelles. Par exemple plus un dépendant est éloigné de la tête, plus il a tendance à être un modifieur, les trait LC , RC vont par exemple permettre d'identifier si le dépendant est précédé ou suivi d'une ponctuation. Un dépendant séparé de la tête par une  ponctuation sera plutôt un modifieur. Le mode permet par exemple de pénaliser l'assignation de  sujets à l'infinitif ou à l'impératif. L'auxiliaire être est une approximation grossière du passif, et doit favoriser l'étiquetage d'une fonction P-OBJ (fonction du complément d'agent), etc.  partie "Le Monde" du corpus EASy.   (Abeillé & Barrier, 2004) décrivent la tâche d'annotation fonctionnelle du F  , pour laquelle ils ont utilisé une annotation automatique, faite par règles, préalable à une révision manuelle. Les auteurs annoncent un rappel et une précision de 89.69% et 89.27% , comparables aux résultats obtenus ici par approche statistique.  (Schluter & van Genabith, 2008) proposent une architecture de parsing statistique 'profond'  du français, avec un parser appris sur le 'modified French Treebank' : un corpus comprenant environ la moitié des phrases du F , avec modification du schéma d'annotation, correction manuelle, et ajout de chemins fonctionnels encodant les dépendances non bornées. Le parser appris produit des couples structure-c/structure-f de type LFG. Les auteurs évaluent leur parser en rappel/précision/F sur les traits des structures fonctionnelles produites. Ils relatent un F de 86.73%, pour un parsing avec tagging parfait préalable. Ces résultats ne sont pas exactement comparables aux nôtres : d'un côté le tagging parfait augmentent leur score, d'un autre côté, les dépendances encodées dans les structures fonctionnelles sont moins surfaciques et donc constituent une tâche plus difficile.  Plus directement comparables sont les résultats de la campagne d'évaluation EASy (Paroubek  et al., 2005). Le meilleur analyseur, Syntex (Bourigault et al., 2005) donne un F = 66% sur sous-corpus Le Monde compris dans EASy, score équivalent à ceux obtenus ici. Cependant, le parser statistique présenté ici a des performances nettement moins bonnes lorsque l'on change de domaine (par exemple F = 61% sur le corpus médical, contre F = 70% pour l'analyseur Syntex). Cet article présente une architecture pour l'analyse syntaxique statistique du français journalistique, qui repose sur un processus séquentiel : analyse en constituants d'abord, extraction de dépendances ensuite. Du point de vue de la modélisation, l'architecture présentée ici fait deux hypothèses simplificatrices essentielles : le modèle génératif en constituants est vu comme indépendant du modèle discriminant d'analyse fonctionnelle et l'étiquetage fonctionnel assigne les fonctions indépendamment à chaque dépendant alors qu'on sait qu'il s'agit d'un problème de séquence, qui doit modéliser une notion de sous-catégorisation. Il reste à investiguer comment lever ces deux hypothèses. La première pourrait être levée en reformulant le modèle discriminant comme un modèle de reranking sur une analyse en constituants intégrée. La seconde demande de modéliser explicitement des séquences de dépendants (incluant arguments et modifieurs) de manière à modéliser des cadres de sous-catégorisation.  Du point de vue plus linguistique cette fois, il s'agira d'exploiter les dépendances de surface   (issues de la conversion du F  ou bien du résultat du parser) pour obtenir des dépendances plus profondes (relations de contrôle, suppression des mots sémantiquement vides...).  
