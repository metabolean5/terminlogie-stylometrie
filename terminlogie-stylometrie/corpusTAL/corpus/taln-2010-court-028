Face à l'abondance et à la prolifération des données textuelles, l'accès à l'information pertinente dans  les corpus est devenu un enjeu majeur avec des besoins dans différents domaines. On peut citer l'analyse du discours évaluatif qui connaît un intérêt croissant pour des applications telles que la veille d'opinions, l'analyse de tendances ou de marchés (Pang & Lee, 2007). Les approches symboliques du traitement automatique des langues dédiées à l'extraction d'information reposent sur des ressources élaborées manuellement dont le coût est important en temps de développement, voire prohibitif lorsqu'il s'agit de les adapter à un nouveau domaine (Poibeau, 2003). C'est pourquoi les méthodes permettant d'apprendre automatiquement les ressources connaissent un essor important. Certaines approches s'appuient sur des corpus annotés (Califf & Mooney, 2003) souvent difficiles à obtenir. D'autres méthodes utilisent des corpus bruts (Riloff, 1996) mais elles reposent sur une analyse syntaxique qui impacte la qualité des résultats. On peut aussi citer les approches dans la lignée de (Hearst, 1992) qui visent à acquérir des relations sémantiques d'un type particulier (hyperonymie) pour enrichir automatiquement des lexiques ou des ontologies. Dans (Charnois et al., 2009) une approche a été proposée pour apprendre automatiquement des patrons linguistiques pour la découverte de relations entre entités nommées. Cette approche s'appuie sur l'utilisation de motifs séquentiels d'items, qui permettent de générer automatiquement des patrons linguistiques, et sur la fouille de données récursive des motifs qui permet de gérer la quantité de patrons extraits. Cette  Identifiant  Séquence 1 (homme homme N OM )(de de PRP )(culture culture NOM ) 2 (en en PRP )(vieux vieux ADJ)(farceur farceur NOM )(misanthrope misanthrope ADJ) 3 (réputé réputer VER pper )(pour pour PRP )(sa son DET POS)(cruauté cruauté NOM )  approche a l'avantage de ne pas nécessiter d'analyse syntaxique ni de ressource extérieure autre qu'un  corpus d'apprentissage brut, et n'est pas dédiée à l'apprentissage d'un type de patrons spécifiques.  Dans cet article, nous proposons une méthode basée sur les motifs séquentiels d'itemsets. Cela signifie  qu'au lieu de décrire un mot par un seul item (son lemme ou sa catégorie grammaticale ou la conjonction des deux) comme dans (Charnois et al., 2009), un mot est décrit par un ensemble d'items. L'avantage de cette description plus riche est de pouvoir générer automatiquement des patrons linguistiques sophistiqués contenant à la fois des lemmes et des catégories grammaticales, comme le patron « homme de NOM ». De plus, pour gérer le problème du grand nombre de motifs extraits à valider par un expert, nous proposons de nous appuyer sur l'ordre partiel existant entre ces motifs. Cela permet une énumération structurée des motifs et facilite leur exploration. Nous appliquons notre approche à l'apprentissage de patrons linguistiques pour la découverte de constituants en position détachée, extra-prédicatifs, et porteurs de qualification, voire de jugement, comme illustrée dans la table 1. Toutefois, le processus peut être facilement adapté pour découvrir d'autres types de patrons linguistiques Dans la section 2, la méthode proposée est détaillée. La section 3 présente l'application de la méthode pour la découverte d'expressions qualificatives.  L'extraction automatique des patrons linguistiques et leur validation s'effectuent en deux étapes : 1) les  motifs séquentiels fréquents sont extraits de la base d'exemples ; 2) ces motifs extraits sont ensuite structurés dans un diagramme de Hasse afin de faciliter leur sélection en tant que patrons linguistiques.  L'extraction de motifs séquentiels d'itemsets a été introduite dans (Agrawal & Srikant, 1995; Srikant &  Agrawal, 1996). L'extraction de motifs séquentiels se fait à partir d'une base de séquences, BDD, où chaque séquence est décrite par une liste ordonnée d'ensembles de littéraux appelés items. Un ensemble d'items est communément appelé itemset, noté (i i ...i ) où les i sont des items. Une séquence est donc une liste ordonnée d'itemsets, notée s ...s où les s sont des itemsets. Dans le cas de la découverte de patrons linguistiques, nous constituons une base de séquences (la base d'exemples) à partir de morceaux de texte. Chaque morceau de texte représente donc une séquence de la base et est décrit par l'ensemble des mots qui le composent. Les mots sont représentés par des itemsets qui décrivent le mot par sa forme fléchie, son lemme et sa catégorie grammaticale . Un extrait de base contenant 3 constituants en position  détachée de qualification est donné à la table 1. Une séquence, S  = a ...a est contenue dans une séquence S = b ...b s'il existe des entiers i < ... < i tels que a  b , ..., a  b . S est alors appelée sous-séquence de S , noté S  S . Le support d'une séquence , S, dans une base, BDD, est le nombre de séquences de BDD qui contiennent S. Par exemple, pour le motif (P RP )(ADJ) son support dans BDD est de 1 (Séquence 2). Les motifs séquentiels ne sont pas nécessairement des suites contigues. Par exemple, le motif (P RP )(ADJ) couvre aussi l'expression « en homme courageux ». Un motif séquentiel fréquent dans BDD est une séquence dont le support est supérieur à un seuil fixé : minsup. Notons que l'utilisation des itemsets permet une description plus riche des mots que l'utilisation de simples items. Cet ajout d'information sur les mots donne la possibilité de découvrir des patrons linguistiques plus sophistiqués, composés d'information mixte comme à la fois les lemmes mais aussi les catégories grammaticales. Par exemple, on trouve des patrons linguistiques de la forme : (en P RP ) (homme N OM )(de P RP )(N OM ) . Pour diriger l'extraction des motifs séquentiels vers l'objectif de l'utilisateur, on définit des contraintes sur les motifs à extraitre. Par exemple, la contrainte gap (Dong & Pei, 2007) impose que pour que S soit contenue dans S il faut que chaque couple d'itemsets adjacents de S ne soit pas séparé dans S par plus d'un certain nombre d'itemsets. Ce nombre est appelé maxgap. Les contraintes linguistiques permettent de définir le type de patrons linguistiques recherchés.  Beaucoup de motifs séquentiels sont générés. Pour pallier à ce problème nous utilisons une représentation  condensée des motifs qui élimine les redondances entre motifs : les motifs fermés (Yan et al., 2003), et un ordre partiel qui permet d'avoir une énumération des motifs structurée et de faciliter leur exploration.  Un motif fréquent, S, est un motif fermé fréquent, s'il n'existe pas de motif fréquent S  tel que S < S et sup (S) = sup(S ). Par exemple, soient S = (homme N OM ) (de) (N OM ) et S = (homme N OM )  (de) (culture N OM ) deux séquences telles que sup(S) = sup(S  ) = 10, alors S n'est pas un motif fermé. En effet les 10 exemples couverts par le motif S sont aussi couverts par le motif S .  Les motifs fermés fréquents extraits sont partiellement ordonnés entre eux. Afin de mieux visualiser cette  relation d'ordre on peut afficher les motifs dans un diagramme de Hasse qui est une représentation graphique d'un ordre partiel (Davey & Priestley, 1990). Un exemple de diagramme de Hasse est présenté à la figure 2. La taille du diagramme de Hasse peut être trop grande pour que le diagramme soit affiché entièrement. Nous proposons donc d'utiliser un outil de navigation permettant de naviguer dans le diagramme des motifs les plus généraux aux plus spécifiques afin de les valider en tant que patrons linguistiques. À la figure 1 nous donnons un exemple de navigation avec l'outil Camelis (Ferré, 2009). La navigation se fait via « l'arbre de navigation » se trouvant à gauche de l'outil. Notons que lorsqu'un motif, M , est sélectionné par l'expert comme patron linguistique, tous les motifs dont M est une sous-séquence ne sont plus à examiner. En effet, lors de l'application des patrons, les morceaux de texte qu'ils reconnaissent sont inclus dans les morceaux de texte reconnus par M . Camelis offre la possibilité de marquer les motifs validés comme patrons linguistiques et donc de ne plus les afficher ainsi que les motifs qui les contiennent (cf « not 'Motif Valide' » dans figure 1), réduisant l'espace des motifs à vérifier et facilitant l'exploration.  Nous avons appliqué notre méthode à l'apprentissage de patrons linguistiques dénotant des expressions  porteuses de qualification et en position détachée comme décrites dans (Jackiewicz et al., 2009a). Les expressions en gras dans les exemples (1) et (2) illustrent le type d'expressions qui nous intéressent :  (1) Ni trop sentimental, ni trop énergique, il maîtrise, avec une finesse quasi mozartienne, un [...]  (2) Figure légendaire de l'opposition au régime communiste, éminent professeur d'histoire médié- vale, ministre des affaires étrangères de la Pologne de 1997 à 2000, Bronislaw Geremek avait [...]  Nous souhaitons apprendre des patrons linquistiques comme ceux définis manuellement par (Jackiewicz  et al., 2009a), par exemple : - Groupes nominaux (GN) : [det] N de GN (Femme de tête,X ; X, le maestro de la désinflation). - Adverbes (courageusement, X) ; groupes prépositionnels (en mauvaise posture, X). - Constructions détachées : groupes adjectivaux (imprévisible et fantasque, X) ; constructions absolues (l'oeil vigilant, X) ; participes (réputé pour son caractère bourru, X).  Deux corpus d'apprentissage ont été générés automatiquement pour pallier l'absence de corpus disponible.  Le corpus AXIOLO est issu des expériences de (Jackiewicz et al., 2009a). Il est constitué d'expressions reconnues par application d'une dizaine de patrons élaborés manuellement sur des articles issus du journal Le Monde, catégorie « Portraits », de la période juillet à décembre 2002 (soit 884 articles), ainsi que sur la période 2003 à 2006 de l'ensemble des articles du Monde pour deux autres patrons spécifiques : en Adj <expansion> et en N <expansion> (Jackiewicz et al., 2009b). Ce corpus d'expressions qualificatives  contient  4 063 expressions (i.e. séquences), ce qui représente 12 257 mots. Il est très peu bruité. Le corpus ARTS a été généré à partir de règles heuristiques sur les articles de la rubrique &#34;Art&#34; du journal Le Monde, année 2006, soit 3 539 articles. Ces heuristiques sont destinées à filtrer parmi les constituants périphériques ceux qui ne sont a priori pas porteurs de qualification (exemples : proposition de la phrase contenant un verbe conjugué, groupe circonstanciel de temps, espace, but, causalité). Ce corpus est constitué de 13 576 expressions (i.e. séquences), ce qui représente 85 153 mots. Il contient des exemples négatifs. Nous estimons à environ 32% le pourcentage d'expressions non qualificatives (bruit). Paramètres de l'apprentissage. Pour le calcul des motifs fermés d'itemsets, nous avons utilisé l'implémentation de Clospan (Yan et al., 2003) proposée dans Illimine . Nous cherchons des patrons linguistiques décrivant des expressions de qualification en position détachée. Pour cela, nous fixons deux contraintes sur les motifs à extraire : 1) ils débutent l'expression ; 2) ils sont formés d'éléments contigüs (maxgap=0). Pour chacun des deux corpus nous avons calculé les motifs séquentiels en faisant varier les valeurs du seuil de support, minsup, de 50% à 0, 05%. On constate que des seuils de support élevés (50% ou 25%) ne fournissent que des motifs très généraux où seuls les catégories grammaticales apparaissent. Il est donc plus intéressant de choisir des seuils de support très bas pour obtenir des motifs spécifiques et capturer des expressions, ou phénomènes, linguistiques peu fréquents .  Résultats quantitatifs. Avec le corpus AXIOLO, pour minsup  = 0, 05 (2 expressions), 8 264 motifs fermés fréquents sont extraits en moins d'une seconde. Après application des deux contraintes il reste 1 789 motifs. Avec le corpus ARTS, pour minsup = 0, 05 (6 expressions), environ 8 millions de motifs fermés fréquents sont extraits en 7h. Après application des contraintes il reste 7 818 motifs .  Résultats qualitatifs et discussion. Des expériences ont été conduites en ne considérant qu'un seul item  pour décrire un mot comme dans (Charnois et al., 2009). Sans surprise, on constate que les motifs découverts sont soit très spécifiques (par exemple : homme de conviction pour les séquences représentées par les lemmes seuls), soit très génériques ( N OM P RP N OM ) lorsque les séquences ne sont formées que des catégories grammaticales. Un motif comme (homme)(de P RP )(N OM ) ne peut être appris qu'à partir de séquences d'itemsets. De plus, l'analyse des motifs séquentiels d'itemsets extraits du corpus AXIOLO montre la complétude de la méthode. On retrouve en effet tous les motifs présentés précédemment et qui ont servi à générer ce corpus. Enfin, les expériences réalisées sur le corpus ARTS ont permis de tester la méthode à une échelle relativement importante sur un corpus généré automatiquement et non annoté. L'ensemble des motifs produits comporte des motifs inintéressants dûs au bruit présent dans le corpus. Face à ce problème, la navigation au sein de la hiérarchie des motifs est un point fort de la méthode permettant aisément d'élaguer des groupes de motifs inintéressants. Enfin, de nouveaux patrons sont extraits au regard de ceux déjà conçus manuellement dans (Jackiewicz et al., 2009a). C'est le cas du motif (ADJ pour DET N OM ) (&#34;célèbre pour son monastère&#34;, &#34;baroque pour une histoire d'amour&#34;, ...) et de ses variantes ou extensions : (ADV )(ADJ)(pour) (&#34;très célèbre pour...&#34;), (ADJ)(pour)(V ER) (&#34;indispensable pour assurer...&#34;).  Dans cet article nous présentons une méthode utilisant l'extraction de motifs séquentiels d'itemsets pour  la génération automatique de patrons linguistiques. Cette approche a l'avantage d'éviter un recoupement manuel d'expressions pour déterminer des patrons. De plus, les patrons extraits sont compréhensibles par un humain. L'avantage de décrire les mots non plus par un seul lemme comme dans (Charnois et al., 2009), mais par un ensemble d'items, est une plus grande expressivité des patrons linguistiques découverts (combinant des informations hétérogènes). Nous proposons aussi une solution pour gérer le nombre de motifs extraits en s'appuyant sur un ordre partiel qui existe entre ces motifs. Un utilisateur humain peut ainsi facilement naviguer dans les motifs et les valider en tant que patrons linguistiques. Nous avons utilisé notre méthode pour l'apprentissage de patrons linguistiques pour la reconnaissance de constituants de qualification en position détachée. Le processus peut être utilisé pour apprendre d'autres types de patrons linguistiques, comme les relations entre entités nommées, en définissant des contraintes appropriées.  
