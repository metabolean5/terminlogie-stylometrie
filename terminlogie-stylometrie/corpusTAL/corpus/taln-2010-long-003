De nombreux systèmes pour l'étiquetage automatique en parties du discours ont été développés pour un  large éventail de langues. Parmi les systèmes les plus performants, on trouve ceux qui s'appuient sur des techniques d'apprentissage automatique . Pour certaines langues comme l'anglais ou d'autres langues très étudiées, ces systèmes ont atteint des niveaux de performance proches des niveaux humains. Il est intéressant de constater que la majorité de ces systèmes n'ont pas recours à une source externe d'informations lexicales, et se contentent d'un lexique extrait « à la volée » à partir du corpus d'apprentissage (cf. cependant (Hajic, 2000)). On est donc en droit de se demander s'il est possible d'améliorer encore les performances des étiqueteurs en exploitant ce type de ressources. Un avantage potentiel de l'utilisation d'un lexique externe consiste en un meilleur traitement des mots « inconnus », c'est-à-dire des mots absents du corpus d'apprentissage, dès lors qu'ils sont présents dans le lexique externe.  Dans (Denis & Sagot, 2009), nous avons montré qu'un modèle d'étiquetage peut bénéficier à la fois  d'informations provenant d'un corpus d'entraînement et d'un lexique exogène à large couverture. Nous avons pour cela utilisé des modèles markoviens à maximisation d'entropie, à savoir une classe de modèles discriminants adaptés aux problèmes séquentiels et par ailleurs très rapides à entraîner. Les expériences menées en couplant ainsi le Corpus Arboré de Paris 7, dorénavant pour French TreeBank (Abeillé et al. , 2003), et le lexique Lefff (Sagot, 2010) ont ainsi conduit à un étiqueteur de niveau état de l'art pour le français, nommé MElt et distribué librement , qui a une précision de 97, 7% sur le jeu de test. (Denis & Sagot, 2009) montre par ailleurs que l'utilisation d'informations extraites du Lefff permet, pour des taux de précision similaires, de réduire le volume du corpus d'entraînement par un facteur de 2 à 3. Indépendamment, un travail comparable, mais qui intègre en plus dans le modèle les informations de lemmatisation, a également montré la pertinence de ce type d'approches (Chrupaa et al., 2008).  Toutefois, les causes précises de l'amélioration des performances lorsque les informations du Lefff sont  exploitées n'avaient pas encore été explorées de façon systématique. On s'attend naturellement à ce que de telles informations supplémentaires améliorent l'étiquetage des mots inconnus. Mais les informations extraites du Lefff sont-elles les plus utiles à propos du mot courant ou du contexte gauche ou droit ? Sont-elles plus cruciales pour étiqueter les mots appartenant à des classes fermées ou ouvertes ?  Pour apporter des éléments de réponse à ces questions, nous avons conduit plusieurs séries d'expériences.  Nous commençons par décrire les ressources utilisées (section 2). Nous détaillons ensuite le fonctionnement et les performances de l'étiqueteur MElt , amélioré depuis sa présentation dans (Denis & Sagot, 2009), et nous le comparons avec d'autres étiqueteurs entraînés sur les mêmes données (section 3). Afin de mieux comprendre la façon dont le couplage avec le Lefff améliore les performances, nous présentons alors des expériences faisant varier la façon dont les informations extraites du Lefff sont exploitées (section 4), puis des expériences faisant varier les jeux d'étiquettes du corpus et du lexique (section 5).  Le corpus annoté en parties du discours que nous avons utilisé est une variante du  . Il diffère du originel en ceci que tous les composés qui ne correspondent pas à une séquence régulière de parties du discours sont fusionnés en un token unique, alors que les autres sont représentés par des séquences de plusieurs tokens (Candito, c.p.). Le corpus résultat contient 350 931 tokens pour 12 351 phrases. Dans le originel, les mots sont répartis en 13 catégories principales, elles-mêmes réparties en 34 sous-catégories. La version du corpus que nous avons utilisée a été obtenue en convertissant ces sous-catégories en un jeu de 29 parties du discours, avec une granularité intermédiaire entre catégories et sous-catégories. Ces 29 étiquettes améliorent les catégories principales par des informations sur le mode des verbes, ainsi que par quelques traits lexicaux supplémentaires. Ce jeu d'étiquettes est celui qui conduit aux meilleurs résultats d'analyse syntaxique probabiliste pour le français (Crabbé & Candito, 2008) . Comme dans (Crabbé & Candito, 2008), le est divisé en 3 sections : entraînement (80%), développement (10%) et test (10%).  Les tailles respectives de ces sections sont détaillées à la table 1, ainsi que les nombres et proportions de  tokens inconnus.  Section  # de phrases # de tokens # de tokens inconnus # de tokens inconnus et absents du Lefff 9 881 278 083 1 235 36 508 1 790 (4, 9%) 604 (1, 7%) 1 235 36 340 1 701 (4, 7%) 588 (1, 6%)  La source d'informations lexicales que nous avons utilisée est le lexique Lefff (Sagot, 2010)  . Nous avons extrait du Lefff 502 223 entrées distinctes de la forme (forme, étiquette), les étiquettes correspondant après conversion au jeu de 29 étiquettes de la variante du décrite ci-dessus et utilisée pour l'apprentissage.  Dans cette section, nous décrivons le modèle markovien à maximisation d'entropie (  ) sur lequel repose l'étiqueteur MElt . Nous présentons d'abord la variante MElt , qui n'exploite pas les informations lexicales du Lefff . Il est comparable aux systèmes de Ratnaparkhi (1996) et Toutanova & Manning (2000), à la fois quant au modèle et quant aux traits utilisés. Aujourd'hui, les étiqueteurs reposant sur ce type de modèles sont parmi les meilleurs pour l'anglais. Un avantage important de ces modèles (sur les modèles de Markov cachés, notamment) est de permettre de combiner ensemble des traits très divers, éventuellement redondants, sans qu'il soit nécessaire de faire une hypothèse d'indépendance entre eux. C'est ce qui nous a permis de construire MElt en rajoutant à MElt des traits lexicaux extraits du Lefff . Enfin, ces modèles sont également attrayants du fait qu'ils sont très rapides à entraîner .  Étant donné un jeu d'étiquettes T et une chaîne de mots (tokens) w  , on définit la tâche d'étiquetage comme le processus consistant à assigner à w la séquence d'étiquettes  t  T de vraisemblance maximale. Suivant (Ratnaparkhi, 1996), on peut alors approcher la probabilité conditionnelle P (t |w ) de sorte que :    t = arg max P (t |w )  arg max P (t |h ), (1)  où t  est l'étiquette du mot w et h est le contexte de (w , t ), qui comprend la séquence des étiquettes déjà assignées t et la séquence des mots w .  Dans un modèle à maximisation d'entropie, on estime les paramètres d'un modèle exponentiel qui a la  forme suivante :  P (t  |h ) = 1 Z(h) · exp  f (h , t ) (2)  Les f  sont des traits, fonctions définies sur l'ensemble des étiquettes t et des historiques h (avec f (h , t )  {0, 1}), les  sont les paramètres associés aux f , et Z(h) est un facteur de normalisation sur les différentes étiquettes. Dans ce type de modèle, le choix des paramètres est assujetti à des contraintes garantissant que l'espérance de chaque trait soit égale à son espérance empirique telle que mesurée sur le corpus d'apprentissage (Berger et al., 1996). Dans nos expériences, les paramètres ont été estimés en utilisant l'algorithme dit Limited Memory Variable Metric Algorithm (Malouf, 2002) implémenté au sein du système Megam (Daumé III, 2004).  Les classes de traits que nous avons utilisées pour la conception du modèle de base MElt  d'étiquetage du français, c'est-à-dire du modèle n'utilisant pas le lexique Lefff , est un sur-ensemble des traits utilisé par (Ratnaparkhi, 1996) et (Toutanova & Manning, 2000) pour l'anglais (qui étaient largement indépendants de la langue). Ces traits peuvent être regroupés en deux sous-ensembles. Le premier rassemble des traits dits internes qui essaient de capturer les caractéristiques du mot à étiqueter. Il s'agit notamment du mot w lui-même, de ses préfixes et suffixes de longueur 1 à 4, ainsi que de traits booléens qui testent si w contient ou non certains caractères particuliers comme les chiffres, le tiret ou les majuscules. Le deuxième ensemble de traits, dits externes, modélise le contexte du mot à étiqueter. Il s'agit tout d'abord des mots qui sont dans les contextes gauche et droit de w (à une distance d'au plus 2). Ensuite, nous intégrons comme traits l'étiquette t assignée au mot précédent, ainsi que la concaténation des étiquettes t et t pour les deux mots précédents w . La liste détaillée des classes de traits utilisées dans MElt est indiquée à la table 2.  Traits internes  w = X & t = T Préfixe de w = P, |P | < 5 & t = T Suffixe de w = S, |S| < 5 & t = T w contient un nombre & t = T w contient un tiret & t = T w contient une majuscule & t = T w contient uniquement des majuscules & t = T w contient une majuscule et n'est pas le premier mot d'une phrase & t = T Traits externes t = X & t = T t t = XY & t = T w = X, j  {2, 1, 1, 2} & t = T  Une différence importante avec le jeu de traits de (Ratnaparkhi, 1996) vient du fait que nous n'avons  pas restreint l'application des traits de type préfixes et suffixes aux mots qui sont rares dans le corpus d'apprentissage. Dans notre modèle, ces traits sont toujours construits, même pour les mots fréquents. En effet, nous avons constaté lors du développement que la prise en compte systématique de ces traits conduit à de meilleurs résultats, notamment sur les mots inconnus. De plus, ces traits sont probablement  plus discriminants sur le français que sur l'anglais, puisque le français est morphologiquement plus riche.  Une autre différence entre notre modèle de base et les travaux antérieurs concerne le lissage. (Ratnaparkhi, 1996) et (Toutanova & Manning, 2000) seuillent leurs traits à un nombre d'occurrence de 10 pour éviter les données statistiquement non significatives. Nous n'avons pas seuillé nos traits mais avons utilisé à la place une régularisation gaussienne sur les poids, ce qui est une technique de lissage plus motivée statistiquement.  L'avantage du modèle sous-jacent à MElt  est de permettre un ajout aisé de traits supplémentaires, y compris de traits dont les valeurs sont calculées à partir d'une ressource externe au corpus d'apprentissage, et notamment d'un lexique comme le Lefff .  Pour chaque mot w  , nous générons une nouvelle série de traits internes basés sur la présence (ou non) de w dans le Lefff et, le cas échéant, les étiquettes associées à w par le Lefff . Si w est associé à une étiquette unique t , nous générons un trait qui encode l'association non ambiguë entre w et t . Lorsque w est associé à plusieurs étiquettes t , . . . , t par le Lefff , nous générons un trait interne pour chacune de ses étiquettes possibles t , ainsi qu'un trait interne qui représente la disjonction de m étiquettes. Enfin, si w n'est pas recensé dans le Lefff , nous créons un trait spécifique qui encode le statut d'inconnu du Lefff . De même, nous utilisons le Lefff pour construire de nouveaux traits externes : nous construisons l'équivalent des traits internes pour les mots des contextes gauche et droit à une distance de moins de 2 du mot courant. Nous générons également des traits bigrammes correspondant à la concaténation des étiquettes du Lefff pour les 2 mots à gauche, les 2 mots à droite, et les deux mots qui entourent w . Lorsque ces mots sont ambigus pour le Lefff , seule leur disjonction contribue au bigramme, et si l'un ce ces mots est inconnu, la valeur unk tient lieu d'étiquette.  La liste détaillée des classes de traits utilisées pour MElt  , en plus de ceux de la table 2, est indiquée à la table 3. Ce jeu de traits étend légèrement celui présenté par (Denis & Sagot, 2009).  Traits lexicaux internes  t = X, if lefff(w ) = {X} & t = T t = X, X  lefff(w ) if |lefff(w )| > 1 & t = T t = lefff(w ) if |lefff(w )| > 1 & t = T t = unk, if lefff(w ) =  & t = T Traits lexicaux externes t = lefff(w ), j  {2, 1, 1, 2} & t = T t t = lefff(w ) lefff(w ), (j, k)  {(2, 1), (+1, +2), (1, +1)} & t = T  Ces différents traits permettent d'avoir une information, ne serait-ce qu'ambiguë, sur les étiquettes dans le  contexte droit du mot, ce que ne permettent pas les traits de base utilisés par MElt . Ceux-ci n'incluent que les étiquettes sur le contexte gauche, les seules à pouvoir être intégrées dans un décodage gauchedroite. Par ailleurs, cette manière d'intégrer les informations issues du lexique au modèle sous forme de traits supplémentaires a l'avantage de ne pas ajouter de contraintes fortes, et d'être ainsi robuste à d'éventuelles erreurs ou incomplétudes du lexique. Une autre façon, plus directe, d'exploiter une ressource lexicale exogène consiste en effet à utiliser les informations lexicales comme filtre. A savoir, on contraint l'étiqueteur à choisir pour un mot w une étiquette correspondant soit à une occurrence de w dans le corpus, soit à une entrée du lexique pour w. C'est l'approche employée par exemple par (Hajic, 2000) pour des langues à morphologie très riche, et notamment pour le tchèque. Dans (Denis & Sagot, 2009), nous avons montré que cette stratégie ne permet d'améliorer que marginalement les performances de MElt , et restent largement en-deçà de celles de MElt .  La procédure de décodage (c'est-à-dire l'étiquetage proprement dit une fois le modèle construit) repose  sur un algorithme de type beam search pour trouver la séquence d'étiquettes la plus probable pour une phrase donnée. Autrement dit, chaque phrase est décodée de gauche à droite, et l'on conserve pour chaque mot w les n séquences d'étiquettes candidates les plus probables du début de la phrase jusqu'à la position i. Pour nos expériences, nous avons utilisé un beam de taille 3 . De plus, la procédure de test utilise un dictionnaire d'étiquettes ) qui liste pour chaque mot les étiquettes qui lui sont associées dans le corpus d'apprentissage. Ceci réduit considérablement l'ensemble des étiquettes parmi lesquelles l'étiqueteur peut choisir pour étiqueter un mot donné, ce qui conduit, comme le montrent nos expériences, à de meilleures performances tant en termes de précision que d'efficacité en temps.  Nous avons comparé les résultats de MElt  et de MElt à divers autres étiqueteurs, dont les deux premiers n'utilisent pas le Lefff , mais qui ont tous été (ré)entraînés d'une façon ou d'une autre sur le corpus d'apprentissage du : - , un étiqueteur de base qui fonctionne comme suit : pour un mot présent dans le corpus d'entraînement, l'étiqueteur assigne l'étiquette la plus fréquemment trouvée dans le corpus ; pour les autres mots, il utilise l'étiquette la plus fréquente du corpus (ici, NC) ; - TreeTagger, un étiqueteur statistique qui repose sur les arbres de décision (Schmid, 1994) réentraîné sur notre corpus d'apprentissage. - , comme , est un modèle unigramme qui repose sur le corpus d'apprentissage, mais qui utilise le Lefff pour étiqueter les mots inconnus : parmi les étiquettes que le Lefff associe à un mot inconnu du corpus, l'étiquette la plus fréquente à l'échelle de tout le corpus est utilisée ; les mots qui sont inconnus et du corpus et du Lefff reçoivent l'étiquette la plus fréquente (ici, NC) ; - TreeTagger est une variante de TreeTagger, le Lefff étant fourni comme lexique externe ; - , une instance de l'analyseur syntaxique de Berkeley tel qu'adapté au français par Crabbé & Candito (2008), et utilisée comme étiqueteur.  Les résultats de cette compraison sur le corpus de test du  font l'objet du tableau 4.  Étiqueteur  Précision globale (%) Précision sur les mots inconnus (%) 91, 90 24, 50 TreeTagger 96, 14 75, 77 93, 40 55, 00 TreeTagger 96, 55 82, 14 97, 25 82, 90 MElt 97, 25 86, 47 MElt 97,75 91,36  Parmi les étiqueteurs ne faisant pas usage du Lefff , on constate que MElt  atteint déjà une précision de 97, 25%, avec 86.47% sur les mots inconnus. Ceci est significativement meilleur que TreeTagger, avec un gain de plus de 10% sur les mots inconnus . On peut avancer plusieurs hypothèses pour expliquer des écarts si importants sur l'étiquetage des mots inconnus. Tout d'abord, l'estimation des paramètres dans un modèle à maximisation d'entropie est moins sujette au problème du manque de données pour certains traits ou certaines valeurs de traits que d'autres approches comme les arbres de décision (utilisés par TreeTagger), notamment parce qu'aucune partition des données d'entraînement n'est effectuée. Par ailleurs, TreeTagger n'est pas en mesure de faire autant de généralisations que MElt sur les traits internes, puisqu'il ne prend en compte que les suffixes, et ce, uniquement sur les mots inconnus.  Parmi les étiqueteurs faisant usage du Lefff , le meilleur d'entre eux est MElt  , avec une exactitude de 97, 75% globalement et 91, 36% sur les mots inconnus. Ces deux résultats constituent des améliorations significatives de 0, 5% et 4, 89% par rapport au modèle sans Lefff . Ces scores sont meilleurs que ceux de tous les étiqueteurs que nous avons pu tester, y compris l'analyseur qui exploite des résultats d'analyse syntaxique probabiliste, et ce, avec un écart significatif .  D'autres étiqueteurs ont été proposés pour le français, notamment lors de la campagne d'évaluation  GRACE . Bien qu'une comparaison directe soit difficile, étant donné la différence de corpus d'évaluation et de jeux d'étiquettes, notons que le meilleurs résultats reportés lors de cette campagne sont de 96% (Adda et al., 1999) et qu'ils ont été obtenus par des analyseurs syntaxiques. Notons par ailleurs que (Nasr & Volanschi, 2004) reporte des scores de 97.82 sur le corpus de Paris 7, mais leur étiqueteur/chunker ne prend pas en compte les mots inconnus.  Une analyse détaillée des causes d'erreurs de MElt  (Denis & Sagot, 2009) peut être résumée ainsi : 43, 5% des erreurs sont des erreurs classiques (dont 4% d'erreurs sur de, du et des, et 5, 5% de confusions entre adjectifs et participes passés), 15, 5% des erreurs concernent des nombres, 27, 5% des erreurs sont liées à des entités nommées, et 13, 5% des erreurs n'en sont pas vraiment, soit que le corpus de référence contient lui-même une erreur (9% des cas), soit que l'étiquette de référence et l'étiquette proposée par MElt semblent toutes deux correctes (4, 5% des cas).  Nous avons cherché à comprendre au mieux la façon dont les informations extraites du Lefff permettent  d'améliorer les résultats. Pour cela, nous avons mené un certain nombre d'expériences, notamment en faisant varier les jeux de traits et d'étiquettes.  En vue de mieux comprendre l'impact des informations extraites du Lefff sur notre modèle, nous nous  sommes livrés à plusieurs expériences d'ablation sur les traits décrits dans le tableau 3. Plus spécifiquement, nous avons évalué les 8 configurations possibles qui consistent à inclure (ou non) les traits lexicaux internes ( ), les traits lexicaux externes définis sur le contexte gauche ( ) et les traits lexicaux externes définis sur le contexte droit ( ). Les résultats de ces différentes expériences menées sur le corpus de développement sont repris dans le tableau 5. Notons que les configurations les plus extrêmes,  et + + , correspondent respectivement aux systèmes MElt et MElt .  Traits Lefff  Précision globale (%) Précision sur les mots inconnus (%)  (MElt ) 96, 54 83, 95 97, 04 91, 4 96, 38 85, 36 96, 39 86, 48 + 96, 92 91, 28 + 97, 30 92, 01 + 96, 57 86, 93 + + (MElt ) 97, 41 92, 35  Ces résultats indiquent que c'est la combinaison des traits internes et des traits sur le contexte droit qui  apporte le plus d'informations à l'étiqueteur. Le sous-ensemble + donne en effet les meilleurs scores après MElt lui-même, aussi bien sur l'ensemble des mots que sur les mots inconnus seuls. Ces deux sous-ensembles sont complémentaires : les traits permettent d'améliorer la couverture lexicale de l'étiqueteur (certains mots inconnus, c'est-à-dire absents du corpus d'entraînement, sont couverts par le lexique), alors que les traits fournissent des informations importantes sur le contexte droit que les traits de MElt ne modélisent que frustement. Indépendamment des expériences présentées à la section précédente, nous avons entraîné différentes versions de MElt en faisant varier à chaque fois le jeu d'étiquettes utilisé par le lexique et par le corpus d'apprentissage. Rappelons en effet que ces deux jeux d'étiquettes n'ont aucunement besoin d'être identiques, les traits lexicaux permettant d'intégrer les informations issues du lexique quels que soient les deux jeux d'étiquettes utilisés. La comparaison entre ces différentes variantes de MElt est utile à deux points de vue au moins. Tout d'abord, elle permet de donner une idée des performances de MElt avec différents jeux de paramètres. Certaines tâches de traitement automatique ou d'extraction d'informations n'ont peut être pas besoin de la granularité de notre jeu d'étiquettes d'origine. Par ailleurs, ces expériences permettent  d'aborder par un autre angle l'analyse de l'impact des informations lexicales sur les performances.  Nous avons donc utilisé différentes variantes du jeu d'étiquettes, qui sont les suivantes :   29  le jeu de départ (cf. section 2) ;  15  les catégories principales du (cf. section 2) ;  open  le même que 15, où toutes les classes fermées (autres que NC, NPP, ADJ, ADV et V) sont regroupées en une seule classe CLOSED ;  gram  le même que 15, où toutes les classes ouvertes sont regroupées en une seule classe LEX.  Jeu d'étiquettes  Jeu d'étiquettes du lexique du corpus pas de Lefff gram open 15 29 gram 96,74% 98,55% 98,82% 98,81% 98,76% open 97,29% 97,88% 98,12% 98,19% 98,25% 15 96,86% 97,15% 97,75% 97,87% 97,87% 29 96,54% 96,63% 97,04% 97,29% 97,41%  Ces résultats permettent de tirer quelques enseignements généraux :  - comme attendu, plus le jeu d'étiquettes sur lequel on s'évalue est riche, plus les résultats se dégradent ; une exception toutefois : dès lors que l'on utilise une des variantes du Lefff , étiqueter les 10 classes fermées est plus facile qu'étiqueter les 5 classes ouvertes ; - en général, les informations du Lefff sont d'une aide d'autant plus grande que les étiquettes qui en sont extraites sont riches ; - les informations lexicales semblent plus améliorer l'étiquetage des classes fermées que celui des classes ouvertes ; nous soupçonnons que ceci s'explique par l'ambiguïté des mots grammaticaux et le fait qu'ils soient difficiles à étiqueter sans aucune information lexicale spécifique.  Nous avons présenté un étiqueteur morpho-syntaxique hybride du français, MElt  , qui a des performances état-de-l'art. Il a pour particularité de chercher à exploiter au mieux des informations extraites d'un lexique exogène non probabilisé, le Lefff , en plus de celles extraites d'un corpus d'apprentissage extrait du . Nous avons essayé de comprendre au mieux de quelle façon ces informations lexicales contribuent au gain de performance observé entre MElt et sa contrepartie MElt qui n'utilise pas le Lefff .  Les perspectives de ce travail sont nombreuses. Tout d'abord, des travaux préliminaires ont été menés qui  montrent la pertinence du modèle sous-jacent à MElt sur d'autres langues que le français, en particulier si une ressource lexicale comparable au Lefff est disponible. Ensuite, des informations supplémentaires pourraient être extraites du Lefff , qui sont susceptibles d'améliorer les performances. Ainsi, des informations de sous-catégorisation verbale, disponibles dans le Lefff , pourraient par exemple améliorer l'étiquetage d'un mot tel que de, ambigu entre d'une part, une préposition qui introduit parfois un argument de type objet indirect et d'autre part, un déterminant partitif qui débute parfois un argument de type objet direct.  Enfin, nous souhaitons permettre à MElt  de prendre en entrée pas seulement une séquence de mots mais plus généralement un graphe de formes, afin de permettre d'utiliser MElt pour lever des ambiguïtés de segmentation, voire de correction orthographique, en plus de fournir une annotation en parties du discours.  
