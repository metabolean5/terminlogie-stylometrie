Quand on envisage l'analyse syntaxique en vue de produire une analyse sémantique complète de la phrase,  il est intéressant de représenter le résultat sous forme de dépendances entre mots. On s'abstrait ainsi de tous les détails qui ne jouent pas de role dans le calcul de la sémantique afin de ne conserver que l'essentiel. Mais alors, il est important de définir des structures en dépendances suffisamment riches pour permettre un calcul fin et complet des relations sémantiques. La campagne P d'évaluation des analyseurs syntaxiques du franc¸ais utilise de fac¸on essentielle de telles structures en dépendances. Les analyseurs participants à la campagne devaient produire à la fois un découpage des phrases en groupes syntaxiques et une annotation de ces phrases à l'aide de relations entre groupes ou mots . Une des difficultés était de produire toutes les relations déterminées par la syntaxe, en particulier les moins immédiates comme celles concernant les sujets des infinitifs par exemple. Le guide d'annotation de P n'impose aucune contrainte sur la structure de dépendances obtenue. De fait, la structure en dépendances obtenue est un graphe qui n'est pas toujours un arbre ; il contient meme parfois des cycles.  Il existe deux approches pour obtenir des analyses en dépendances. La première consiste à les calculer  directement. Or, pour des raisons d'efficacité, les analyseurs qui font cela imposent des contraintes sur les structures en dépendances produites (K¨ubler et al., 2009; Debusmann, 2006). Généralement, ils ne produisent que des arbres et ne permettent donc pas de retrouver toutes les relations nécessaires à la construction d'une représentation sémantique. La seconde approche consiste à extraire une analyse en dépendances à partir d'une analyse en constituants (Rambow & Joshi, 1997; Kucerov´a &  Zabokrtsk´y, 2002; Candito et al., 2009). Les relations de dépendances sont alors extraites de l'arbre syntagmatique de la phrase, ce qui n'est pas toujours évident, mais surtout l'information pour produire certaines relations peut etre manquante.  La méthode que nous proposons s'apparente à la seconde approche dans la mesure où nous utilisons une  analyse en constituants. Cependant, comme Rambow & Joshi (1997) et Candito & Kahane (1998) l'ont observé dans le cas des TAG il est souvent utile de ne pas s'appuyer seulement sur le résultat de l'analyse mais sur le processus d'analyse lui-meme, pour produire des dépendances. Notre méthode utilise le cadre des Grammaires d'interaction (GI) et en exploite la spécificité : l'utilisation de polarités pour guider la composition syntaxique. Nous avions, dans un précédent article (Marchand et al., 2009), montré comment obtenir une analyse en dépendances en réalisant une dépendance entre deux mots à chaque fois que des polarités qui étiquetaient les objets lexicaux correspondants se saturaient. Cette approche nous imposait d'ajouter une nouvelle polarité au système de polarités des GI afin de repérer les saturations qui ne faisaient que controler le contexte des mots lors de l'analyse et qui provoquaient une sur-génération de relations de dépendances.  La méthode avait été testée sur une grammaire du franc¸ais à relativement large échelle (Perrier, 2007) mais  les principes qui avaient présidé à la construction de cette grammaire n'avaient pas pris en compte l'objectif d'extraire des dépendances syntaxiques des analyses, dans la mesure où cet objectif est apparu après que la grammaire ait été construite. Récemment, la grammaire a été revue afin d'intégrer des principes exprimant les dépendances syntaxiques. Cela a permis de se passer de la nouvelle polarité et a fait apparatre des régularités structurelles dans la saturation des polarités donnant lieu à la production de dépendances. Ces régularités ont été formalisées à l'aide du concept de motif de graphe (pattern en anglais dans l'idée de pattern matching). Un motif est un ensemble de contraintes qui décrit le contexte structurel dans lequel deux polarités qui se saturent réalisent une dépendance syntaxique. Le processus d'analyse avec les GI étant formalisé sous forme d'un graphe, les dépendances sont alors créées par détection de motifs dans ce graphe.  La section 1 précise ce qu'on entend par analyse en dépendances syntaxiques complète. La section 2  présente brièvement le formalisme des GI et la section 3 décrit les principes de construction de la grammaire du franc¸ais qui permettent d'exprimer les dépendances syntaxiques. Enfin, la section 4 montre comment les motifs de graphe sont utilisés pour produire des dépendances.  La notion d'analyse complète fait appel à la différence entre dépendances dites directes (en noir dans les  figures) et dépendances indirectes (en rouge dans les figures), selon qu'elles se réalisent sans ou à l'aide d'un mot intermédiaire. Dans la proposition "Jean permet à Marie de venir" (figure 1), "Jean" sujet de "permet" et "à" complément d'attribution de "permet" correspondent à des dépendances directes (1a). La relation "Marie" sujet de "venir" est quant à elle une dépendance indirecte (1b).  Nous appellerons analyses partielles les analyses uniquement composées de dépendances directes. Dans  nos exemples, les analyses partielles sont inspirées par le guide d'annotation de la French Dependency Treebank . Nous appellerons analyses complètes les analyses qui contiennent les dépendances indirectes utiles pour l'analyse sémantique . F 1 - Structure en dépendances pour la phrase "Jean permet à Marie de venir"  Souvent, les dépendances indirectes peuvent etre retrouvées à partir des dépendances directes. Toutefois,  ce n'est pas toujours le cas. Dans la phrase "Jean promet à Marie de venir", la structure en dépendances partielle est identique à celle de la phrase "Jean permet à Marie de venir" (1a). Cependant, dans la première il y a une dépendance indirecte "Jean" sujet de "venir", et dans la deuxième cette dépendance est entre "Marie" et "venir".  La figure (1b) montre déjà que les dépendances complètes ne forment pas un arbre. Dans le syntagme  nominal contenant une relative "la fille que Jean connat", l'analyse complète (figure 2b) n'utilise plus le pronom relatif "que" comme relais pour introduire la relative et rappeler l'objet de "connat". La relation "fille" objet de "connat" est une dépendance indirecte qui introduit un cycle dans la structure. De plus, la structure n'est plus connexe : le pronom relatif "que" qui a servi d'intermédiaire entre la relative et son antécédent n'a plus d'utilité. F 2 - Structure en dépendances pour le syntagme nominal "la fille que Jean connat" Les grammaires d'interaction (Perrier, 2003) sont un formalisme grammatical qui place la notion de polarité au coeur du mécanisme de composition syntaxique. Les objets de base d'une grammaire d'interaction sont des fragments d'arbres syntaxiques sous-spécifiés qui sont décorés par des polarités. Ces polarités expriment l'état de saturation du fragment concerné et sa capacité d'interaction avec d'autres fragments. La composition syntaxique consiste alors à superposer partiellement ces fragments d'arbres pour saturer leurs polarités et obtenir un arbre unique complètement spécifié où toutes les polarités auront été saturées.  On peut voir la composition syntaxique de fac¸on totalement statique. L'ensemble des fragments d'arbres  servant à construire un arbre syntaxique peut etre vu comme une spécification d'une famille d'arbres qui constituent les modèles de cette spécification. C'est pourquoi nous l'appellerons une Description d'Arbre Polarisée (DAP) . L'arbre syntaxique final représente alors un modèle particulier de cette description. La composition syntaxique apparat ensuite comme la réalisation d'une fonction d'interprétation associant chaque noeud d'une DAP à un noeud d'un arbre syntaxique. On peut oublier le processus de composition pour ne conserver finalement que le triplet (DAP, arbre syntaxique, interprétation) que nous appellerons graphe d'interprétation , dans la mesure où il peut se représenter sous forme d'un graphe.  Seules les principales caractéristiques du formalisme des GI nécessaires à la compréhension de la suite de  l'article sont données ici (voir Guillaume & Perrier (2010) pour une présentation complète).  Une DAP est un ensemble de noeuds représentant des syntagmes, structuré par des relations de domination  et de précédence immédiates et sous-spécifiées. Les propriétés morpho-syntaxiques de chaque syntagme sont décrites par une structure de traits attachée à au noeud correspondant. Il existe deux types de traits : - les traits polarisables qui portent en plus de leur valeur une polarité qui peut etre positif (), négatif (), virtuel () ou saturé () ; dans la suite deux traits de ce type seront utilisés : cat et funct ; - les traits neutres qui ne portent pas de polarités (le symbole = est utilisé pour ces traits). Dans la suite, les noeuds des modèles sont notés {N} ; ceux des DAP, [N].  F  3 - Graphe d'interprétation de la phrase "Jean en apprécie le gout" Une interprétation d'une DAP dans un arbre syntaxique est valide si elle préserve les relations de domination et de précédence. Par ailleurs, elle doit préserver les valeurs de traits ainsi que les relations de co-indexations entre celles-ci . Concernant la structure d'arbre ainsi que des traits étiquetant les noeuds, une interprétation garantit une minimalité du modèle en un sens défini dans Guillaume & Perrier (2010).  Pour ce qui est des polarités, une interprétation valide doit respecter une des deux propriétés suivantes  pour chaque ensemble de traits polarisés de la DAP de départ interprétés dans le meme trait de l'arbre syntaxique d'arrivée : - cas non-linéaire : un seul trait est saturé et tous les autres sont virtuels ; - cas linéaire : un trait est positif, un second négatif et tous les autres virtuels. Une conséquence des conditions de saturation est que l'on peut définir, pour un noeud {N} contenant un trait polarisable f , l'antécédent principal de {N} relativement à f (noté f ({N})) comme l'unique noeud de l'ensemble I ({N}) de la DAP porteur du trait f saturé (dans le cas non-linéaire) ou du trait f positif (dans le cas linéaire).  Dans la suite, on appellera noeud principal un noeud d'une DAP qui porte un trait cat positif ou saturé (on  notera donc cat | ? dans les motifs).  Une grammaire particulière d'interaction est définie par l'ensemble de ses DAP élémentaires (DAPE)  utilisées pour composer des arbres syntaxiques.  Illustrons ces notions par l'exemple de l'analyse syntaxique de la phrase "Jean en apprécie le gout"  avec la grammaire d'interaction du franc¸ais G (Perrier, 2007). Dans une première phase, il s'agit de sélectionner les DAPE de G qui vont servir à analyser la phrase. Elles sont réunies en une unique DAP D représentant le point de départ de l'analyse. Cette DAP est présentée par la figure 3 dans sa partie haute. L'arbre syntaxique T résultant de l'analyse est présenté dans la partie basse de la meme figure. La fonction d'interprétation de D dans T est représentée sur la figure par des arcs orange allant des noeuds de D vers ceux de T . L'ensemble des deux structures et de la fonction d'interprétation de la figure 3 constitue le graphe d'interprétation. f  La grammaire G  a été construite en suivant un certain nombre de règles qui sont l'expression dans le formalisme des GI de principes linguistiques qui ne sont pas spécifiques au franc¸ais mais qui valent aussi pour d'autres langues plus ou moins proches. Voici l'essentiel de ces règles : 1. La grammaire est strictement lexicalisée, ce qui signifie que chaque DAPE est associée à un motforme unique du franc¸ais par le biais d'une feuille spéciale de la description, appelée son ancre. Sur les figures, les ancres sont représentées en jaune foncé. L'ensemble des ascendants de l'ancre s'appelle l'épine dorsale de la DAPE.  2. Certains noeuds ont une forme phonologique vide. Ce sont toujours des feuilles qui représentent la  trace d'un argument qui n'est pas dans sa position canonique. Cela peut correspondre à un argument extrait, un sujet inversé ou encore un clitique comme "en" dans notre exemple. Sur les figures, les noeuds vides sont représentés en blanc et les noeuds non vides en jaune ; dans les DAP, un noeud gris  ne porte pas de contrainte sur la forme phonologique, il peut etre vide ou non vide. Par exemple, sur  la figure 3, la trace du complément de l'objet du verbe modifié par le clitique "en" est représentée par le noeud vide [DeObj].  3. Tous les noeuds de la grammaire portent un trait cat. Pour chaque DAPE, tous les noeuds principaux  non vides sont sur l'épine dorsale. Ces noeuds forment un chemin non vide commenc¸ant à un noeud que l'on appelle la projection maximum de l'ancre et terminant à l'ancre elle-meme. L'ancre est la tete de tous ces noeuds et de fac¸on duale, ceux-ci représentent ses diverses projections. Pour une projection différente de l'ancre, on définit son fils principal comme son fils qui est aussi une projection de la tete. Sur la figure 3, dans la DAPE de "apprécie", l'ancre [V] a comme projections, outre elle-meme, les noeuds [Vmax] et [S]. Dans la DAPE de "en", l'ancre [Clit] n'a qu'elle-meme comme projection. Telles qu'elles viennent d'etre définies, les notions de tete et de projection sont relatives à une DAPE mais on peut les transposer à un arbre syntaxique modèle d'un ensemble de DAPE à l'aide d'une interprétation I. Pour tout noeud non vide {N}, cat ({N}) est un noeud non vide d'une DAPE D dont la tete est l'ancre [A ] de D . On dit alors que la tete de {N} est I([A ]) et que {N} est une projection de I([A ]). Par exemple, dans l'arbre syntaxique T de la figure 3, le noeud {V} est la tete de {Vmax} et {S}.  4. Si un noeud d'un arbre syntaxique modèle d'une DAP est porteur d'un trait funct avec une valeur  X, cela signifie d'un point de vue linguistique que le syntagme correspondant remplit la fonction syntaxique X par rapport à un syntagme représenté par un de ses noeuds frères dans l'arbre. Par exemple dans l'arbre T de la figure 3, les noeuds {Subj} et {Obj} remplissent les fonctions respectives sujet et objet par rapport au noyau verbal représenté par leur frère {Vmax}. Lorsqu'un noeud d'un arbre syntaxique pourvu d'un trait funct de valeur X a plusieurs frères, la lecture du modèle ne permet pas de déterminer lequel est celui par rapport auquel il remplit la fonction X. Pour cela, il faut revenir à la DAP correspondante via l'interprétation. Nous devons distinguer trois cas. Considérons une DAP D composée de n DAPE D , . . . , D qui est interprétée dans un modèle T via une interprétation I. Considérons dans T un noeud {N} porteur d'un trait funct de valeur X, le père de {N} étant noté {P}.  (a) Interaction linéaire prédicat-argument. Le trait funct est l'image d'un trait positif issu  d'une DAPE D et d'un trait négatif issue d'une autre DAPE D . Dans D , la grammaire assure que le noeud [N ] porteur du trait funct positif a toujours un unique frère [M ] qui est un noeud principal. Dans l'arbre T , on peut alors dire que {N} remplit la fonction X par rapport à l'image {M} de ce frère. On parle alors d'interaction linéaire entre les DAPE D et D . Cette interaction est la réalisation d'une relation prédicat-argument. Par exemple, il y a une interaction linéaire entre les DAPE associées à "gout" et à "apprécie" qui a pour résultat de réaliser la fonction objet du noeud [Obj] par rapport au noeud [Vmax].  (b) Interaction non-linéaire modifié-modificateur. Le trait funct est l'image d'un trait saturé  issu d'une DAPE D et l'antécédent du noeud {N} dans D est un noeud [N ] qui a comme père un noeud [P ] pourvu d'un trait virtuel cat. Il existe alors une DAPE unique D qui contient le noeud principal [P ] = cat ({P}). Le fils principal [M ] de [P ] a pour image le frère {M} de {N}. Dans l'arbre T , on peut alors dire que {N} remplit la fonction X par rapport à {M}. On parle alors d'interaction non-linéaire entre les DAPE D et D . Cette interaction est la réalisation d'une relation de modification ou d'adjonction.  Par exemple, il y a une interaction non-linéaire entre les DAPE associées à "gout" et "en" qui  a pour résultat de réaliser la fonction complément de nom du noeud {DeObj} par rapport au noeud {Np2  Obj}. (c) Relation prédicat-argument non réalisée. Le trait funct est l'image d'un trait saturé issu d'une DAPE D et l'antécédent du noeud {N} dans D est un noeud vide [N ] qui a comme père un noeud principal [P ]. [N ] a comme frère le fils principal [M ] de [P ]. Dans l'arbre T , {N} remplit alors la fonction X par rapport à l'image {M} = I([M ]) de ce frère. Dans la figure 3, nous n'avons pas d'illustration de ce troisième cas que l'on rencontre en particulier pour représenter des relations prédicat-argument non réalisées phonologiquement, comme les relations verbe-sujet pour les infinitifs.  5. Si un noeud d'une DAPE porte un trait ref, cela signifie que le syntagme correspondant est associé  à une référence sémantique (la valeur du trait peut préciser la qualité de cette référence : animée, inanimée mais concrète ou encore abstraite). Si dans une meme DAPE, deux noeuds ont des traits ref co-indexés, cela signifie qu'ils renvoient à la meme entité sémantique de référence. Par exemple, dans la DAPE associée à "en", les noeuds [Clit] et [DeObj] ont des traits ref co-indexés. Cela veut dire qu'ils représentent la meme entité sémantique. De meme, c'est avec la co-indexation de traits ref que l'on modélise la différence de controle entre "permet" et "promet" (ce mécanisme s'apparente aux équations de controle de LFG). Cette co-indexation entre traits ref de plusieurs noeuds se propage dans un modèle via la fonction d'interprétation et elle permet de réaliser des interactions indirectes entre syntagmes.  Comme nous l'avons vu plus haut, pour calculer une structure en dépendances, il est parfois nécessaire  de considérer des informations qui ne sont pas dans l'arbre syntaxique mais plutot dans l'historique de sa dérivation. En grammaire d'interaction, l'historique d'une dérivation est décrit par ce que nous avons appelé le graphe d'interprétation et qui représente le triplet (DAP, arbre syntaxique, interprétation). Le calcul des dépendances à partir du graphe d'interprétation peut alors s'exprimer à l'aide de motifs de graphe.  Les motifs de graphe  Un motif de graphe décrit un ensemble de contraintes à satisfaire par le graphe d'interprétation pour qu'une dépendance soit produite. Formellement, un motif de graphe est constitué d'un ensemble de motifs de noeud et de relations entre ces motifs. Identifier un motif dans une structure revient à construire une fonction d'appariement (on note l'image de N par la fonction d'appariement N) qui associe à chaque noeud du motif un noeud du graphe d'interprétation compatible avec les contraintes exprimées par le motif. Il est important de noter que les motifs font apparatre des noeuds de la DAP (rectangles) et des noeuds du modèle (coins arrondis).  La figure 5 décrit les motifs que l'on utilise pour la grammaire G  ; les contraintes portent sur les structures de trait, notamment sur les traits cat et funct et les polarités associées. Ces contraintes portent également sur le fait qu'un noeud est vide (fond blanc) ou non vide (fond jaune) dans le modèle. Pour les relations, deux types de contraintes sont utilisées. D'une part, on peut contraindre N à etre l'interprétation de M (les motifs de noeuds M et N sont alors reliés par une arete orange dans le motif). D'autre part, on peut contraindre N à etre un sous-constituant immédiat de M (M est au-dessus de N et ils sont reliés par un trait noir).  Chaque motif décrit un ensemble de contraintes à vérifier pour qu'une dépendance soit ajoutée. La flèche  rouge ne fait pas partie du motif, elle indique simplement qu'une dépendance doit etre ajoutée quand le motif est repéré dans le graphe d'interprétation ; la dépendance créée relie alors les mots-formes portés par les ancres des descriptions correspondant aux noeuds G et D.  Par exemple, on peut appliquer le motif représentant le cas linéaire et canonique, en haut et à gauche dans  la figure 5, au graphe d'interprétation de la figure 3 par l'appariement : N = {Np1  Subj}, G = [Subj] et D = [Np1]. On vérifie facilement que toutes les contraintes imposées par le motif sont vérifiées ; on peut donc ajouter une relation de dépendance portant l'étiquette subj (valeur du trait funct dans le noeud N) entre "apprécie" (mot-forme de l'ancre de la DAPE qui contient le noeud G) et "Jean" (mot-forme de l'ancre de la DAPE qui contient le noeud D). Cela correspond à la dépendance verte dans la figure 4.  F  4 - Structure en dépendance pour la phrase "Jean en apprécie le gout"  Motifs de graphe pour les dépendances complètes  Présentons maintenant les quatre motifs qui s'appuient sur les principes de la grammaire pour calculer les dépendances complètes d'une phrase. La grammaire modélise chaque dépendance par l'utilisation d'un trait funct ; il s'agit donc d'interpréter les principes décrits dans le point 4 de la section 3 de telle fac¸on que :  si  {N} remplit la fonction syntaxique X par rapport à un frère {M} alors une dépendance existe entre la tete de {M} et la tete de {N}.  Les quatre règles de la figure 5 contiennent toutes un motif de noeud N avec le trait funct de valeur X.  Elles correspondent à la combinaison de deux alternatives : la linéarité et le fait que le dépendant soit en position canonique ou pas. Pour chaque noeud {N} du modèle portant un trait funct de valeur X, on fixe N = {N} et on distingue :  Le cas linéaire : ce cas correspond aux deux règles à gauche dans la figure 5 et il est caractérisé par le  fait que funct ({N}) a un trait funct positif. Cela correspond au point 4(a) de la section 3 et donc, le noeud par rapport auquel {N} remplit la fonction syntaxique X est dans la meme DAPE que funct ({N}) et donc G = funct ({N}).  Le cas non-linéaire : ce cas (les deux règles de droite) s'applique quand funct  ({N}) a un trait funct saturé (4(b) et 4(c) de la section 3). Le noeud {M} par rapport auquel {N} remplit la fonction syntaxique X est le fils principal du noeud [P ] dans le cas 4(b) et du noeud [P ] dans le cas 4(c). Dans les deux cas, ce noeud {M} est donc dans la meme DAPE que la tete du père {P} du noeud {N}.  Le cas canonique : le dépendant de la relation de dépendance est la tete du noeud {N} quand elle existe  (c'est-à-dire quand {N} est non-vide) et donc par définition cette tete est dans la meme DAPE que cat ({N}) c'est le cas pour les deux motifs de graphe en haut de la figure 5 qui correspondent au cas où le dépendant est en position canonique.  linéaire  funct ({N}) a un trait funct positif non-linéaire funct ({N}) a un trait funct saturé  canonique  {N} est vide  non-canonique  {N} est non-vide  F  5 - Motifs pour le calcul de dépendances  Le cas non-canonique : si le noeud {N} est vide, on utilise le principe du point 5 de la partie 3 ; ce principe  assure qu'un noeud {C} non-vide dont le trait ref est co-indexé avec celui du noeud {N} renvoie à la meme entité sémantique, c'est donc ce noeud qui a pour tete le dépendant réel ; les deux motifs de graphe du bas de la figure 5 s'appliquent alors avec C = {C} et D = cat ({C}). L'existence et l'unicité d'un tel noeud {C} est assuré par la grammaire.  Par exemple, considérons le trait funct : deobj du noeud {DeObj} de la figure 3.   On considère le trait funct : deobj du noeud {DeObj}  N = {DeObj} funct ({Deobj}) = [DeObj] qui a un trait funct saturé donc cas non-linéaire I = [DeObj]  le père de {DeObj} est {Np2  Obj}  P = {Np2  Obj} cat ({Np2  Obj}) = [Np2] G = [Np2] {DeObj} est vide (cas non-canonique), on considère l'unique noeud non-vide avec le meme index 9 , il s'agit de {Clit} C = {Clit}  cat  ({Clit}) = [Clit] D = [Clit]  Le motif de graphe pour le cas non-linéaire non-canonique s'applique donc, ce qui donne la dépendance  (dessinée en bleu sur la figure 4) deobj entre "gout" (le mot-forme de l'ancre de G = [Np2]) et "en" (le mot-forme de l'ancre de D = [Clit]). Sur la figure 4, les trois autres dépendances sont des applications du cas linéaire canonique. . Nous avons présenté une méthode pour calculer les dépendances syntaxiques d'un énoncé à partir du processus d'analyse en constituants à l'aide des grammaire d'interaction. Cette méthode à base de motifs de graphes permet de retranscrire tout l'information de l'analyse en constituants nécessaire à la construction de la sémantique. Il nous reste maintenant à valider notre méthode sur des corpus à grande échelle, par exemple dans le cadre d'une campagne d'évaluation comme PASSAGE.  D'autre part, notre méthode de sélection de motifs de graphe peut etre généralisée pour l'analyse sémantique.  Il ne s'agit plus de détecter des motifs de graphes mais d'appliquer des transformations directement sur les graphes dans le cadre de la réécriture de graphes (Bonfante et al., 2010).  B  G., G B., M M. & P G. (2010). Réécriture de graphes de dépendances pour l'interface syntaxe-sémantique. In Actes de TALN 2010, Montréal. C M.-H., C ´ B., D P. & G ´ F. (2009). Analyse syntaxique statistique du franc¸ais : des constituants aux dépendances. In TALN 2009, Senlis, France.  C  M.-H. & K S. (1998). Can the TAG derivation tree represent a semantic graph ? An answer in the light of Meaning-Text Theory. In TAG. Proc+4, p. 21-24, Philadelphie. D R. (2006). Extensible Dependency Grammar : A Modular Grammar Formalism Based On Multigraph Description . PhD thesis, Saarland University. G B. & P G. (2010). Interaction Grammars. Research on Language and Computation (à paratre) . K ¨ S., M D R. T. & N J. (2009). Dependency Parsing. Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers. K  ´ I. &  Z ´ Z. (2002). Transforming Penn Treebank Phrase Trees into (Praguian) Tectogrammatical Dependency Trees. The Prague Bulletin of Mathematical Linguistics, (78), 77-94.  M  J., G B. & P G. (2009). Analyse en dépendances à l'aide des grammaires d'interaction. In TALN 2009, Senlis, France. P G. (2003). Les grammaires d'interaction. Habilitation à diriger les recherches, Université Nancy 2. P G. (2007). A French Interaction Grammar. In RANLP 2007, p. 463-467, Borovets Bulgarie. R O. & J A. (1997). A Formal Look at Dependency Grammars and Phrase-Structure Grammars, with Special Consideration of Word-Order Phenomena. In Current Issues in Meaning-Text Theory , London : Pinter.  
