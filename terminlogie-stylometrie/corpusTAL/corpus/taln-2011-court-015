CALL, dictation exercises, alignment, diagnosis, finite-state machines.   L'Apprentissage et l'Enseignement des Langues Assistés par Ordinateur (ALAO/ELAO) ont pour objectif premier  d'améliorer l'acquisition des langues par les apprenants. Pourtant, force est de constater qu'actuellement, l'investissement dans le domaine a plus été technologique que didactique : pour l'essentiel, la numérisation des cours n'a pas modifié leur contenu ni leurs méthodes d'évaluation (Desmet & Héroguel, 2005). Selon les spécialistes, l'amélioration de l'apprentissage et de l'enseignement implique de dépasser les sempiternels exercices fermés, tels que les textes à trous et les choix multiples qui, s'ils sont faciles à corriger, limitent considérablement les possibilités d'évaluation des connaissances. Il faudrait au moins proposer des exercices semi-ouverts, qui autorisent plusieurs réponses relativement prévisibles, pour autant que la correction automatique de ces exercices soit fiable : apprentissage et enseignement, en effet, ne tolèrent pas l'approximation (Antoniadis et al., 2009). La dictée, où l'enseignant lit à haute voix un passage que les étudiants doivent copier, est typiquement l'un de ces exercices semi-ouverts qui, s'il était automatisé, pourrait considérablement améliorer l'apprentissage et l'enseignement des langues. La dictée est ainsi un très bon moyen d'estimer le niveau d'un étudiant (Coniam, 1996). Sa pratique, en outre, permet d'améliorer des compétences telles que la maîtrise de la grammaire, les capacités de lecture, la connaissance du vocabulaire et le niveau de compréhension (Rahimi, 2008). Actuellement pourtant, rares ont été les essais d'automatisation de cet exercice. Or, grâce aux synthétiseurs de la parole, lire automatiquement un texte inconnu n'est plus un problème. Mais la correction d'une copie d'apprenant, par contre, est une étape beaucoup plus délicate à automatiser, parce qu'elle pose deux questions sensibles : la détection de la place réelle des erreurs et leur classification. L'importance d'exercices semi-ouverts en ALAO/ELAO a souvent été mise en avant. Des tests ont en outre montré l'intérêt de la dictée comme moyen d'évaluation et d'amélioration de la maîtrise de la langue, qu'il s'agisse d'apprenants natifs ou d'allophones, pour autant que ceux-ci présentent un niveau de maîtrise avancé de la langue étudiée (niveaux C1 ou C2 du Cadre européen commun de référence pour les langues). Pourtant, peu de travaux ont directement concerné l'automatisation de cet exercice et de sa correction. Le travail le plus significatif dans le domaine est certainement celui de Santiago-Oriola (1998). La partie de ce travail qui nous intéresse ici est la méthode de correction proposée : elle repose sur le fait que le lien entre graphie et prononciation n'est pas aisé à acquérir en français : seuls 80 à 85% des lettres d'un texte transcrivent un phonème, ce qui est la cause de nombreuses fautes d'orthographe. Sur cette base, la correction proposée se divise en deux modules : un premier module s'occupe de la détection des erreurs en réalisant un alignement de l'original et de la copie dirigé par des règles de transformation phonologiques ; un second module ne produit pas un diagnostic, mais sélectionne un diagnostic pré-établi, associé dans les ressources du système à une ou plusieurs erreurs recensées dans la langue. Hormis une évaluation de l'outil qui a montré que 80% des 24 enfants l'ayant testé l'ont apprécié, ce travail très intéressant n'a malheureusement pas été poursuivi. Plus récemment, le logiciel de dictées La Dictée interactive a été présenté dans la revue Alsic, dédiée à l'apprentissage des langues (Ruggia, 2000). Cet article, centré sur la présentation du potentiel de l'outil, ne donne qu'une seule information concernant la méthode de correction des erreurs : elle cible les erreurs courantes chez les apprenants italophones de niveau faux-débutant en français. Cette méthode est donc probablement peu générique. Ces dernières années, la dictée a complètement disparu de la littérature scientifique. Dans le domaine des exercices semi-ouverts, on peut cependant encore noter les travaux de Desmet & Héroguel (2005), dont la plateforme d'apprentissage des langues étrangères autorise entre autres la réalisation de traductions de phrases d'une langue source vers une langue cible. Le principe de correction proposé se rapproche de l'exercice de dictée dans lequel l'original est disponible : l'idée, ici, est de produire plusieurs formulations (les « originaux »), et de sélectionner, par approximate string matching, la formulation dont la réponse de l'apprenant se rapproche le plus. Le système, qui travaille au niveau du mot, signale ensuite les erreurs à l'apprenant en remplaçant un mauvais mot par XXX, un mot superflu par (XXX) et un mot manquant, par (. . .). Par contre, aucun diagnostic n'est produit.  Notre méthode de correction partage deux similarités avec celle de Santiago-Oriola (1998). Premièrement, elle  comprend deux étapes, une phase de détection précédant une phase de diagnostic. Deuxièmement, la phase de détection repose sur un alignement de l'original et de la copie. Un aspect distingue particulièrement notre approche : la totalité de la correction repose sur une analyse morphosyntaxique de l'original de la dictée. Cette analyse est produite par le système eLite (Beaufort & Ruelle, 2006), qui réalise successivement un pré-traitement, une analyse morphologique et une désambiguïsation contextuelle du texte. La désambiguïsation est obtenue par l'application d'un modèle de langue probabiliste (Beaufort et al., 2002). Les informations morphosyntaxiques sont ensuite stockées dans une structure de données qui contient, entre autres, une couche Sent correspondant aux phrases, et une couche Word correspondant aux mots. Une fois l'analyse de l'original d'une dictée terminée, la structure de données correspondante est sauvegardée dans un fichier XML, qui sera chargé par notre module de correction lorsqu'il devra traiter une copie de cette dictée. Au-delà des informations morphosyntaxiques qui seront utilisées par le module de correction, il faut noter que le processus de correction dans son ensemble est influencé par cette structure de données : la couche Sent, qui identifie les phrases du texte, permet en effet d'appliquer le module de correction phrase par phrase, ce qui réduit considérablement la complexité du processus.  Détection.  Comme dans l'état de l'art, la détection des erreurs de l'apprenant se fait sur la base d'un alignement de la phrase originale et de la copie. Classiquement, cet alignement est obtenu en calculant la distance d'édition des deux séquences (Damerau, 1964; Levenshtein, 1966). Or, la distance d'édition classique n'autorise que des opérations de base : substitution, insertion et suppression d'un caractère, et transposition de deux caractères contigus. Ceci est gênant dans le cas qui nous occupe, parce que les erreurs des apprenants correspondent souvent à des substitutions n-m, où n caractères se substituent à m caractères : -es  -ent, -ait  -aient, -er  -ées, etc. Dans  F  1 - Illustration des étapes 2 à 4 de la détection des erreurs  le cadre de la distance d'édition classique, la substitution n-m se modélise sous la forme de plusieurs opérations  d'édition, ce qui tend à l'écarter des solutions pertinentes, étant donné que la distance qui lui est attribuée est la somme de plusieurs opérations. Afin de dépasser cette limite, nous avons eu recours aux machines à états finis et à une méthode que nous avons décrite dans (Beaufort, 2010) : étant donné deux séquences x et y représentées sous la forme des automates à états finis X et Y, nous construisons le transducteur pondéré E correspondant à l'ensemble E des alignements possibles entre x pour y. Cet ensemble est obtenu au travers de la cascade de compositions :  E = X  F  Y  (1)  où F est un transducteur pondéré qui modélise les opérations d'édition acceptées. Le meilleur alignement entre  x et y correspond au meilleur chemin de E, obtenu par calcul du plus court chemin d'un graphe. La méthode est appelée composition filtrée, parce que le transducteur pondéré F peut être considéré comme un filtre qui détermine la taille de l'intersection entre x et y. Le filtre F est compilé sous la forme d'un transducteur F à partir d'un fichier de règles de réécriture de la forme :  ?   / w (2)  où la séquence  peut se réécrire  et se voit dans ce cas attribuer le poids w. Il s'agit donc de règles facultatives,  ce qui permet à  soit de rester inchangé, soit de se voir appliquer plusieurs réécritures.  L'algorithme de détection des erreurs, illustré en Figure 1, est entièrement construit autour de ce principe :   1. la phrase originale x et la copie y sont converties en automates à états finis X et Y. Les deux automates sont  composés au travers du filtre F qui représente les opérations d'édition classiques ainsi que la substitution n-m des séquences graphiques couramment confondues en français. Actuellement, le filtre autorise surtout la substitution des terminaisons nominales et verbales, telles que celles que nous avons citées précédemment. Le transducteur E des alignements possibles entre x et y est ensuite réduit à son meilleur chemin E , correspondant au meilleur alignement de x et y ; 2. le transducteur E est parcouru et converti en trois vecteurs : un pour la phrase originale, un pour la copie, et un pour les poids associés aux opérations réalisées. Dans le vecteur de poids, un poids positif indique le début d'une opération d'édition ; 3. les trois vecteurs sont parcourus en parallèle afin d'entourer les erreurs de marqueurs [ et ] qui en indiquent les limites. Le système considère qu'une erreur commence quand le poids est différent de 0, et qu'elle finit lorsque le poids redevient 0 et que les deux vecteurs de lettres présentent des caractères identiques ;  4. il reste à identifier les frontières de mots à l'aide de marqueurs { et }. À ce niveau, l'algorithme est guidé  par l'analyse linguistique, qui parcourt successivement les éléments de la couche Word. Sur cette base, le système identifie le mot courant dans le vecteur de la phrase originale. Ensuite, il adapte les frontières au besoin, pour inclure dans le mot courant les erreurs contiguës qui correspondent à des insertions de caractères alphabétiques. C'est le cas du n dans la forme nentretien ; 5. chaque erreur est ensuite sauvegardée dans le Word adéquat de la structure de données. Cette sauvegarde s'accompagne de calculs permettant de catégoriser l'erreur : dans ou en frontière d'élément, élément manquant , élément superflu, erreur ne contenant que des séparateurs. Ces indices guideront l'établissement du diagnostic.  Diagnostic.  À ce stade, toutes les informations disponibles sont sauvegardées dans les éléments Word de la structure de données : l'analyse morphosyntaxique de la forme correcte et, s'il y a eu erreur, la forme erronée et les indices prélevés. Le diagnostic n'est déclenché que sur les éléments Word contenant une erreur. Dans l'ensemble, les erreurs concernent (1) un séparateur, (2) un mot simple ou (3) une séquence d'éléments (mots et séparateurs). L'orientation du diagnostic vers une erreur sur séquence dépend de l'indice associé à l'erreur : un séparateur manquant peut indiquer une fusion en une forme du lexique (quoi que  quoique, d'avantage  davantage), un séparateur superflu, une segmentation en plusieurs formes du lexique (quoique  quoi que, davantage  d'avantage ). Si les indices l'y poussent, l'algorithme de diagnostic commence donc par tester une erreur sur séquence, et ne propose un autre diagnostic que si ces tests échouent. Pour des raisons de clarté cependant, nous commençons par détailler le fonctionnement du diagnostic sur séparateur et sur mot simple.  1) Le diagnostic relatif à une erreur sur séparateur (ponctuation ou espace) est très simple à produire : si l'indice  sauvegardé est superflu ou manquant, le diagnostic est identique. Sinon, le séparateur existe mais est erroné, et le diagnostic signale simplement que l'on attendait un séparateur différent.  2) Une erreur sur mot simple peut être lexicale et/ou grammaticale. Une erreur est lexicale si la forme erronée est  hors-vocabulaire (nentretien) ou appartient à la même catégorie que la forme correcte, mais possède un lemme différent (sceptique  septique). Une erreur est grammaticale si la forme erronée présente des traits grammaticaux différents de ceux de la forme correcte (parle  parles diffèrent au niveau de la personne). Une forme erronée peut bien sûr cumuler erreur lexicale et grammaticale (différent  différant cumulent erreur de lemme et erreur de catégorie). Pour poser l'un de ces diagnostics, nous commençons par rechercher la forme erronée dans le lexique. Si la forme n'y figure pas, elle est considérée comme hors-vocabulaire. Dans le cas contraire, l'idée est de comparer l'analyse linguistique retenue pour la forme correcte lors de la préparation de la dictée, à l'ensemble d'analyses possibles proposées par le lexique pour la forme erronée, et de retenir l'analyse de la forme erronée la plus proche de celle de la forme correcte. Qu'il s'agisse d'une forme correcte ou erronée, une analyse linguistique est toujours constituée d'un lemme et des traits grammaticaux suivants : temps/mode, genre, nombre, personne. La méthode de comparaison d'analyse que nous utilisons est fort proche de la méthode d'alignement que nous avons présentée précédemment. Elle est illustrée en Figure 2 : on compile l'analyse de la forme correcte (a ) et l'ensemble d'analyses de la forme erronées (a ) sous la forme d'automates à états finis (resp. A et A ). Sur cette base, la meilleure analyse à conserver pour la forme erronée (A ) correspond au meilleur chemin de la composition de ces deux automates au travers d'un filtre F :  A  = Best(A  F  A ) (3)  où le filtre autorise des conversions pondérées entre traits grammaticaux. Par exemple, un infinitif peut être converti  en participe passé moyennant un coût de 1 et en nom moyennant un coût de 5. Le meilleur chemin entre les deux analyses est donc celui qui réalise les transformations de traits les moins coûteuses. Lorsque les lemmes des deux formes diffèrent (sceptique  septique), la composition des automates échoue. Dans ce cas, l'erreur est au moins lexicale. Il reste cependant à choisir l'analyse de la forme erronée et à tester une éventuelle erreur grammaticale. Le même calcul est de ce fait reproduit sur deux nouveaux automates, ne présentant que les traits grammaticaux des deux formes à comparer. Cette composition donne toujours un résultat.  3) Dans le principe, l'analyse d'une erreur sur séquence se déroule comme celle d'un mot simple : la séquence  erronée est recherchée dans un lexique. S'il n'y a pas de résultat cependant, la séquence n'est pas considérée comme hors-vocabulaire ; le diagnostic s'oriente simplement vers l'un des deux autres types d'erreurs. La recherche de la séquence erronée dans le lexique diffère en deux points de la recherche d'un mot simple : il faut construire la séquence à rechercher et choisir un lexique approprié. En cas de séparateur manquant (quoique pour quoi que, davantage pour d'avantage), on suppose que la forme erronée est un mot simple. Les mots corrects (par exemple, quoi et que) sont dans ce cas concaténés sans séparateur (quoique) et recherchés dans le même lexique que celui utilisé pour l'analyse des erreurs sur mots simples. En cas de séparateur superflu (quoi que pour quoique, d'avantage pour davantage), on suppose que la forme erronée contient plusieurs formes correctes simples. Les segments de mots (par exemple, d et avantage) sont dans ce cas concaténés autour du séparateur superflu (d'avantage) et recherchés dans un lexique correspondant à l'expression régulière suivante :  (W ordApo | (W ord Sep))  W ord (4)  où W ordApo est un mot terminé par une apostrophe (d', qu', etc.) et Sep est un espace ou un trait d'union. Cette  expression autorise donc simplement une suite de mots respectant les conventions typographiques du français.  1. Automate  A représentant l'analyse de la forme correcte. Ici, l'analyse est augmentée par composition avec le filtre F  2. Automate  A représentant l'ensemble des analyses de la forme erronée  3. Intersection des deux automates. Le chemin rouge correspond à la meilleure analyse   F  2 - Aide au diagnostic : composition des analyses  Nous avons réalisé une première évaluation sur le corpus de dictées de Lenoble-Pinson, numérisé et étiqueté par  Fairon & Simon (2009). Ce corpus comprend 1 300 dictées réalisées sur une période de 40 années (1969-2008) aux Facultés Universitaires Saint-Louis (Bruxelles, Belgique) par des étudiants de 1 et 2 baccalauréat. Dans le corpus original, les erreurs étaient réparties en trois catégories : usage, grammaire et ponctuation. La version numérisée raffine ce classement en ajoutant trois catégories : homophone, nouvelle orthographe et transcription. Les fautes répertoriées nouvelle orthographe signifient que l'étudiant a signalé employer une convention (l'orthographe traditionnelle ou la nouvelle orthographe), mais a malgré tout utilisé des formes de l'autre convention. Les erreurs de transcription correspondent à des passages (un ou plusieurs mots complets) manquants ou ajoutés par l'étudiant. Il faut noter que le classement dans les différentes catégories est probablement à uniformiser : par exemple, la confusion quelquefois  quelle que fois est classée dans usage, alors que quelque  quel que est classée dans homophone. Notre évaluation, réalisée sur un sous-ensemble de 441 dictées présentant 5 152 erreurs, a porté sur la qualité du système de détection d'une part, et sur la qualité du système de diagnostic d'autre part.  1) Globalement, 99% des erreurs (5 111 sur 5 152) sont correctement détectées et alignées. Toutes les erreurs  de détection sont dues à des problèmes de transcription, qu'il s'agisse de passages superflus ou manquants. Le système est alors peu performant, puisqu'il ne gère correctement que 59% de ces erreurs. Pour comprendre le phénomène, voici un exemple de passage tronqué :  . . . française [, quels qu'en puissent être la gravité et le nombre] .   Contre toute attente, le système a favorisé l'alignement du e final de française sur le ent de puissent. Après analyse  des poids des différents alignements possibles, cette erreur est en fait due au filtre, à qui l'on demande de favoriser la substitution ent  e. Ce point ne manquera pas d'être étudié.  2) Évaluation du diagnostic. L'évaluation a porté ici sur l'ensemble des erreurs, sauf celles de transcription, dont  la détection-même pose problème. Le corpus de test est de ce fait réduit à 5 052 erreurs. Nous ne générons pas le même classement que celui de Fairon & Simon (2009). L'évaluation a de ce fait consisté à valider manuellement les analyses produites, et ce à deux niveaux : en surface (séparateur superflu ou manquant, erreur lexicale et/ou grammaticale, etc.) et en profondeur (mot hors-vocabulaire, erreur de lemme, erreur sur un trait grammatical, etc.). Toute erreur d'analyse, quel que soit son niveau, a donné lieu au rejet du diagnostic dans son ensemble. En l'état actuel, le système a été capable d'analyser correctement 83% des erreurs (4 200 sur 5 052). Ce résultat est à nuancer. 51,4% des erreurs d'analyse se répartissent entre les catégories nouvelle orthographe, usage et homophone . Actuellement, nous ne gérons pas la nouvelle orthographe, ce qui explique les erreurs dans cette catégorie : toute orthographe nouvelle, absente de nos lexiques, a été à tort classée comme hors-vocabulaire. Les erreurs recensées dans les catégories usage et homophone concernent toutes des séquences sur-segmentées, comme quel que pour quelque ou d'avantage pour davantage. Ceci est dû au fait que le système, au moment de l'évaluation, n'utilisait pas encore le lexique multi-mot décrit à l'Équation 4. Dans l'ensemble, ces erreurs devraient donc être facilement corrigées. 41,4% des erreurs concernent l'analyse grammaticale. L'erreur, dans ce cas, est souvent déjà présente dans l'analyse de la forme correcte. Il s'agit soit de confusions de catégories entre nom et adjectif, soit de confusions de modes entre indicatif, subjonctif et impératif, soit de confusions de personnes au singulier. Ce type d'erreurs indique clairement que l'analyse syntaxique réalisée sur la dictée doit être améliorée. Actuellement, nous pensons aborder le problème à l'aide de grammaires locales, qui guideront le modèle de langue.  
