Les systèmes de résumé automatique multi-documents par extraction fondés sur une classification préalable des  phrases en classes lexicales (CL) ont récemment prouvé leur efficacité lors des campagnes d'évaluation internationales TAC . Ces systèmes offrent une modélisation du corpus à résumer différente de celles traditionnellement utilisées . La redondance dans les corpus multi-documents est plus importante que dans des documents simples. Une telle modélisation le prend en compte, et s'appuie sur la redondance pour cibler l'information pertinente tout en évitant la répétition d'éléments d'information dans le résumé. Nous avons montré que cette modélisation pouvait être utile afin d'affiner la sélection de phrases (Bossard & De Neef, 2011).  La problématique du réordonnancement de phrases pour le résumé multi-documents est plus complexe que pour  le résumé mono-document. En effet, dans un document unique, les phrases sont toutes issues de la même structure discursive, et peuvent être restituées dans l'ordre du document source. En revanche, en multi-documents, les phrases peuvent être extraites de documents épars, et une structure discursive doit être recomposée. Nous montrons ici que la modélisation en classes lexicales peut également servir à réordonner les phrases du résumé, et présentons une évaluation de notre méthode de réordonnancement. Dans un premier temps, nous dressons un état de l'art de l'ordonnancement de phrases pour le résumé automatique. Cet état de l'art vise à renseigner le lecteur sur les différentes stratégies de réordonnancement de résumé, non sur les méthodes de résumé en soi. Pour plus de renseignements sur les méthodes de résumé automatique, le lecteur pourra se référer à (Mani, 1999) ou à (Das & Martins, 2007). Dans un second temps, nous présentons notre méthode d'ordonnancement et son évaluation réalisée sur le corpus RPM2 (de Loupy et al., 2010). Enfin, nous discutons les résultats obtenus  À côté de modélisations chronologiques ou rhétoriques, peu robustes et non génériques (Lin et al., 2008; Rutledge  et al. , 2000), des auteurs ont privilégié des approches fondées uniquement sur des indices lexicaux, tentant de maximiser le vocabulaire commun de deux phrases voisines dans le résumé (Wang, 2002), ou fondées sur la position des phrases dans leur document d'origine et la date de ce dernier (Saggion & Gaizauskas, 2004). Ces approches ne garantissent cependant pas la cohérence logique ni chronologique du résumé. La position d'une phrase dans un document permet difficilement d'en déduire la position dans un texte différent. Pour répondre à ce problème, Regina Barzilay et al. (2002) génèrent des résumés fondés sur la détection de paraphrases. Une phrase est extraite de chacun des groupes paraphrastiques, et ces mêmes groupes sont utilisés afin de déterminer un ordre entre les phrases. Ainsi, ce ne sont plus les caractéristiques d'une phrase isolée qui déterminent sa position dans le résumé, mais les caractéristiques des phrases d'un groupe paraphrastique. L'algorithme MO - Majority Ordering - construit un graphe orienté des groupes paraphrastiques. Le poids du lien d'un groupe G vers un groupe G est égal au nombre de documents dans lequel une phrase classée dans G précède une phrase classée dans G . Ordonner les phrases du résumé revient alors à ordonner les groupes paraphrastiques dont elles sont issues.  Notre approche est semblable à ce dernier algorithme. Cependant, nous ne fondons pas le résumé automatique sur  la détection de paraphrases au sens strict - (Regina Barzilay et al., 2002) détectent les paraphrases par comparaison d'arbres syntaxiques et ajout d'informations sémantiques - mais sur la classification lexicale des phrases. Par conséquent, les classes que nous utilisons sont plus étendues, et les documents comportant plusieurs phrases d'au moins deux CL sont plus nombreux, ce qui oblige à revoir les approches de création du graphe et du parcours de celui-ci.  Nous fondons notre approche de résumé automatique sur le système CBSEAS, présenté en détails dans (Bossard  & De Neef, 2011). Celui-ci procède en deux étapes : regrouper les phrases en CL, puis sélectionner les phrases à extraire, à raison d'une phrase par classe au maximum. Dans le système utilisé pour l'article, le nombre de classes est fixé à 8 . L'intuition derrière ce système est que la classification des phrases permet d'une part d'éviter la redondance dans les résumés générés, d'autre part de disposer de deux critères d'extraction : la pertinence d'une phrase vis-à-vis du contenu global des documents (centralité globale) et la pertinence d'une phrase vis-à-vis de sa CL (centralité locale). La campagne d'évaluation TAC 2009 témoigne de l'efficacité de ce système de résumé pour ce qui est de l'extraction d'informations essentielles (Bossard & Poibeau, 2009). Ces résultats sont corroborés par une expérience sur un corpus français (Bossard & De Neef, 2011) . En revanche, les campagnes TAC ont révélé des problèmes de lisibilité chez les utilisateurs. Nous supposons que ceci est dû pour une grande partie au manque de cohérences logique et chronologique des résumés (ordre des faits cités inapproprié), même si d'autres aspects entrent en ligne de compte : anaphores non résolues, conjonction de coordination indésirables... La section qui suit propose une stratégie pour résoudre ce problème.  Nous faisons l'hypothèse que les phrases du résumé peuvent être ordonnées dans le même ordre que les classes  dont elles sont issues. Nous faisons également l'hypothèse que l'ordre des phrases dans les documents d'origine reflète un ordre logico-temporel, partagé par l'ensemble des documents à résumer, et qu'il est possible de projeter sur les phrases du résumé. Les méthodes d'ordonnancement que nous proposons se veulent les plus génériques possible, ne faisant appel à aucune technique linguistique dépendante de la langue. Cependant, cette hypothèse contraint les documents sur lesquels la méthode est applicable. Dans l'expérience que nous avons menée, les  documents en entrée sont tous des dépêches de presse, majoritairement organisées autour de la même structuration  de l'information, en pyramide inversée.  Les méthodes que nous proposons sont fortement semblables à celle décrite dans (Regina Barzilay et al., 2002).  Cependant, celle-ci compte seulement le nombre de documents dans lesquels une phrase d'une classe B suit une phrase d'une classe A, tandis que nous calculons la proportion de phrases de B situées après des phrases de A, transposables sous formes de probabilités. De plus, nous proposons une évaluation différente, en comparant nos méthodes avec une baseline plus performante.  3.2.1  Génération du graphe d'ordonnancement  Lors d'une première étape, un graphe orienté d'ordonnancement des phrases est établi, dans lequel les noeuds  sont les CL. Le poids des arêtes est calculé de deux manières différentes. Dans la première (méthode DU, pour « Distance Unique »), le poids de l'arête d'une CL A à une CL B est égal à :  n   n n + n (1)  où n  est le nombre couples de phrases (p , p ) tels que : - p appartient à la classe thématique X ; - p appartient à la classe thématique Y ; - p et p sont extraites du même document ; - p est située après p . Dans la seconde (méthode DR pour, « Distance Relative »), le poids de l'arête d'une CL A à une CL B est égal à : pos(p , p ) |pos(p , p )| (2)  où :  - C (X, Y ) est l'ensemble des couples de phrases telles qu'elles appartiennent au même document, la première appartient à la classe X et la seconde à la classe Y. - pos(p , p ) est le nombre de phrases séparant p de p si p est situé après p , et l'opposé du nombre de phrases séparant p de p si p précède p .  A la différence de DR, DU ne prend pas en compte la distance entre les phrases d'un même document mais  uniquement leur position relative. L'idée derrière ces calculs est d'obtenir non seulement l'ordre présumé entre deux groupes de phrases, mais également la probabilité qu'il soit correct.  3.2.2  Parcours du graphe et ordonnancement  Ordonner les noeuds d'un tel graphe est un problème NP-complet. Nous avons donc utilisé une heuristique pour  résoudre ce problème : le parcours du graphe débute à partir du noeud qui minimise la somme des valeurs de ses arêtes sortantes, c'est-à-dire le noeud dont les phrases maximisent la probabilité de précéder celles des autres noeuds. Les phrases de ce noeud précèdent donc majoritairement les phrases des autres noeuds. Tant qu'il existe un noeud non visité, dont le lien du noeud courant vers celui-ci est strictement négatif, le parcours se poursuit depuis le noeud qui minimise ce lien (donc celui dont le poids est le plus proche de 1). S'il n'existe pas de tel noeud, l'algorithme parcourt le noeud non visité qui minimise la somme des valeurs de ses arêtes sortantes. L'algorithme se poursuit tant que tous les noeuds du graphe n'ont pas été visités. Les phrases du résumé sont ordonnées dans l'ordre de parcours du graphe.  Au cours des premières expériences que nous avons menées, nous avons constaté que la première phrase choisie  par un tel parcours de graphe est souvent inappropriée. Dans un résumé de dépêches, la première phrase doit décrire l'événement clé afin de faciliter la lecture du reste du document. Nous avons donc implémenté une seconde méthode de parcours, qui débute par la phrase dont le score calculé par CBSEAS est le plus important. Cette phrase devrait contenir les mots-clés les plus discriminantants du thème traité, et nous faisons l'hypothèse qu'elle est la plus pertinente comme accroche du résumé.  Nous avons implémenté deux baselines. La première ordonne les phrases selon le score que CBSEAS leur a  attribué. Ainsi, les phrases éventuellement « hors sujet », c'est-à-dire ne correspondant pas à une composante informationnelle importante des documents d'origine, sont repoussées à la fin du résumé et n'en perturbent pas la lecture. Les phrases contenant le vocabulaire le plus fréquent apparaîtront en premier ; dans le cadre de résumés de dépêches, cela peut être bénéfique, car les premières phrases auront une probabilité élevée d'introduire tous les acteurs des événements traités. La deuxième baseline consiste à ordonner les phrases selon la date d'émission des documents dont elles sont issues. Si plusieurs phrases appartiennent au même document, elles sont ordonnées selon leur position dans celui-ci.  Nous avons évalué trois systèmes :  - un qui utilise la méthode de génération de graphe DU ; - un qui utilise la méthode de génération de graphe DR ; - un dernier qui utilise DU et le parcours de graphe débutant par la phrase la mieux classée par CBSEAS (DU+score). Ces systèmes ont été comparés aux deux baselines présentées en Section 4.1.  L'évaluation a été réalisée sur le corpus RPM2, composé de 200 dépêches de presse, et divisé en 20 thèmes de 10  documents. Chacun des thèmes a été utilisé afin de générer un résumé par CBSEAS, ordonné selon les méthodes DU, DR, DU+score, et les deux baselines. Les résumés ont été évalués par quatre évaluateurs différents, en aveugle, selon deux axes : leur cohérence - sur une échelle de 0 à 3, la qualité de l'enchaînement des phrases - et la pertinence de leur première phrase - pertinente (1) ou non (0) .  T  1 - Scores de cohérence  T  2 - Évaluation de la pertinence de la première phrase  Pour effectuer cette annotation, les évaluateurs avaient également pour consigne de ne pas tenir compte de la  rhétorique, c'est-à-dire des marqueurs de discours qui assurent le lien logique entre phrases (typiquement des adverbes tels que néanmoins, en outre, cependant...). Ils ne devaient pas non plus pénaliser la redondance interphrastique. En revanche, la présence d'expressions non référentielles (anaphores, périphrases...) ininterprétables était à pénaliser.  T  3 - Comparaison des évaluations avec 175 et 100 mots.  Le Tableau 1 présente les résultats de l'évaluation de la cohérence globale des résumés. Les annotateurs ont  considéré qu'ordonner les phrases selon leur score produisait les résumés les plus cohérents. La deuxième méthode est DU+score, et la moins bonne la méthode Date+pos. Il est intéressant de constater que le réordonnancement selon le score produit également les accords inter-annotateurs les plus importants. Si le pourcentage d'accord pour cette méthode est faible (le nombre de notations identiques), les notes des annotateurs sont parmi les moins divergentes, avec un coefficient de variation moyen - l'écart type moyen rapporté à la moyenne - de 0.68. La méthode d'ordonnancement la moins probante est la baseline 2.  Les résultats témoignent de l'importance du choix de la première phrase. En effet, la méthode DU+score obtient  des résultats supérieurs à ceux de la méthode DU seule. Seule changeait dans cette méthode le choix de la première phrase, qui a paru plus judicieux aux annotateurs (cf Tableau 2). Les résultats de la méthode DU+score n'égalent toutefois pas ceux de la baseline 1, quoique deux annotateurs sur quatre aient jugé les deux méthodes sensiblement de même valeur.  Les résultats de cette évaluation sont décevants, puisqu'aucun des systèmes présentés n'est meilleur que la baseline  1. De plus, les notes sont assez faibles, puisqu'aucun système de réordonnancement n'obtient de note supérieure à la moyenne. Cependant, les résultats obtenus sont à mettre en rapport avec le nombre élevé de mots par résumé utilisé lors de cette expérience - 175. Ce nombre élevé de mots, associé à un nombre de CL également important - 8 - a pour effet d'augmenter le rappel des informations extraites dans les résumés, tout en en diminuant la précision. Ainsi, certaines phrases sont hors-sujet et perturbent la lisibilité du résumé. La Figure 1 présente un même résumé ordonné selon les méthodes baseline 1, DU, DU+score et Baseline 2. On constate bien le phénomène d'interposition de phrases qui perturbent le discours (ici, la phrase « La tension monte encore d'un cran entre Rachida Dati et les magistrats. »).  Une évaluation préliminaire, réalisée avec une configuration différente, avait livré des conclusions différentes.  Les résumés étaient limités à 100 mots, et générés à partir de 5 CL. Un seul annotateur avait participé à cette étude. Le Tableau 3 montre que la méthode DU avait été jugée la plus efficace, légèrement devant la baseline 1. Pour comparaison, nous avons présenté dans ce tableau l'évaluation de cet annotateur sur les résumés de 175 mots. On constate que la tâche se complexifie rapidement avec l'accroissement du nombre de phrases ; la seule méthode qui reste stable est la baseline 1. Afin d'éviter, comme c'est le cas dans beaucoup des résumés de 175 mots générés pour notre expérience, que des phrases trop marginales ne perturbent la lecture du résumé, on peut imaginer prendre en compte le score des phrases du résumé lors du calcul du graphe, de manière à affaiblir les arêtes qui relient les noeuds dont la phrase représentative est mal notée par CBSEAS. Ainsi, la probabilité que de telles phrases soient reléguées en fin de résumé sera plus importante. Bien que les résultats de cette étude soient décevants, nous avons identifié le principal problème relatif aux méthodes proposées, et suggéré une manière d'y remédier, qu'il conviendra que nous évaluions.  
