(1)   UCLouvain, Cental, Place Blaise Pascal, 1, B-1348 Louvain-la-Neuve, Belgique   (2) UCLouvain, CECL, B-1348 Louvain-la-Neuve, Belgique  nadja.vincze@uclouvain.be, yves.bestgen@uclouvain.be   De nombreuses méthodes automatiques de classification de textes selon les sentiments qui y sont exprimés s'appuient sur   un lexique dans  lequel  à chaque entrée est  associée une valence. Le plus souvent, ce lexique est  construit  à partir d'un  petit nombre de mots, choisis arbitrairement, qui servent de germes pour déterminer automatiquement la valence d'autres  mots. La question de l'optimalité de ces mots germes a bien peu retenu l'attention. Sur la base de la comparaison de cinq  méthodes automatiques de construction de lexiques de valence, dont une qui, à notre connaissance, n'a jamais été adaptée  au français et une autre développée spécifiquement pour la présente étude, nous montrons l'importance du choix de ces  mots germes et l'intérêt de les identifier au moyen d'une procédure d'apprentissage supervisée.   Many methods of automatic sentiment classification of texts are based on a lexicon in which each entry is associated with   a  semantic  orientation.  These  entries  serve  as  seeds  for  automatically  determining  the  semantic  orientation  of  other  words. Most often, this lexicon is built from a small number of words, chosen arbitrarily. The optimality of these seed  words  has  received  little  attention.  In  this  study,  we  compare  five  automatic  methods  to  build  a  semantic  orientation  lexicon. One among them, to our knowledge, has never been adapted to French and another was developed specifically  for  this  study.  Based  on  them,  we  show  that  choosing  good  seed  words  is  very  important  and  identifying  them  with  a  supervised learning procedure brings a benefit.        La  classification  de  textes  consiste  à  classer  automatiquement  les  textes  dans  un  ensemble  prédéfini  de   catégories.  Ce  sont initialement les classifications thématiques et par genre qui ont  motivé  les recherches,  mais,  depuis  une  dizaine  d'années,  ce  champ  d'études  s'est  élargi  et  intègre  la  classification  de  textes  en  fonction des sentiments qui y sont exprimés : détection de la subjectivité, avec une classification objectif /  subjectif  (Wiebe  et  al.,  2004 ;Yu,  Hatzivassiloglou,  2003)  et  détermination  de  la  valence  des  documents,  avec une  classification binaire positif / négatif, parfois  multi-classes selon le degré de polarité (Abbasi  et  al.,  2008 ;  Pang  et  al.,  2002).  La  plupart  des  implémentations  de  ces  classifieurs  requièrent  des  lexiques  porteurs  de  valence,  c'est-à-dire  des  lexiques  où  à  chaque  entrée  est  associée  une  polarité  ou  un degré  de  polarité.  Une  série  d'approches  attribuent  une  valence  globale  aux  textes  selon  des  statistiques  sur  la  présence de mots subjectifs (Bestgen, 2006 ;  Turney, 2002). Les  approches dites symboliques  intègrent  la  prise en compte de phénomènes syntaxiques qui viennent modifier l'orientation sémantique de mots ou de  groupes de mots (Harb  et  al., 2008 ; Vernier  et  al., 2009 ;  Wilson et  al., 2005). Enfin, quelques tentatives  d'apprentissages  supervisés  ont  également  pris  en  compte  des  mots,  dont  la  valence  est  connue,  comme  caractéristiques  de  leurs  vecteurs  (Chesley  et  al.,  2006).  Ces  lexiques  constituent  donc  des  ressources  sémantiques capitales au développement de classifieurs efficaces.   Dans un premier temps, ces lexiques ont été construits manuellement par des juges (Nasukawa, Yi, 2003 ;   Wiebe et al., 2005), mais le travail étant lent et couteux, des procédures automatiques ou semi-automatiques  ont  vu  le  jour  et  constituent  aujourd'hui  un  sous-domaine  de  recherche  important.  Comme  le  souligne  la  présentation  des  travaux  antérieurs  (section  2),  une  spécificité  des  recherches  menées  dans  ce  champ  est  qu'elles  portent  presque  exclusivement  sur  l'anglais,  langue  pour  laquelle  de  nombreuses  ressources  linguistiques  ont  été  développées  comme  WordNet  (Miller,  1990).  Un  des  deux  objectifs  principaux  de  notre  étude  est  de  déterminer  dans  quelle  mesure  ces  méthodes  sont  applicables  au  français.  Une  autre  spécificité des recherches menées dans ce champ est que la quasi-totalité des méthodes proposées utilise un  petit  nombre  de  mots,  comme  bon,  mauvais,  gentil,  afin  de  servir  de  germes  (seed)  pour  déterminer  automatiquement la valence d'autres mots (voir par exemple Hu, Liu, 2004; Kamps, Marx, 2002 ; Turney,  Littman, 2003). La question de l'optimalité de ces mots germes a bien peu retenu l'attention, le plus souvent  les  chercheurs  reprenant  ceux  proposés  dans  des  travaux  antérieurs  (Esuli,  Sebastiani,  2006 ;  Harb  et  al.,  2008).  Notre  second  objectif  est  de  proposer  une  méthode  permettant  d'identifier  automatiquement  ces  germes au moyen d'une technique d'apprentissage supervisée.   Après une brève présentation des travaux antérieurs, la section 3 décrit les différentes méthodes comparées   dans le cadre de cette étude. Une série d'expériences visant à évaluer leur efficacité sont présentées dans la  section  4.  La  section  5  rapporte  les  principaux  résultats,  dont  les  implications  et  les  développements  possibles sont discutés dans la conclusion.   Parmi les méthodes automatiques ou semi-automatiques proposées pour construire des lexiques porteurs de   valences, on peut distinguer deux types d'approches : celles basées sur des ressources linguistiques comme  WordNet et celles basées sur des corpus de textes.    Les  approches  qui  s'appuient  sur  des  bases  de  connaissances  linguistiques  calculent  généralement  la   similarité entre  les mots à partir de leur relation de synonymie. Une méthode de base  consiste à partir de  quelques mots dont la valence est connue et à lancer un algorithme d'amorçage (bootstrapping) qui parcourt  les liens synonymiques et antonymiques de la base, en attribuant la même orientation aux mots synonymes  et vice-versa (Hu, Liu, 2004 ; Kim, Hovy, 2004). Kamps et Marx (2002) ont probablement été les premiers  à proposer une telle procédure en dérivant de WordNet un graphe dans lequel chaque noeud représente un  terme et un lien est présent entre deux noeuds s'ils sont synonymes. À partir de ce graphe, ils calculent une  valeur  normalisée  pour  les  noeuds  liés  aux  mots  good  et  bad.  Esuli  et  Sebastiani  (2006)  ont  étendu  cette  approche  pour  développer  SentiWordNet,  une  ressource  basée  sur  WordNet,  qui  assigne  à  chaque  synset  trois  valeurs  normalisées :  une  positive,  une  négative  et  une  objective.  La  spécificité  principale  de  leur  approche  est qu'elle s'appuie sur un apprentissage semi-supervisé basé  sur les définitions de  mots germes  sélectionnés manuellement.   calculent  les  similarités  différemment.  Hatzivassiloglou  et  McKeown  (1997)  ont  proposé  un  algorithme  capable de déterminer l'orientation sémantique d'adjectifs à partir de l'analyse de leurs cooccurrences avec  des  conjonctions.  Turney  et  Littman  (2003 ;  Turney,  2002)  et  Bestgen  (2002,  2008)  ont  proposé  des  méthodes plus générales puisqu'elles permettent d'estimer la valence de n'importe quel terme présent dans  un  corpus.  Ils  utilisent  l'analyse  sémantique  latente  (ASL,  Latent  Semantic  Analysis,  Deerwester  et  al.,  1990)  pour  construire  un  espace  sémantique  à  partir  d'informations  statistiques  sur  les  cooccurrences  de  termes dans des textes. Turney et Littman l'emploient pour estimer la distance sémantique entre des mots et  14 mots germes, 7 positifs (good, nice, excellent, positive, fortunate, correct, superior) et 7 négatifs (bad,  nasty, poor, negative, unfortunate, wrong, inferior). Un mot est d'autant plus positif qu'il est plus proche des  germes  positifs  et  plus  éloigné  des  germes  négatifs.  Pour  sa  part,  Bestgen  (2002)  a  recours  à  l'ASL  pour  identifier les mots fréquemment associés aux mots dont il veut déterminer la valence affective. Il attribue à  chaque  mot  la  valence  moyenne  de  ses  plus  proches  voisins  dont  la  valence  est  connue.  Pour  cela,  il  s'appuie  sur  un  dictionnaire  de  3000  mots  dont  la  valence  a  été  évaluée  par  des  juges.  On  notera  que  les  similarités  peuvent  être  calculées  sans  passer  par  l'analyse  sémantique  latente,  mais  que,  dans  ce  cas,  des  corpus de très grande taille semblent nécessaires (Turney, Littman, 2003; Velikovich et al., 2010), sauf si, à  la manière de Harb et al. (2008), on emploie un corpus très spécifique et des règles d'associations.   Peu d'initiatives de construction automatique de lexiques ont eu lieu en français, comparé à l'effervescence   dans  le  milieu  anglophone.  Nous  pouvons  citer  Bestgen  (2002)  et  Chardon  (2010)  qui  a  développé  une  méthode  pour  élaborer  une  ressource  lexicale  d'adjectifs  d'opinion  à  partir  d'une  liste  de  mots  germes  et  d'une  taxinomie  des  mots  du  français.  Pak  et  Paroubek  (2010)  ont  proposé  une  méthode  de  construction  automatique d'un lexique affectif à partir de messages disponibles sur Twitter. Leur procédure est basée sur la  comparaison  de  la  fréquence  d'occurrence  d'un  mot  dans  les  messages  contenant  une  émoticône  positive  et  dans  ceux  contenant  une  émoticône négative.  Vernier  et  Monceaux  (2010)  ont  proposé  une  méthode  d'apprentissage  pour  enrichir  automatiquement  un  lexique  subjectif  à  partir  d'un  corpus  annoté.  L'apprentissage  automatique  se  base  sur  des  tests  sémantiques,  qui  permettent  de  mesurer  le  degré  de  subjectivité des termes, ainsi que leur valence s'il s'agit d'adjectifs, et qui sont effectués à l'aide du moteur  de recherche Yahoo!.     Cinq  méthodes  pour  estimer  automatiquement  la  valence  de  mots  ont  été  comparées,  deux  de  celles-ci   consistant en une transposition de méthodes efficaces pour la langue anglaise : celle de Turney et Littman  (2002,  2003)  et  celle  de  Kamps  et  Marx  (2002 ;  Kamps  et  al.,  2004).  Nous  avons  également  repris  la  méthode de Bestgen (2002, 2008). Ces  trois  méthodes serviront de référence pour évaluer deux nouvelles  approches :  une  extension  de  la  méthode  de  Kamps  et  Marx  et  une  méthode  d'apprentissage  supervisé  de  mots germes. La présente section décrit les principes à la base de ces différentes méthodes. Des précisions à  propos  de  leur  implémentation  et  des  ressources  linguistiques  qu'elles  requièrent  sont  données  dans  la  section suivante.    3.1   Niveaux de base : SO-ASL et DIC-ASL   Ces deux méthodes se basent sur l'analyse sémantique latente d'une collection de textes pour déterminer la   proximité entre des mots et des germes dont la valence est connue.      SO-ASL : il s'agit de la méthode proposée par Turney et Littman (2003) décrite ci-dessus. Elle  est basée sur 14 mots germes choisis en raison de leur valence extrême sur la dimension positifnégatif.  La  valence  d'un  mot  correspond  à  la  somme  des  cosinus  entre  ce  mot  et  les  germes  positifs dont on soustrait la somme des cosinus entre ce mot et les germes négatifs.      DIC-ASL :  il  s'agit  de  la  méthode  proposée  par  Bestgen  (2002)  décrite  ci-dessus.  Pour  chaque  mot dont on veut déterminer la valence, on identifie les 30 plus proches voisins dont la valence  est connue et on lui affecte la valence moyenne de ceux-ci.    Ces deux méthodes sont basées sur la fonction d'évaluation définie par Kamps et Marx (2002).       KA1 : cette méthode est basée sur les liens synonymiques entre les adjectifs. Le principe consiste  à  mesurer  la  distance  minimale,  c'est-à-dire  le  plus  court  chemin,  entre  le  mot  auquel  on  veut  attribuer une valeur et les mots germes good et bad. La valence d'un terme t est alors égale à sa  distance relative avec les deux germes :      où d (i, j) représente la distance du plus court chemin synonymique entre les mots i et j.       KA7 est  une  adaptation  de  KA1  dans  laquelle  le  nombre  de  paires  d'adjectifs  de  référence  est  multiplié  par  7.  Nous  avons  repris  les  7  paires  de  référence  de  Turney  et  Littman  (2003),  que  nous  avons  traduites  comme  suit :  bon,  gentil,  excellent,  positif,  heureux,  correct,  supérieur  et  mauvais,  méchant,  médiocre,  négatif,  malheureux,  faux,  inférieur.  La  fonction  d'évaluation  adaptée reprend alors la somme des évaluations pour chaque paire :       où i  et j  forment une paire d'adjectifs positif et négatif des n paires prises en compte.    3.3   Apprentissage supervisé de mots germes : ASG   Un des objectifs de cette recherche est de proposer et d'évaluer une méthode dérivée de celles de Turney et   Littman (2003) et de Bestgen (2002) dans laquelle les mots germes originaux, sélectionnés arbitrairement,  sont remplacés par des germes optimaux obtenus par une procédure d'apprentissage supervisée basée sur la  régression.  Pour  ce  faire,  nous  employons  comme  matériel  d'apprentissage  une  norme  lexicale  pour  la  dimension  évaluative  obtenue  en  demandant  à  des  juges  d'évaluer  un  grand  nombre  de  mots  sur  cette  dimension. À la suite de Heise (1965), une série de normes de ce type ont été développées, principalement  en  psycholinguistique  (Syssau,  Font,  2005).  La  méthode  proposée  est  composée  des  quatre  étapes  suivantes :   1.   Sélectionner  comme  germes  potentiels  les  mots  qui  sont  les  plus  extrêmes  sur  la  dimension  positif-négatif selon une norme évaluative comme celle employée dans DIC-ASL.   2.   Sur  la  base  d'un  espace  sémantique  obtenu  par  l'ASL  d'une  collection  de  textes,  calculer  le  cosinus entre chacun de ces germes potentiels et tous les mots qui se trouvent dans la norme.   3.   Utiliser une procédure de régression afin de  construire un  modèle prédictif basé sur  les germes  les plus efficaces pour prédire la valence.   4.   Employer  le  modèle  construit  à  l'étape  précédente  pour  estimer  la  valence  de  termes  présents  dans l'espace sémantique, mais non dans la norme initiale.   Le critère de sélection des germes potentiels proposé à la première étape devrait permettre l'identification de   mots  germes  similaires  à  ceux  originellement  choisis  par  Turney  et  Littman  (2003).  Toutefois,  lorsqu'on  considère  le  fait  que  le  seuil  pour  sélectionner  les  mots  les  plus  extrêmes  est  par  définition  arbitraire,  il  devient immédiatement évident que la procédure proposée  n'est qu'un cas particulier d'une procédure plus  générale dans laquelle les germes potentiels sont composés de l'ensemble des mots présents dans la norme.  Et,  d'une  manière  tout  aussi  évidente,  cette  première  généralisation  n'est,  elle-même,  qu'un  cas  particulier  d'une  seconde  généralisation,  qui  emploie  comme  germes  potentiels  tous  les  mots  pour  lesquels  il  est  possible de calculer un cosinus avec les mots qui se trouvent dans la norme, soit tous les mots présents dans  l'espace  sémantique,  que  leur  valence  soit  connue  ou  non.  Étant  donné  que  les  candidats  germes  pour  l'approche la plus restrictive forment un sous-ensemble des candidats germes employés dans les approches  plus générales, on doit s'attendre à ce que la qualité de la prédiction de la valence des mots du dictionnaire  des  différents  modèles  pourraient  être  équivalentes  si  ceux  basés  sur  le  plus  grand  nombre  de  germes  potentiels présentent un défaut de surapprentissage.   4.1   Ressources linguistiques pour l'implémentation des méthodes   Les  différentes  méthodes  proposées  ci-dessus  nécessitent  des  ressources  linguistiques  spécifiques  comme   un dictionnaire de synonymes ou une collection de textes pour extraire l'espace sémantique. Les ressources  que nous avons employées sont décrites dans la présente section.   4.1.1   Dictionnaire de synonymes   L'adaptation  de  la  méthode  de  Kamps  et  Marx  (2002)  au  français  nécessite  une  ressource  plus  ou  moins   équivalente  au  WordNet  anglais.  En  raison  de  la  trop  faible  couverture  de  WOLF  (WordNet  Libre  du  Français) et du WordNet français développé dans le cadre du projet EuroWordNet , nous avons employé le  dictionnaire de synonymes développé par  le  laboratoire  CRISCO de  l'université de  Caen (Manquin  et al.,  2004) . Celui-ci a été constitué à partir de sept dictionnaires français et comprend plus de 49 000 entrées et  396 000  relations  synonymiques.  De  manière  similaire  à  Kamps  et  Marx  (2002),  nous  avons  récupéré  récursivement tous les mots liés à la paire d'adjectifs bon et mauvais, avec des restrictions sur la catégorie  grammaticale pour éviter de générer trop de bruit. Une petite adaptation a dû être faite pour rendre la liste  des synonymes récupérés symétrique (Kamps et al., 2004 : 1115).   4.1.2   Norme de valence : Nev   La norme de valence  employée pour les méthodes DIC-ASL et ASG  est  composée de 3252 mots évalués   sur une échelle à 7 points allant de  très désagréable (1) à  très agréable (7) par un minimum de 30 juges  (Hogenraad et  al., 1995). À  titre d'exemple, la liste  suivante donne les valeurs attribuées à quelques mots  extraits aléatoirement de ce dictionnaire : détresse = 1.4, impassible = 2.6, ambigu = 3.2, outil = 4.3, revenir  = 5.0, admiratif = 5.7, doux = 6.0.    4.1.3   Constitution de l'espace sémantique   L'espace sémantique, utilisé pour calculer les cosinus entre les mots nécessaires pour SO-ASL, DIC-ASL et   ASG,  a  été  construit  sur  la  base  d'une  collection  de  textes  littéraires  composée  de  romans,  nouvelles  et  contes  disponibles  sur  le  Web  (principalement  dans  les  bases  littéraires  ABU  et  Frantext).  Elle  contient  approximativement 5 300 000 mots. Chaque texte a été subdivisé en segments de 125 mots. Pour construire  le  tableau  lexical,  les  prétraitements  suivants  ont  été  effectués :  lemmatisation  par  le  logiciel  TreeTagger  (Schmid, 1994), suppression de mots outils et suppression des mots de fréquence totale inférieure à 10. La  matrice de cooccurrences des 12 285 termes dans les 40 635 segments a été soumise à une décomposition  en valeurs singulières et les 300 premiers vecteurs propres ont été conservés.   4.2   Méthode pour l'évaluation   Pour  évaluer  l'efficacité  de  méthodes  visant  à  déterminer  automatiquement  la  valence  de  mots,  le  test   classique,  lorsque l'étude  est réalisée en anglais,  se base sur les  listes de  mots positifs  et négatifs  incluses  dans le General Inquirer (p.e., Dragut et al., 2010 ; Kamps et al., 2004 ; Turney, Littman, 2003). Ces listes  n'étant pas, à notre connaissance, disponibles en français, nous avons recherché un matériel équivalent dans                                                                  Le WOLF couvre 30 % du WordNet de Princeton (Mouton & Chalendar, 2010) et, selon nos calculs, le  WordNet français couvre environ 25 % des synsets de la version 1.5 de WordNet.     www.crisco.unicaen.fr/cgi-bin/cherches.cgi  l'avantage d'avoir été récoltées dans des conditions rigoureuses et bien documentées, alors qu'on ne dispose  de  pratiquement  aucune  information  sur  la  procédure  suivie  pour  constituer  les  deux  listes  du  General  Inquirer. Cependant, elles ne portent que sur 735 mots alors que les listes originales du General Inquirer en  contiennent plusieurs milliers. À titre comparatif, nous avons réalisé une première adaptation française des  listes du General Inquirer.   4.2.1   Valemo : V80, V50 et Vscore   Syssau  et  Font  (2005)  ont  demandé  à  600  juges  d'évaluer  735  mots    sur  deux  échelles :  une  échelle  nominale  à  trois  modalités  (négatif,  neutre  et  positif)  et  une  échelle  bipolaire  en  11  points  allant  de  très  négatif (-5) à très positif (+5) (voir Syssau et Font pour une discussion des  avantages et  inconvénients de  ces deux types d'évaluation). Chaque mot a été évalué par 100 juges et un même juge n'a effectué qu'un seul  des  deux  types  d'évaluation.  Les  mots  ont  été  sélectionnés  sur  la  base  de  deux  normes  d'associations  verbales de manière à constituer &#34;un ensemble de mots suffisamment diversifié pour être représentatif de la  langue française&#34; (Syssau, Font, 2005). De la première évaluation, Syssau et Font ont dérivé deux normes  catégorielles :  les  mots  &#34;indubitablement&#34;  positifs  ou  négatifs  qui  ont  été  classés  dans  la  catégorie  correspondante par au moins 80% des juges (V80) et les mots &#34;majoritairement&#34; positifs ou négatifs qui ont  été classés ainsi par au moins 50% des  juges (V50). La seconde évaluation a produit une norme valencée  (Vscore) avec pour chaque entrée un score compris entre -5 et +5.    4.2.2   General Inquirer (version francisée) : GI   Le General Inquirer est un projet né en 1961 qui visait à développer un programme d'analyse objective de   contenu  (Stone  et  al.,  1966)  basé  sur  un  dictionnaire  composé  de  182  catégories  sémantiques.  Les  deux  dernières catégories ajoutées sont les catégories positive et négative, qui répertorient respectivement 1915 et  2291  mots.  Ces  listes  n'étant  pas,  à  notre  connaissance,  disponibles  en  français,  nous  les  avons  traduites  automatiquement à l'aide du traducteur en ligne Systran. Après avoir été lemmatisées avec TreeTagger, ces  deux listes ont été contrôlées par deux juges. Après suppression des doublons et des mots présents dans les  deux listes - problèmes présents dans la version originale, mais également dus à la traduction - , nous avons  obtenu 1246 mots positifs et 1527 mots négatifs.   Cinq  normes  ont  été  employées  pour  comparer  l'efficacité  des  méthodes  de  construction  automatique  de   lexiques dans l'estimation de la valence de mots : la norme Nev, les trois normes issues du projet Valemo  (Vscore, V50 et V80) et notre traduction des listes positive et négative du General Inquirer (GI). Pour les  deux normes qui définissent la valence comme une variable continue (Nev et Vscore), nous avons évalué la  qualité de la prédiction en calculant le coefficient de corrélation de Pearson entre les valences prédites par  les méthodes automatiques et les valeurs moyennes attribuées par les juges. Lorsque la variable à prédire est  dichotomique (positif versus négatif : V50, V80 et GI), nous avons employé comme mesure d'efficacité le  pourcentage  de  mots  classés  par  les  procédures  automatiques  dans  la  catégorie  déterminée  par  la  norme.  Pour  chacune  des  méthodes  évaluées,  un  mot  est  considéré  comme  négatif  lorsque  sa  valence  prédite  est  inférieure à la moyenne et comme positif dans le cas contraire .    La principale difficulté que nous avons rencontrée lors de ces analyses trouve son origine dans le fait que   les différentes méthodes testées ne donnent pas des valeurs de valence aux mêmes mots : celles dérivées de  Kamps et Marx (2002) en proposent un nombre nettement plus restreint que celles qui s'appuient sur l'ASL.  Ceci nous a conduits à présenter séparément les résultats de ces deux groupes de méthodes.                                                                     La  norme  initiale  portait  sur  605  mots,  mais  elle  a  été  ultérieurement  étendue  à  735  mots.  Elle  est  disponible à l'adresse : http://www.lexique.org/     Des  analyses  complémentaires  ont  montré  que  ce  seuil  était  proche  de  la  valeur  optimale  obtenue  par  régression logistique.   Le tableau 1 présente les performances des méthodes KA1 et KA7 pour les différentes normes. Pour tous   les tests, KA7, la version basée sur les 7 paires de mots germes de Turney et Litman (2003), est supérieure à  KA1  qui  n'emploie  qu'une  seule  de  ces  paires,  celle  sélectionnée  par  Kamps  et  Marx  (2004).  Les  corrélations entre la valence prédite par les méthodes et la valence moyenne selon les juges sont élevées et  même  très  élevées  pour  Vscore.  Pour  la  prédiction  de  la  catégorie  des  mots,  les  performances  sont  également  impressionnantes  pour  les  trois  tests.  Dans  leur  étude  sur  l'anglais,  Kamps  et  al.  (2004)  rapportent  un  pourcentage  de  mots  bien  classés  par  leur  procédure  de  67 %  pour  les  667  adjectifs  pour  lesquels  ils  ont  pu  calculer  un  score  d'évaluation  à  partir  de  WordNet  et  qui  se  trouvent  dans  la  liste  du  General Inquirer (Evaluation II, Table 1 dans Kamps et al., 2004). Cette valeur est nettement inférieure à  celle que nous avons obtenue. S'il est difficile d'identifier précisément l'origine de l'amélioration, force est  de  constater  que  l'implémentation  de  la  technique  de  Kamps  et  Marx  sur  la  base  d'un  dictionnaire  de  synonymes plutôt que de WordNet est une alternative viable.      Nev  Vscore  V80  V50  GI   N   663  76  20  43  688   KA1   0.55  0.64  90%  84%  80%   KA7   0.61  0.72  100%  88%  84%   Tableau 1 : Performances (corrélation et pourcentage de classification correcte)     5.2   Approches basées sur l'ASL   Dans cette section, nous comparons la nouvelle méthode ASG à celles de  Turney et Littman (2003) et de   Bestgen (2002). Quatre versions différentes de ASG ont été testées.  Elles se distinguent par  l'étendue des  germes potentiels pris en compte : ASG0.5 limite ceux-ci aux valeurs les plus extrêmes de la norme (de 1 à  1.5 et de 6.5 à 7), ASG1.0 est moins stricte et prend en compte celles comprises entre 1 et 2 et entre 6 et 7,  ASGnorme  prend  en  compte  l'ensemble  des  mots  repris  dans  la  norme  Nev  et  ASGtout  sélectionne  les  germes parmi l'ensemble des termes présents dans l'espace sémantique. Pour construire le modèle prédictif  sur  la  base  de  ces  ensembles  de  germes  potentiels,  nous  avons  employé  une  régression  linéaire  multiple   avec  sélection  des  prédicteurs  par  la  technique  ascendante  (forward)  et  un  seuil  de  probabilité  pour  la  sélection fixé à 0.01.   5.2.1   Performances pour le matériel d'apprentissage : Nev   La première ligne du tableau 2 présente les corrélations entre les valeurs données dans la norme Nev, qui a   servi  pour  l'apprentissage,  et  les  valeurs  prédites  par  les  différentes  méthodes.  Comme  on  pouvait  s'y  attendre,  SO-ASL,  la  seule  des  méthodes  qui  ne  s'appuie  pas  sur  la  norme,  obtient  le  moins  bon  résultat.  Tout aussi attendus sont les bénéfices apportés par l'apprentissage supervisé (ASG versus DIC-ASL) et par  la possibilité de choisir les germes parmi un nombre plus important de candidats. On note néanmoins que la  différence principale se situe entre ASG0.5 et ASG1.0.   5.2.2   Performances pour Vscore   L'analyse de Vscore, deuxième  ligne du  tableau 2, donne comme attendu, des valeurs inférieures  à  celles   obtenues  pour  la  norme  ayant  servi  à  l'apprentissage,  mais  la  différence  est  assez  faible.  On  note  tout  particulièrement  que  les  méthodes  ASG  sont  nettement  plus  performantes  que  SO-ASL,  ce  qui  confirme  l'hypothèse que les mots germes employés par cette dernière sont loin d'être optimaux.                                                                    Toutes les analyses ont également été effectuées en employant la SVR (SVM appliqué à la régression),  mais ils ne sont pas présentés, car les deux techniques ont produit des résultats très similaires.   Nev   2685  0.38  0.60  0.60  0.65  0.66  0.67   Vscore  631   0.32  0.60  0.56  0.61  0.61  0.60   Tableau 2 : Corrélation entre les valeurs prédites par les méthodes et les normes     5.2.3   Performances pour les catégories : V80, V50 et GI   Le  tableau  3  présente  le  pourcentage  de  mots  bien  classés  pour  les  différentes  normes  catégorielles.  Les   performances pour V80 et V50 sont très élevées, mais il faut prendre en compte le fait que ces deux normes  ne  contiennent  qu'un  nombre  réduit  de  mots.  Pour  l'adaptation  française  du  General  Inquirer,  les  performances sont moins bonnes. Elles dépassent toutefois largement la performance de SO-ASL rapportée  par  Turney  et  Littman  (2003)  pour  le  General  Inquirer  en  version  anglaise  (65%),  valeur  très  proche  de  celle  que  nous  avons  obtenue  pour  l'adaptation  française  (64%).  On  observe  aussi  que  DIC-ASL  fait  presque aussi bien que les méthodes basées sur une procédure d'apprentissage automatique.    Test   SO-ASL  DIC-ASL  ASG0.5  ASG1.0  ASGnorme  ASG,tout   V80 (N=128)   73%  88%  83%  87%  88%  91%   V50 (N=280)   63%  82%  78%  82%  84%  82%   GI (N=1992)   64%  71%  70%  72%  73%  72%   Tableau 3 : Pourcentage de classification correcte    Dans  le  tableau  3,  tous  les  mots  mentionnés  dans  les  normes  sont  pris  en  compte,  même  ceux  qui  sont   présents dans la norme Nev qui a servi à l'apprentissage supervisé. Il s'ensuit qu'il est problématique de se  baser  sur  ces  données  pour  évaluer  les  capacités  de  généralisation  de  la  méthode  ASG  à  des  mots  qui  ne  font pas partie du matériel d'apprentissage. Pour cette raison, les mêmes analyses que celles rapportées cidessus  ont  été  effectuées  après  suppression  dans  les  normes  catégorielles  de  tous  les  mots  présents  dans  Nev.  Les  résultats  sont  présentés  dans  le  tableau  4.  Pour  GI,  on  observe  une  diminution  assez  faible  et  relativement  égale  des  performances  pour  toutes  les  méthodes,  y  compris  celles  qui  n'ont  pas  recours  à  l'apprentissage  supervisé.  Pour  V50  et  surtout  V80,  les  différences  sont  plus  nettes  et  s'observent  même  pour SO-ASL, alors que cette méthode ne s'appuie pas sur la norme Nev. L'explication la plus probable est  que les mots qui ont été supprimés sont particulièrement faciles à classer par toutes les méthodes.    Test   SO-ASL  DIC-ASL  ASG0.5  ASG1.0  ASGnorme  ASG,tout   V80 (N=25)   60%  80%  68%  72%  72%  76%   V50 (N=82)   60%  82%  72%  73%  78%  74%   GI (N=1130)   62%  68%  68%  71%  71%  70%   Tableau 4 : Pourcentage de classification correcte pour les mots non inclus dans Nev     D'une  manière  générale,  ces  tests  confirment  le  caractère  non  optimal  des  mots  germes  employés  dans   l'approche SO-ASL, cette méthode atteignant un niveau de performance nettement  inférieur à celui atteint  par toutes celles basées sur l'apprentissage supervisé de germes.    Une dernière série d'analyses visent à comparer le plus rigoureusement possible les performances de toutes   les procédures testées, y compris KA1 et KA7, sur une même tâche afin de  les rendre comparables. On a  donc calculé le pourcentage de termes bien classés pour les mots de GI traités par toutes les méthodes. Le  tableau 5, qui présente ces résultats, souligne  la supériorité  de KA7 sur toutes les autres méthodes. Il faut  toutefois garder à l'esprit que KA7 propose au maximum des valeurs pour 688 mots du GI   alors que  les  méthodes  basées  sur  l'ASL  traitent  1992  mots  de  cette  même  liste.  De  plus,  nous  n'avons  employé  qu'un  seul espace sémantique d'un genre très spécifique (voir discussion). Les mêmes analyses ont été réalisées en  supprimant,  en  plus,  les  mots  qui  sont  dans  la  norme  NEV,  sans  que  les  conclusions  ne  soient  modifiées  (différences plus petites ou égales à 2%).    N  SO-ASL  DIC-ASL  ASG0.5  ASG1.0  ASGnorme  ASGtout  KA1  KA7    550   64%  70%  75%  75%  76%  75%  80%  83%   Tableau 5 : Pourcentage de classification correcte pour les mots de GI traités par toutes les méthodes    5.4   Mots germes les plus importants pour prédire la valence   Si  la  méthode  ASG  n'apparait  pas  comme  nettement  supérieure  à  DIC-ASL,  elle  présente  un  avantage   potentiellement  très  important  en termes d'identification de  mots germes. Alors que DIC-ASL sélectionne  les  germes  localement  puisqu'un  ensemble  différent  de  germes  est  employé  pour  chaque  mot,  ASG  sélectionne  les  germes  globalement :  un  seul  et  même  ensemble  de  germes  est  employé  pour  prédire  la  valence de tous les mots. Il reste cependant à montrer que les germes choisis par ASG sont bien pertinents.    Une première manière de répondre à cette question consiste à s'intéresser au modèle prédictif construit par   la  régression  multiple.  Faute  de  place,  il  n'est  pas  possible  de  reprendre  ici  tous  les  mots  germes  sélectionnés  par  les  différentes  versions  de  ASG.  La  liste  suivante  présente  l'ensemble  des  germes  sélectionnés par ASG1.0, suivant l'ordre dans lequel ils ont été introduits dans le modèle (chaque fois suivi  par  la  valence  selon  la  norme  Nev) :  épouvantable  (1.8),  délicieux  (6.2),  irriter  (1.9),  admiration  (6.1),  affectueux (6.2), atroce (1.5), heureux (6.5), monstrueux (1.4), magnifique (6.5), embrasser (6.4),  lugubre  (1.8), rêver (6.3), libre (6.3), savourer (6.0), ennui (1.7), intéressant (6.0), indifférence (2.0), espoir (6.1),  pire (1.4), fidèlement (6.1), gaieté (6.4), rat (1.9), insulte (1.6), maladie (1.5), laideur (1.6), enlacer (6.4),  enfant (6.3), crasse (1.8), voyage (6.2), malchance (1.6), admirable (6.1).    L'analyse  qui  précède  repose  sur  le  modèle  prédictif  construit  par  la  régression  multiple.  Celui-ci   correspond  à  la  meilleure  combinaison  possible  de  mots  germes  pour  prédire  la  norme  et  non  aux  mots  germes  qui  apportent  individuellement  la  contribution  la  plus  importante  à  la  prédiction  de  celle-ci.  Tout  particulièrement, la régression multiple ne sélectionnera qu'un seul de deux mots sémantiquement très liés,  même si tous les deux sont d'excellents prédicteurs (cf. rage et colère dans le tableau 6). Or, comme notre  objectif  prioritaire  est  d'identifier  des  mots  germes  spécifiques  qui  pourraient  être  ensuite  employés  dans  d'autres méthodes, comme celle de Kamps et Marx (2002), il semble préférable de s'intéresser à ces derniers  et donc à ceux dont le vecteur de cosinus (avec les mots présents dans la norme) est le plus corrélé avec la  valence  de  ces  mots.  Le  tableau  6  présente,  à  titre  d'exemple,  une  petite  fraction  des  germes  les  plus  importants pour prédire la valence, classés par ordre d'efficacité, lorsqu'on prend en compte l'ensemble des  mots  présents  dans  l'espace  sémantique.  La  partie  gauche  reprend  les  30  germes  les  plus  corrélés  négativement  avec  la  valence  et  la  partie  droite  les  30  germes  les  plus  corrélés  positivement.  La  quasitotalité  des  germes  négatifs  mentionnés  dans  ce  tableau  correspond  à  ce  qu'on  entend  habituellement  par  mots  germes  pour  la  valence .  La  grande  majorité  des  germes  positifs  sont  aussi  pertinents  et  plus  de  la  moitié d'entre eux ne se trouve pas dans la norme ayant servi à l'apprentissage (signalé par un &#34;-&#34; à la place  du score de valence). Cette observation souligne la valeur heuristique de la méthode proposée. On y trouve  néanmoins  quelques  mots  spécifiques  à  la  collection  de  textes  employée  pour  l'ASL  (mythologique,  nymphe, pampre). Il est à noter que les germes qui suivent, par ordre d'importance, ceux présentés dans le                                                                     Il  n'est  pas  possible,  à  ce  stade  de  l'analyse,  de  déterminer  le  nombre  de  cas  dans  lesquels  débattre  correspond à se débattre. Il s'agit là d'une limite évidente des prétraitements effectués avant l'extraction  de l'espace sémantique  31. brute, 41. monstrueux, 51. exécration, 61. exaspération, 71. désespérer, 81. sourd, 91. égorgement, 101.  râle.      Négatif  Nev    Négatif  Nev    Positif  Nev    Positif  Nev  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  rage  colère  épouvantable  fureur  atroce  horrible  abominable  écraser  horreur  crachat  exaspérer  misérable  étrangler  affreux  assassin  2.1  2.2  1.8  2.8  1.5  1.8  1.9  1.9  2.1  1.3  2.4  1.8  -  1.9  -  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  infamie  imprécation  tourmenteur  lâche  menaçant  menace  épouvanter  saigner  cracher  débattre  effrayant  plainte  crever  meurtre  injurier  -  -  -  1.1  -  -  2.0  -  -  -  2.4  -  1.7  1.4  1.9  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  charmant  charmer  ravissant  délicieux  gracieux  merveille  magnifique  brillant  aimable  harmoniser  élégant  riant  splendide  mythologique  composer  5.7  5.8  6.4  6.2  5.9  6.1  6.5  -  5.9  -  -  -  -  -  -  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  charme  description  modeste  ravir  admirable  romance  nymphe  exquis  distingué  pampre  enchanter  exotique  raffoler  modestement  fraîcheur  6.1  -  -  5.6  6.1  4.4  -  -  -  -  -  -  -  -  -   Tableau 6 : Mots germes sélectionnés par la méthode ASG    Pour  conclure,  nous  avons  transposé  au  français  deux  méthodes  de  construction  automatique  de  lexiques   porteurs  de  valences  bien  établies  dans  le  monde  anglo-saxon :  celles  de  Turney  et  Littman  (2003)  et  de  Kamps  et  Marx  (2002).  Cette  dernière  montrant  des  résultats  encourageants,  nous  l'avons  étendue  en  augmentant  le nombre de paires de mots germes.  Cette modification nous a permis d'obtenir les meilleurs  résultats, avec plus de 80 % de  termes bien classés.  Ce pourcentage doit cependant  être relativisé dans la  mesure où il est calculé sur un nombre restreint de mots. Nous avons également développé une méthode qui  sélectionne les mots germes par apprentissage supervisé. Avec une efficacité d'environ 75 %, elle surpasse  nettement  la  méthode  SO-ASL  dont  elle  est  dérivée.  Il  est,  hélas,  impossible  de  déterminer  si  les  valeurs  obtenues  reflètent  un  niveau  de  performance  proche  de  celui  atteint  par  des  annotateurs  parce  qu'on  ne  dispose  pas  d'information  à  propos  du  degré  d'accord  entre  ceux-ci.  L'analyse  des  mots  apportant  la  plus  grande  contribution  individuelle  à  la  prédiction  de  la  valence  souligne  l'intérêt  de  cette  méthode  pour  l'identification de mots germes. Un des principaux développements envisagés est d'utiliser ces mots germes  dans des méthodes comme celles de Kamps et Marx (2002) ou d'Esuli et Sebastiani (2006). Des adaptations  seront nécessaires puisque, dans la version actuelle, les mots germes identifiés ne forment pas des couples  comme requis par la méthode de Kamps et Marx. Il sera tout particulièrement intéressant de déterminer si la  méthode  proposée,  qui  ne  requiert  pas  WordNet,  est  plus  efficace  que  celle  développée  par  Esuli  et  Sebastiani et, surtout, si l'emploi dans leur méthode des mots germes identifiés par ASG améliore encore les  performances.  Enfin,  il  sera  nécessaire  d'évaluer  les  bénéfices  apportés  par  l'apprentissage  supervisé  de  germes pour l'objectif principal de ce genre d'études : déterminer l'orientation de textes (Harb et al., 2008).   Cette  étude  comporte  plusieurs  limitations  qui  sont  autant  de  pistes  pour  des  recherches  futures.  Tout   d'abord,  un  seul  espace  sémantique,  extrait  de  textes  littéraires,  a  été  exploité.  Les  implications  de  cette  limitation sont particulièrement mises en évidence par la sélection de mots germes spécifiques à ce genre de  textes.  Il  serait  intéressant  d'effectuer  ces  analyses  sur  un  corpus  plus  diversifié  ou,  séparément,  sur  des  corpus  de  genres  différents.  Dans  ce  dernier  cas,  il  devrait  être  possible  d'attribuer  aux  mots  germes  un  indice qui traduit leur degré de généralité. Ensuite, les germes identifiés par la méthode ASG consistent en  des formes (lemmes) isolées, ce qui réduit fortement la qualité linguistique de l'analyse (voir débattre). La  prise en compte de mots composés ou d'expressions figées  serait également un développement intéressant  (Vernier,  Monceaux,  2010).  D'autres  méthodes  pour  mesurer  les  proximités  sémantiques  devraient  également  être  testées.  Il  est  en  effet  loin  d'être  évident  que  le  passage  par  l'ASL  améliore  l'efficacité  (Bestgen,  2006).  Enfin,  notre  traduction  des  listes  du  General  Inquirer  pourrait  sans  aucun  doute  être  améliorée afin de récupérer un certain nombre de mots perdus. Cependant, on peut s'interroger sur l'utilité  d'un tel travail, étant donné le peu d'information disponible sur la procédure de construction de ces listes. Il  rigueur et les procédés de construction sont bien établis.   Yves Bestgen est chercheur qualifié du F.R.S-FNRS. Les auteurs remercient vivement A. Syssau pour les   explications  complémentaires  à  propos  de  la  norme  Valemo  et  l'équipe  du  CRISCO  pour  l'autorisation  d'extraction des informations incluses dans le dictionnaire de synonymes.   
