L'alignement sous-phrastique consiste à extraire des traductions d'unités textuelles de grain inférieur à la phrase à partir de textes multilingues parallèles alignés au niveau de la phrase. Un tel alignement est nécessaire, par exemple, pour entraîner des systèmes de traduction statistique. L'approche standard pour réaliser cette tâche implique l'estimation successive de plusieurs modèles probabilistes de complexité croissante et l'utilisation d'heuristiques qui permettent d'aligner des mots isolés, puis, par extension, des groupes de mots. Dans cet article, nous considérons une approche alternative, initialement proposée dans (Lardilleux & Lepage, 2008), qui repose sur un principe beaucoup plus simple, à savoir la comparaison des profils d'occurrences dans des souscorpus obtenus par échantillonnage. Après avoir analysé les forces et faiblesses de cette approche, nous montrons comment améliorer la détection d'unités de traduction longues, et évaluons ces améliorations sur des tâches de traduction automatique. Sub-sentential alignment is the process by which multi-word translation units are extracted from sentence-aligned multilingual parallel texts. Such alignment is necessary, for instance, to train statistical machine translation systems. Standard approaches typically rely on the estimation of several probabilistic models of increasing complexity and on the use of various heuristics that make it possible to align, first isolated words, then, by extension, groups of words. In this paper, we explore an alternative approach, originally proposed in (Lardilleux & Lepage, 2008), that relies on a much simpler principle, which is the comparison of occurrence profiles in subcorpora obtained by sampling. After analyzing the strengths and weaknesses of this approach, we show how to improve the detection of long translation units, and evaluate these improvements on machine translation tasks. alignement sous-phrastique, traduction automatique par fragments. sub-sentential alignment, phrase-based machine translation.  L'alignement sous-phrastique consiste à extraire des traductions d'unités textuelles de grain inférieur à la phrase  à partir de corpus multilingues parallèles, c'est-à-dire dont les phrases ont préalablement été mises en correspondance. Cette tâche constitue la première étape de la plupart des systèmes de traduction automatique fondés sur les données (traduction statistique et traduction par l'exemple). Les systèmes qui concentrent aujourd'hui les efforts de recherche sont majoritairement des systèmes statistiques par fragments (phrases en anglais), qui utilisent comme principale ressource une table de traductions, dérivée d'alignements sous-phrastiques. Un telle table consiste en une liste pré-calculée de couples de traductions associant à chaque couple de fragments (source, cible) un certain nombre de scores reflétant la probabilité que source se traduise par cible.  On peut globalement inscrire les méthodes d'alignement sous-phrastique dans l'un des deux courants suivants :  l'approche estimative, introduite par Brown et al. (1988), et l'approche associative, introduite par Gale & Church (1991). La première est la plus utilisée à ce jour, principalement parce qu'elle est parfaitement intégrée à la traduction automatique statistique, dont elle constitue un pilier depuis l'apparition des modèles IBM (Brown et al., 1993). Cette approche consiste à définir un modèle probabiliste du corpus parallèle dont les paramètres sont estimés selon un processus de maximisation globale sur l'ensemble des couples de phrases disponibles. Pratiquement, le but est de déterminer les meilleurs appariements possibles entre les mots sources et cibles dans chacun des couples de phrases parallèles. Dans la seconde approche, on établit une liste de traductions candidates soumises à un test d'indépendance statistique, tels que l'information mutuelle (Fung & Church, 1994) ou le rapport de vraisemblance  (Dunning, 1993) - voir (Melamed, 2000; Moore, 2005) pour des travaux récents dans cette lignée. Il s'agit ici  d'un processus de maximisation locale : chaque segment est traité indépendamment des autres. Cette approche est plus souvent utilisée pour extraire directement des couples de traductions, tandis que la première cherche avant tout à établir des liens de traduction entre les mots sources et cibles de chacun des couples de phrases du corpus d'entrée. Ces liens permettent, dans un deuxième temps, d'extraire des couples de traductions.  Nous avons récemment proposé une méthode d'alignement sous-phrastique (Lardilleux & Lepage, 2008, 2009;  Lardilleux, 2010), apparentée aux méthodes associatives, s'attaquant à un certain nombre de problèmes souvent négligés dans le domaine : traitement simultané de multiples langues, parallélisme massif, passage à l'échelle au coeur de la méthode, et simplicité de mise en oeuvre. En moyenne, cette méthode s'est révélée meilleure que l'état de l'art sur des tâches de constitution de lexiques bilingues, mais en retrait sur des tâches de traduction automatique par fragments (Lardilleux et al., 2009). Nous n'avions émis jusqu'alors que des hypothèses pour expliquer ces résultats a priori contradictoires. Dans cet article, nous proposons une analyse fine du comportement de notre méthode afin de déterminer l'origine de ces différences, ainsi qu'une généralisation destinée à améliorer ses performances en traduction automatique par fragments.  Cet article est organisé de la façon suivante : la section 2 présente une vue d'ensemble de la méthode d'alignement  d'origine ; la section 3 présente des expériences mettant en évidence l'origine de ses faiblesses ; nous décrivons dans la section 4 une généralisation, et évaluons ses performances ; et la section 5 conclut ces travaux. Notre méthode d'alignement peut être vue comme une émulation des méthodes associatives, à la différence (majeure) près qu'elle ne se restreint pas à aligner des couples de mots (source, cible). Elle permet, en effet, de considérer des séquences de mots de taille variable, éventuellement discontinues, qui partagent strictement la même distribution (répartition) dans les phrases du corpus parallèle d'entrée, indépendamment de leur langue. Ces séquences constituent en fait un sous-ensemble des candidats de traduction qui obtiendraient un score maximal par des tests d'association statistiques. Le nombre de séquences de mots ayant exactement la même distribution étant réduit, nous ne recherchons pas ces séquences dans le corpus d'entrée même, mais dans des sous-corpus de celuici, l'idée étant que plus un sous-corpus est petit, plus les mots qu'il contient ont de chances de partager la même distribution, et que par conséquent plus le nombre de mots alignés dans ce sous-corpus est élevée.  Le coeur de la méthode consiste donc à extraire des alignements à partir de multiples sous-corpus indépendants  construits par échantillonnage. En pratique, nous privilégions les sous-corpus de petite taille car ils sont plus rapides à traiter et semblent donner de meilleurs résultats (Lardilleux, 2010). Pour chaque séquence de mots de même distribution dans un sous-corpus, deux alignements sont extraits : la séquence elle-même, d'une part, et son complémentaire, d'autre part. Le nombre de sous-corpus à traiter n'étant pas défini à l'avance, le processus est anytime , c'est-à-dire qu'il peut être interrompu à tout moment par l'utilisateur, ou selon des critères tels que le temps écoulé ou le taux de couverture du corpus de départ. Plus le nombre de sous-corpus traités est élevé, plus la couverture du corpus de départ est grande et plus les mesures d'association sont précises. Les alignements extraits sont collectés à partir de l'ensemble des sous-corpus traités, et sont évalués par divers scores (probabilité de traduction et poids lexicaux (Koehn et al., 2003)) à proportion du nombre de fois qu'ils ont été extraits. Le résultat est une table de traductions directement utilisable, par exemple, pour des tâches de traduction automatique.  L'algorithme d'extraction complet est schématisé dans le tableau 1.   La figure 1 illustre les principales étapes de l'algorithme sur un exemple d'alignement d'un texte trilingue. Dans  la suite de cet article consacré aux applications de l'alignement en traduction automatique, nous nous limiterons à une application bilingue de la méthode, bien que son caractère multilingue en constitue un atout majeur.  Entrée : un corpus multilingue, ici arabe-français-anglais.      Transformation en corpus  alingue (= monolingue) en concaténant les traductions d'une même phrase et distinguant les mots en fonction de leur langue d'origine. Sélection d'un sous-corpus aléatoire (ici, les trois premières lignes du corpus d'origine).     Indexation des mots (calcul des vecteurs de présence). Les mots ayant même distribution sont regroupés.      Chaque groupe de mots permet d'extraire deux alignements par phrase où il apparaît.  .. .     Décompte des alignements et rétablissement des limites entre langues.  .. .  Dans cette section, nous résumons les principaux résultats et conclusions de (Lardilleux, 2010). Nous avons évalué  cette méthode d'alignement sur deux tâches : en traduction automatique statistique par fragments et en constitution de lexiques bilingues. L'implémentation de notre méthode, Anymalign , est comparée à MGIZA++ (Gao & Vogel, 2008), l'implantation la plus récente des modèles IBM. Anymalign étant anytime, nous commençons en pratique par exécuter MGIZA++ avec ses paramètres par défaut (5 itérations de chacun des modèles IBM1, HMM, IBM3 et IBM4), mesurons son temps d'exécution, et exécutons Anymalign pendant la même durée. Les corpus parallèles utilisés dans les expériences sont principalement Europarl (Koehn, 2005) et des extraits du BTEC (Takezawa et al., 2002), distribués lors des campagnes d'évaluation de traduction automatique IWSLT (Fordyce, 2007). Les extraits du BTEC sont constitués de 20 000 à 40 000 couples de phrases courtes alignées (10 mots anglais en moyenne) et ceux d'Europarl de 100 000 couples de phrases longues (30 mots anglais).  Dans la tâche de traduction automatique statistique par fragments, nous comparons les scores obtenus par Moses  (Koehn et al., 2007) avec sa table de traductions par défaut, construite à partir des alignements de MGIZA++, et celle produite par Anymalign. En moyenne, Anymalign est en retrait de deux points BLEU (Papineni et al., 2002) sur l'ensemble des expériences que nous avons menées. Dans le meilleur des cas, nous avons obtenu un gain d'un point par rapport à MGIZA++ (BTEC, japonais-anglais) ; dans le pire, une perte de huit points (Europarl, finnois-anglais). Dans l'ensemble, les écarts sont plus prononcés sur Europarl que sur le BTEC.  Dans la tâche de constitution de lexiques bilingues, nous comparons les tables de traductions produites par les deux  aligneurs avec un lexique bilingue de référence . Dans un premier temps, ce lexique est filtré de façon qu'il ne contienne que des couples de traductions qui peuvent effectivement être extraits par les aligneurs à partir du corpus parallèle d'entrée. En pratique, un couple de traductions du lexique de référence est conservé s'il s'agit d'une sousséquence d'un couple de phrases du corpus parallèle. Nous définissons alors le score d'une table de traductions relativement à ce lexique de référence filtré comme la somme des probabilités de traduction source  cible des alignements de la table de traductions présents dans la référence, divisée par le nombre d'entrées distinctes dans la référence. Le résultat s'interprète comme un score de rappel, entre 0 et 1. En moyenne, Anymalign est meilleur de 7 % relativement à MGIZA++ sur l'ensemble des expériences que nous avons menées. Dans le meilleur des cas, nous avons obtenu un gain relatif de 70 % (Europarl, finnois-français) ; dans le pire une perte de 18 % (Europarl, suédois-finnois). Le genre de textes constituant le corpus ne semble pas avoir d'influence majeure sur ces scores.  En résumé, notre méthode est en retrait sur les tâches de traduction automatique par fragments, mais produit de  meilleurs alignements de mots, comme l'attestent les résultats de comparaison avec lexiques de référence, dont les entrées sont majoritairement des mots simples (le nombre moyen de mots par entrée est 1,2). Nous avons montré (Lardilleux et al., 2009) que cela est en fait principalement dû à la faible capacité de cette méthode à produire des alignements de n-grammes de mots avec n 2, comme l'illustre la figure 2. Le but de la section suivante est de mettre en évidence l'origine de ces différences.  0 %  20 % 40 % 60 % 80 % 100 %  1  2 3 4 5 6 7 Couverture des ngrammes  n  MGIZA++ Anymalign  Dans cette section, nous présentons des expériences montrant que deux causes principales sont à l'origine des  résultats apparemment contradictoires présentés ci-dessus : les différences de fréquences des mots qui composent les séquences à aligner (cause propre à la méthode), et les fréquences de mots utiles à ces tâches (cause propre à la tâche). Les expériences présentées ici sont réalisées sur un extrait d'environ 320 000 phrases d'Europarl, avec les couples de langues portugais-espagnol (cas extrêmes de langues proches dans nos expériences) et finnoisanglais (cas extrême de langues éloignées : le finnois est une langue ouralienne agglutinante, l'anglais une langue germanique d'influence romane isolante, ce qui s'exprime par une grande différence de taille des vocabulaires). Le tableau 2 présente le nombre de mots de chaque partie de nos corpus.  Nous faisons un pas supplémentaire en étudiant la taille des sous-corpus d'où les mots sont extraits en fonction de  la fréquence de ces mots. Étant donné un mot source m à aligner isolément, trois cas peuvent se produire : 1. dans un sous-corpus « trop petit », d'autres mots sources ont la même distribution que m . Il n'est donc pas possible d'aligner m isolément. 2. dans un sous-corpus de taille « idéale », aucun autre mot source n'a la même distribution que m , et au moins un mot cible a cette distribution. m peut donc être aligné isolément.  3. dans un sous-corpus « trop grand », aucun autre mot source n'a la même distribution que m  , mais aucun mot cible non plus. m ne peut donc pas être aligné du tout.  Il existe ainsi une plage de tailles de sous-corpus qui permet d'extraire un mot isolément. Cette plage dépend bien  entendu du mot à extraire et plus particulièrement de sa fréquence. Ces plages sont déterminées empiriquement en mesurant, pour chaque mot source d'un corpus parallèle, la taille moyenne des sous-corpus à partir de laquelle il peut être aligné isolément, ainsi que celle à partir de laquelle il ne peut plus être aligné du tout. Pour cela, nous commençons par tirer aléatoirement un sous-corpus d'une seule phrase contenant ce mot, testons si le mot peut y être aligné, puis recommençons ce test en augmentant le sous-corpus d'une nouvelle phrase tirée aléatoirement. Le processus s'arrête lorsque plus aucun mot cible n'a la même distribution que le mot source testé.  Chaque expérience produit deux nombres : la taille à partir de laquelle le mot peut être aligné isolément (passage  du cas 1 au cas 2 ci-dessus), et celle à partir de laquelle le mot ne peut plus être aligné du tout (du cas 2 au cas 3). Ce test est répété 1 000 fois pour chaque mot source, et nous effectuons la moyenne des mesures recueillies sur l'ensemble des 1 000 tirages. Les résultats sont présentés à la figure 3, par classes de mots de fréquences proches.  Taille moyenne des souscorpus  Nombre d'occurrences du mot pt    es  1  10 100 1 000 10 000 100 000  1  10 100 1 000 100 000  Taille moyenne des souscorpus  Nombre d'occurrences du mot fi    en  1  10 100 1 000 10 000 100 000  1  10 100 1 000 100 000  Ces graphiques nous permettent de faire deux remarques. D'abord, la plage des tailles « idéales » des sous-corpus,  autrement dit la largeur de la zone du milieu, varie grandement d'un couple de langues à l'autre. Notons que l'échelle logarithmique fait paraître cette plage plus étroite qu'elle ne l'est en réalité : le rapport moyen entre sa limite supérieure et sa limite inférieure est de 2,2 pour le couple espagnol-portugais et 1,2 pour le couple finnoisanglais. Cette différence de rapport s'explique aisément par les différences de morphologie des langues dans chacun de ces couples. Nous pouvons donc nous attendre à ce que l'alignement d'un mot donné par Anymalign nécessite le traitement de davantage de sous-corpus avec le couple finnois-anglais qu'avec le couple portugaisespagnol, puisqu'il est alors plus difficile de tirer aléatoirement un sous-corpus de la « bonne » taille.  La seconde remarque nous intéresse tout particulièrement dans le cadre de cet article : plus un mot est fréquent,  plus les sous-corpus à partir desquels il est extrait sont petits, et réciproquement. Les mots rares (partie gauche des graphiques) sont donc alignés à partir de grands sous-corpus, tandis que les mots fréquents (partie droite des graphiques) sont alignés à partir de petits sous-corpus, constitués par exemple de 5 à 9 phrases pour la virgule. Ces résultats valident nos premières hypothèses : s'il est difficile de tirer un sous-corpus dans lequel deux mots source de fréquences différentes partagent la même distribution, c'est avant tout parce que ces mots ne peuvent pas être alignés à partir du même sous-corpus. Pour aligner des mots de fréquences différentes, il est nécessaire de les extraire à partir de sous-corpus de tailles différentes. Nous proposerons une alternative dans la section suivante.  La seconde explication des différences de résultats d'Anymalign sur les deux tâches sur lesquelles il a été évalué  provient en fait de la tâche elle-même, ou pour être plus précis du couple (aligneur, tâche).  Notre méthode et les modèles IBM reposent sur des intuitions opposées : la première tire parti de la rareté des  mots pour les aligner (on réduit artificiellement et temporairement la fréquence de tous les mots en se plaçant dans un sous-corpus), tandis que les seconds sont estimés à partir des observations mesurées sur l'ensemble du corpus. En conséquence, Anymalign aligne mieux les mots rares, tandis que MGIZA++ aligne mieux les mots fréquents, comme l'illustre la figure 4.  0 %  20 % 40 % 60 % 80 % 100 %  1  10 100 1 000 100 000 Score  Nombre d'occurrences des mots  pt-es  Anymalign (60 %)  MGIZA++ (53 %)  0 %  20 % 40 % 60 % 80 % 100 %  1  10 100 1 000 100 000 Score  Nombre d'occurrences des mots  fi-en  Anymalign (36 %)  MGIZA++ (26 %)  Dans cette section, nous présentons une généralisation de la méthode destinée à améliorer ses performances en  traduction automatique statistique par fragments. En conformité avec la méthode d'origine, nous travaillerons  toujours sur les formes surfaciques des mots et sans ressource autre que le corpus d'entrée (traitement endogène).  Notre but est d'extraire davantage d'alignements de n-grammes (chaînes de mots) avec n 2 (cf. figure 2), tout en contournant le problème de l'extraction des mots de fréquences différentes (section 3.1).  Nous introduisons le traitement à un grain variable en indexant des n-grammes plutôt que des mots. Nous ne  chercherons pas à effectuer une segmentation particulière des phrases, par exemple en chunks, dont Vergne (2009) a montré qu'ils pouvaient être déterminés de façon endogène, mais traiterons plus simplement tous les n-grammes de mots se chevauchant. Considérons le (sous-)corpus d'entrée alingue suivant, constitué de trois phrases :  L'indexation sur l'ensemble des n-grammes de ce corpus, avant recensement des groupes de même distribution  servant de base à l'extraction des alignements, produit le résultat suivant : Dans l'étape suivante, le recensement des groupes de même distribution, nous introduisons un changement majeur : si des n-grammes de même distribution se chevauchent, le groupe de mots résultant est constitué de l'union de ces n-grammes. Par exemple, les bigrammes de même distribution bd et de formeront le groupe de mots bde. Autrement dit, les groupes ne sont plus constitués de mots de même distribution, mais de mots issus de n-grammes de même distribution. Un même mot peut désormais apparaître dans plusieurs groupes, ce qui n'était pas le cas dans la méthode d'origine.  Ce changement soulève un problème qui ne pouvait pas se produire avec la méthode d'origine : des n-grammes  peuvent masquer des (n1)-grammes, et ce récursivement. L'unigramme b est par exemple masqué par le bigramme de même distribution ab, car l'union de b et ab donne ab, et b ne peut plus être aligné isolément. Il est donc nécessaire de traiter l'introduction de chaque longueur de n-gramme de façon spécifique.  Nous avons testé trois stratégies :  1. traiter séparément les n-grammes en fonction de leur longueur. Ainsi, les groupes de mots ne sont construits qu'à partir de n-grammes de même longueur en source et en cible. Cela est bien entendu d'efficacité limitée sur des couples de langues tels que finnois-anglais : il serait préférable d'autoriser l'extraction d'un seul mot d'une langue agglutinante avec plusieurs mots d'une langue isolante. 2. permettre le mélange de toutes les longueurs de n-grammes, mais en ajoutant progressivement chaque longueur. L'ensemble initial ne contient que des unigrammes (méthode d'origine). Dans un deuxième temps, nous ajoutons les bigrammes et recréons tous les groupes de mots : certains sont identiques (les décomptes des alignements correspondants sont renforcés), d'autres sont nouveaux, d'autres enfin sont masqués mais cela n'a pas d'importance car ils ont déjà été extraits à partir des unigrammes. On ajoute ensuite les trigrammes, etc. Les alignements sont extraits à chaque fois que des n-grammes sont ajoutés. 3. forcer l'alignement de n-grammes de longueurs différentes, à contrepied de la première stratégie, en traitant séquentiellement tous les couples de longueurs (source, cible) possibles (produit cartésien). Cela permet l'alignement de n-grammes de longueurs très différentes en source et en cible, voire trop : puisque nous n'avons recours à aucune connaissance extérieure, Anymalign ne sait pas a priori quelle langue est traitée, et rien ne l'empêche par exemple de vouloir aligner des unigrammes en anglais avec de longs n-grammes en finnois, quand bien même il est peu probable que le moindre alignement puisse être produit à partir d'une telle configuration. En outre, la complexité de cette approche est bien plus importante que celle des deux précédentes, et ne passe pas à l'échelle lorsque nous traitons plus de deux langues simultanément.  Pour comparer ces trois stratégies, nous préparons un ensemble de 100 000 sous-corpus aléatoires issus d'Europarl  (français-anglais) et en extrayons les alignements selon chacune de ces stratégies. Nous réalisons l'expérience pour des longueurs maximales de n-grammes allant de 1 à 5. Les tables de traductions (3 × 5 = 15 tables au total), obtenues à partir de ce même ensemble de sous-corpus, sont évaluées sur les mêmes tâches que précédemment : en traduction automatique statistique par fragments (les critères d'évaluation sont BLEU et TER (Snover et al., 2006)) et en constitution de lexiques bilingues. Les résultats sont présentés dans le tableau 3.  Comme il était attendu, plus la longueur maximale des n-grammes indexés est grande, plus le nombre d'entrées  dans la table de traductions et la longueur de ces entrées sont également élevés, car les alignements produits avec un n max. donné contiennent ceux produits avec un n max. inférieur (inclusion des tables). Les scores en constitution de lexiques augmentent de façon négligeable lorsque n max. augmente avec les deux premières approches, mais se dégradent de façon significative avec la troisième. Le gain en traduction automatique est significatif avec les trois approches. La seconde semble néanmoins fournir des résultats très légèrement meilleurs selon les trois critères d'évaluation. Son temps d'exécution est légèrement supérieur à celui de la première (au pire deux fois plus lent avec les 5-grammes), mais bien en-deçà de celui de la troisième (de l'ordre de l'heure à celui de la journée avec les 5-grammes).  La stratégie que nous utiliserons par la suite sera donc la deuxième. Elle constitue sur le fond un bon compromis  entre les deux autres. La figure 5 présente le détail de la colonne « Nombre d'entrées » du tableau 3 pour cette deuxième stratégie, et est à confronter avec la figure 2. Dans l'ensemble, l'ajout d'une longueur de n-grammes indexés, autrement dit le passage d'une courbe à celle immédiatement au-dessus, augmente considérablement la quantité de l'ensemble des n-grammes produits (y compris, de façon marginale, les n-grammes de taille inférieure, mais cela n'est dû qu'à l'extraction des complémentaires des groupes de mots). Le cas le plus significatif est celui de l'indexation des bigrammes (n max. = 2), qui fait exploser la quantité de bigrammes en sortie, et dans une moindre mesure de toutes les tailles de n-grammes supérieures. Le phénomène se produit également en indexant des n-grammes encore plus longs, mais cela est de moins en moins significatif à mesure que n max. augmente. Le graphique semble montrer qu'il n'est pas utile d'indexer des n-grammes de plus de 3 ou 4 mots, car cela se révèle peu productif. Les n-grammes qui nous intéressent le plus sont de toute façon ceux de longueur 1 à 3, parce que ce sont généralement les plus utiles en traduction automatique par fragments.  Nous comparons à présent notre méthode généralisée (indexation des n-grammes + constitution des groupes de  mots selon la deuxième stratégie testée) à MGIZA++ sur des tâches de traduction automatique statistique par  0  20 000 40 000 60 000 80 000 100 000 120 000 140 000  1  2 3 4 5 6 7 Nombre d'entrées source  Longueur des entrées source (en mots)  n max. = 5 n max. = 4 n max. = 3 n max. = 2 n max. = 1  
