Modéliser les préférences est incontournable dans de nombreux problèmes de la vie courante,  que ce soit pour la prise de décision individuelle ou collective (Arora et Allenby, 1999), les interactions stratégiques entre agents (Brainov, 2000) ou la théorie des jeux (Hausman, 2000). Un aperçu des travaux sur les préférences en Intelligence Artificielle est donné par Kaci (2011).  Une préférence est généralement définie comme un ordre donné par un agent sur différentes  options. Les options dépendent du domaine : elles peuvent être des vols d'avions, des voitures, des horaires et lieux de rendez-vous, etc. L'ordonnancement des préférences peut être total (strict ou non), rendant chaque paire d'options comparable, ou partiel, quand certaines options ne peuvent pas être comparées par un agent donné. Parmi ces options, certaines sont acceptables pour l'agent, c'est-à-dire qu'il est prêt à agir pour les réaliser, et d'autres ne le sont pas. Parmi les options acceptables, l'agent en préfère généralement certaines par rapport aux autres.  Il est important de différencier les notions de préférence et d'opinion. Alors que les opinions  sont un point de vue, un sentiment ou un jugement qu'un agent peut avoir sur un objet ou une personne, les préférences, comme nous les avons définies, impliquent un ordre de la part de l'agent et sont ainsi relationnelles et comparatives. Les opinions concernent donc un jugement absolu sur des objets ou des personnes (positif, négatif ou neutre), tandis que les préférences concernent un jugement relatif sur des options, les préférant, ou non, aux autres. Par exemple, Ce film n'est pas mauvais exprime une opinion directe positive sur un film mais nous ne savons pas si ce film est le « plus » préféré. J'aimerais aller au cinéma. Allons voir Madagascar 2 exprime deux préférences, l'une dépendant de l'autre. La première est que l'auteur préfère aller au cinéma par rapport aux autres actions alternatives ; la seconde est qu'étant donnée cette préférence, il préfère aller voir Madagascar 2 plutôt que les autres films possibles. Traiter les préférences n'est pas aisé. Tout d'abord, il est nécessaire de connaître au moins partiellement l'ensemble des options sur lesquelles portent les préférences. Ensuite, il faut pouvoir définir un ordre a priori sur les options acceptables mais ce n'est pas toujours trivial. De plus, donner un ordre entre deux options (appareils photos) peut être difficile à cause de la nécessité de tenir compte des compromis et des interdépendances entre les différents critères (durée de vie de la batterie, poids, etc.). Ensuite, les utilisateurs manquent souvent d'informations complètes sur leurs préférences initiales qui tendent à changer au cours du temps. En effet, les utilisateurs peuvent apprendre du domaine, des préférences des autres et même de leurs propres préférences au cours du processus de prise de décision. Plusieurs méthodes ont été proposées en Intelligence Artificielle pour éliciter les préférences (Chen et Pu, 2004). Cependant, à notre connaissance, aucun travail ne montre comment les préférences pourraient être déterminées à partir de dialogues en utilisant une approche linguistique.  L'approche que nous proposons a pour but d'étudier le rôle du discours pour extraire et raisonner  sur les préférences. Notre approche comporte trois étapes : 1. Extraire les options. L'objectif est de repérer, au sein de chaque segment de discours, les expressions linguistiques sur lesquelles portent les préférences d'un agent. 2. Identifier les éventuelles dépendances entre les options extraites à l'étape 1 en utilisant un en- semble d'opérateurs spécifiques. Ces dépendances nous permettent d'inférer les préférences de l'agent et d'identifier, étant données deux options, leur ordonnancement. 3. Proposer une description formelle des préférences de chaque agent. Nous étudions comment les relations de discours permettent de suivre l'évolution des préférences au cours du dialogue. Cette description se fait en utilisant une représentation compacte des préférences, les CP-nets (Conditional Preference Networks) (Boutilier et al., 2004). Une description détaillée de ces étapes est donnée dans (Cadilhac et al., 2011). Le travail présenté ici est un premier pas vers l'automatisation de ce processus en se focalisant sur la première étape. Nous analysons comment les préférences sont exprimées linguistiquement, c'est-à-dire comment les options et les dépendances sont lexicalisées. Nous montrons comment les options peuvent être extraites automatiquement grâce à un algorithme d'apprentissage supervisé utilisant des traits locaux et discursifs et nous évaluons la fiabilité de notre approche.  Nos données viennent de deux corpus. Le premier corpus,  , est composé de 35 dialogues choisis au hasard dans le corpus Verbmobil déjà existant (Wahlster, 2000), dans lequel deux agents discutent pour fixer la date et le lieu d'un rendez-vous. Il a été utilisé pour créer la liste des traits d'apprentissage. Le second corpus, , a été utilisé pour évaluer à quel point notre méthode est dépendante du domaine. Il a été construit à partir de plusieurs ressources d'apprentissage de l'anglais disponibles sur Internet (par exemple, www.bbc.co.uk/worldservice/learningenglish). Il contient 21 dialogues choisis au hasard, dans lesquels un agent, le client, appelle un service pour réserver une chambre, un vol d'avion, un taxi, etc. En voici un exemple typique : Afin d'analyser comment les options et les dépendances sont exprimées linguistiquement dans les dialogues de négociation, nous avons réalisé une annotation à deux niveaux : d'abord, au niveau du discours, séparant le texte en segments (les  ci-dessus) liés entre eux par des relations rhétoriques ; puis, au niveau des préférences exprimées dans chaque segment. Les dialogues sont structurés par des tours de parole qui permettent à chaque agent de participer au dialogue. Un agent peut, par exemple, répondre aux questions d'autres agents, poser ses propres questions, etc. Dans chacun de ces tours, les agents s'engagent sur leurs croyances et préférences. En général, les modèles formels de dialogue n'explicitent pas le lien entre les énoncés et les préférences (voir, par exemple, (Ginzburg, 2012)). Il est alors nécessaire d'avoir, d'une part, une méthode qui permet une extraction partielle des préférences et de leurs dépendances et, d'autre part, une méthode qui permet d'exploiter cette description partielle afin d'identifier l'ensemble des options préférées. Notre approche exploite la structure du discours selon la Théorie des Représentations Segmentées du Discours, SDRT (Asher et Lascarides, 2003) où des unités discursives (UD) sont liées entre elles par des relations rhétoriques telles que Paire Question-Réponse (QAP), Plan-Correction (P-Corr), etc. Bien que le problème d'extraction de la structure du discours reste redoutable, on peut approximer ces relations relativement bien en utilisant des caractéristiques qui peuvent facilement être obtenues automatiquement (par exemple, Baldridge et Lascarides (2005b) réalisent un F-score d'environ 69,2%). Notre étude montre ici l'importance des caractéristiques du discours pour l'extraction de préférences, en supposant que celles-ci sont données par un oracle. Pour , nous avons utilisé l'annotation de Baldridge et Lascarides (2005a). Pour , l'annotation a été faite par consensus en utilisant le même ensemble de relations rhétoriques qui a été utilisé pour annoter . Notre objectif est d'analyser comment les préférences sont linguistiquement exprimées dans des segments de dialogues. Deux étapes sont nécessaires : (i) identifier l'ensemble O des options (des termes) sur lesquelles portent les préférences d'un agent, (ii) identifier les éventuelles dépendances entre les éléments de O en utilisant un ensemble d'opérateurs spécifiques, c'est-à-dire identifier les préférences de l'agent parmi les options énoncées. Par exemple, dans Rencontrons nous lundi ou mardi, nous avons O = {lundi, mardi} où les options sont linguistiquement reliées par la conjonction ou qui signifie que l'agent est prêt à réaliser une de ces options, les préférant de manière égale.  Dans une UD, les préférences peuvent être exprimées de différentes manières. Elles peuvent être  atomiques, par exemple, « Je veux X » ou « Je préfère X » où « X » est une option acceptable. Cette option peut être un groupe nominal (lundi), un groupe prépositionnel (à mon bureau) ou un groupe verbal (se rencontrer). Les préférences peuvent aussi être exprimées dans des constructions comparatives et/ou superlatives (un vol moins cher). Elles sont aussi exprimées d'une manière indirecte en utilisant des questions. Bien que toutes les questions n'impliquent pas que l'auteur s'engage sur une préférence, dans beaucoup de cas elles le font. C'est-à-dire si un agent demande Pouvons-nous nous rencontrer la semaine prochaine ?, il implique une préférence pour se rencontrer. Des expressions de sentiment ou de politesse peuvent aussi être utilisées pour introduire indirectement des préférences. Dans , le segment Economique, s'il vous plaît indique que l'agent préfère être dans la classe économique. Les expressions de préférences peuvent aussi être complexes, exprimant des négations, conjonctions, disjonctions, ou dépendances. Nous associons à chacune de ces expressions des opérateurs spécifiques (non-booléens), que nous désignons respectivement par not, &, or et . Les réalisations linguistiques de ces opérateurs nous seront utiles dans la phase d'extractions des options (voir section 3). Les négations indiquent ce que l'agent ne préfère pas, c'est-à-dire que l'option exprimée est non-préférée. La négation peut être explicite, comme dans Je ne veux pas qu'on se rencontre vendredi, ou inférée à partir du contexte, comme dans Je suis occupé mardi. Un exemple de conjonction entre préférences est Pourrais-je avoir un petit déjeuner et un repas vé- gétarien ? où l'agent exprime deux préférences qu'il souhaite satisfaire et il aimerait en avoir au moins une des deux s'il ne peut pas les avoir toutes. La sémantique des disjonctions est une modalité de choix libre. Par exemple, Je suis libre lundi ou mardi signifie que lundi ou mardi est un jour possible pour se rencontrer et que l'agent est indifférent entre les deux. Finalement, certaines UD expriment des engagements sur des préférences dépendantes. Par exemple, dans la phrase Pourquoi pas lundi, dans l'après-midi ?, il y a deux préférences : une pour le jour lundi et, étant donné la préférence pour lundi, une pour la période de l'après-midi (au moins pour une des interprétations syntaxiques du segment).  Pour chaque UD, nous avons demandé à deux annotateurs d'identifier comment les options sont  exprimées et ensuite d'indiquer comment les préférences sur ces options sont liées entre elles en utilisant les opérateurs spécifiques not, &, or et . Nous donnons ci-dessous un exemple de comment certains segments sont annotés. < o >_i indique que o est l'option numéro i dans le segment, et le symbole // est utilisé pour séparer les deux niveaux d'annotation. Une description détaillée de ce schéma d'annotation est donnée dans (Cadilhac et al., 2012). En utilisant le coefficient Kappa de Cohen, nous avons calculé deux taux d'accord interannotateurs sur l'identification des options. L'un est basé sur un accord exact où deux annotations (c'est-à-dire, les unités de texte correspondant à une option) doivent correspondre exactement pour être considérées comme correctes. L'autre est basé sur un accord souple où deux annotations correspondent s'il y a un chevauchement entre leurs unités de texte (comme pour 2 heures et environ 2 heures). Nous avons obtenu un accord exact de 0,66 et un accord souple de 0,85. L'accord souple étant bon pour , nous avons décidé d'annoter par consensus.  Le gold standard pour les deux corpus a été construit après discussion des cas de désaccord.  Nous avons observé quatre cas. (1) Le premier concerne la redondance des préférences et nous avons décidé de ne pas garder les préférences redondantes dans le gold standard. En effet, les agents répètent souvent des préférences qui ont déjà été établies, comme dans l'exemple suivant,  A : jeudi, vendredi et samedi je ne suis pas là.  A : Ces 3 jours ne sont pas possibles pour moi, où nous avons Resultat( ,  ). (2) Le second cas de désaccord vient des préférences qui sont exprimées par des anaphores. Nous avons décidé de les annoter dans le gold standard car elles sont souvent utilisées dans les corpus pour introduire ou préciser des préférences. Comme dans l'exemple suivant,  A : A 2 heures, le 17 ?  B : C'est parfait, où nous avons Q-Elab( ,  ). (3) Le troisième cas de désaccord concerne l'explication de préférence. Dans le gold standard, nous avons choisi de ne pas annoter les expressions qui sont utilisées pour expliquer des préférences déjà établies. Comme dans l'exemple suivant,  A : pas lundi,  A : j'ai un cours de 9 à 12 heures, où nous avons Explication( ,  ). (4) Finalement, le dernier cas de désaccord provient des préférences qui ne sont pas directement liées à l'action de fixer une date pour le rendez-vous mais plutôt à d'autres actions comme déjeuner ensemble. Même si ces préférences ont souvent été omises par les annotateurs, nous avons décidé de les garder.  Le problème de l'extraction est de décider si un terme est une option ou non. L'objectif est donc  de classer les termes en deux catégories : Option et Non-option indiquant respectivement que le terme exprime une option faisant l'objet des préférences, ou non. Nous rappelons que les options peuvent être des groupes nominaux, groupes prépositionnels ou groupes verbaux. Nous devons donc choisir quels groupes de mots doivent être classés. Dans les données, les agents négocient pour se mettre d'accord sur une action : se rencontrer un jour donné, réserver un certain vol, etc. Nous sommes généralement informés de ces actions dans les groupes verbaux. Cependant, les termes correspondants aux options de préférences sont plutôt contenus dans les groupes nominaux (GN). Par exemple, pour fixer un rendez-vous, la négociation porte sur les jours et les heures. Pour réserver un hôtel, la négociation porte sur des options plus spécifiques comme une chambre double. Il semble donc approprié d'extraire les GN. Pour les classer dans une des deux classes, nous utilisons deux genres de traits (tous binaires) : les traits locaux et les traits discursifs. Le classifieur est basé sur les Machines à Vecteurs de Support.  La portée des traits locaux est soit l'unité qui doit être classée, c'est-à-dire le GN, soit le segment  qui contient le GN. Certains de ces traits reposent sur une ontologie qui modélise un calendrier (date, temps, etc.) inspirée de deux ontologies de haut niveau, SUMO et COSMO. Nous avons cinq traits au niveau du GN qui testent si le GN contient : le label d'un concept appartenant à l'ontologie, un comparatif, un superlatif, une disjonction ou une conjonction. Nous avons dix traits au niveau du segment : (1) le voisin gauche du GN correspond à un label d'un concept de l'ontologie. Puisque la liste des termes associés à chaque concept de notre ontologie est courte, ce trait aide à retrouver des lexicalisations supplémentaires ; (2) le segment contient une disjonction ou une conjonction ; (3) le GN est dans la portée d'une négation, d'un modal ou d'un verbe d'action du domaine (se rencontrer, réserver). La portée des négations et des modaux est résolue de manière simplifiée en utilisant l'arbre syntaxique de l'UD ; (4) le segment contient un mot d'opinion (bon, mauvais, OK, etc.), un mot de politesse ou un mot qui introduit des préférences (préférer, favori, choix, trop, etc.) ; (5) le segment contient une référence à l'autre agent. Ce trait est un indice pour la classe Non-option. Dans des segments comme Tu as dit que tu n'es pas libre mardi matin ou mercredi après-midi ?, l'agent n'apporte pas de nouvelle information sur les préférences mais répète seulement ce qui a déjà été établi par l'autre agent. Nous avons neuf traits au niveau du discours : (1) les relations rhétoriques qui lient l'UD courante à l'UD précédente et à l'UD suivante impliquent des préférences. Nous avons remarqué que certaines relations de discours peuvent aider à repérer des segments qui contiennent, ou non, des préférences. Nous dissocions les relations de discours en trois catégories : (a) celles qui impliquent « généralement » une Non-option comme Explication, Commentaire, Résumé, (b) celles qui impliquent « peut-être » une Option comme Elaboration, Continuation, Correction et  T  1 - Résultats (pourcentages) pour les trois évaluations.  (c) celles qui impliquent « généralement » une Option. Dans  , 86 % des relations de discours sont de la catégorie (a) alors que 14 % des relations annotées appartiennent à la catégorie (b). Nous observons la même tendance pour . Il n'y a pas d'instances de la catégorie (c) dans les relations de discours utilisées lors de l'annotation des deux corpus. Ainsi, nous avons six traits : trois pour tester si la relation entre l'UD courante et l'UD précédente appartient, ou non, à une des trois catégories, et trois autre pour la relation entre l'UD courante et l'UD suivante ; (2) l'UD courante ou l'UD précédente est une question. Dans nos corpus, les formes interrogatives ne sont pas toujours suivies par une marque de question. Pour détecter les questions, nous utilisons donc les relations de discours spécifiques, comme QAP, Q-Elab ; (3) le GN apparaît au moins deux fois dans le dialogue.  Plusieurs évaluations sont réalisées pour évaluer la validité de notre méthode d'extraction. La  première est effectuée sur les 35 dialogues de (C ) pour un total de 1272 UD. Nous le séparons au hasard en un corpus d'entraînement constitué de 25 dialogues, soit 2374 GN, et un corpus de test de 10 dialogues, soit 700 GN. Dans la seconde (C ), le classifieur est entraîné sur 15 dialogues de , soit 837 GN et testé sur 6 dialogues pris au hasard, soit 312 GN. Les 21 dialogues de ce deuxième corpus comportent au total 348 UD. Pour la troisième, le classifieur est évalué en utilisant pour l'entraînement (les 35 dialogues) et pour le test (les 21 dialogues) (C + C ). Cette dernière évaluation, plutôt inhabituelle, est supposée aider à déterminer si notre méthode permet l'entrainement sur un corpus plus grand et disponible et le test sur un corpus plus petit et parfois d'un domaine différent. Pour toutes ces évaluations, nous utilisons le logiciel SVM-light (http ://svmlight.joachims.org).  Nous comparons les résultats du classifieur avec ceux de trois baselines : la première classe  tous les GN dans la catégorie Option, la seconde classe dans la catégorie Option tous les GN qui contiennent un concept appartenant à l'ontologie, et la troisième baseline est une version simplifiée de notre classifieur qui utilise seulement un sous-ensemble de nos traits (nous enlevons les traits basés sur l'ontologie ainsi que tous les traits basés sur les relations de discours). La table 1 présente les résultats, sous forme de précision (P), rappel (R) et F-mesure (F). Elle montre d'abord les résultats des baselines. Nous développons ensuite notre modèle en considérant les traits locaux au niveau du GN, puis nous ajoutons les traits locaux au niveau du segment et ajoutons progressivement les traits au niveau du discours (l'ajout des traits est symbolisé par le signe +). La dernière ligne présente le résultat final, obtenu en utilisant tous les traits. Les résultats dans la table 1 montrent que, parmi les trois baselines, la seconde donne les meilleurs résultats pour . Ceci était attendu puisque l'ontologie a été construite pour ces données. Cependant, cette baseline ne permet pas de retrouver toutes les options car certains GN qui contiennent des concepts de l'ontologie ne sont pas des options (ce sont des répétitions, des commentaires, etc.) et bien sûr toutes les options exprimées par les agents ne sont pas couvertes par les concepts de l'ontologie. Pour , l'ontologie dégrade le rappel par rapport à la première baseline, puisqu'il y a un faible recouvrement entre les concepts dans l'ontologie et ceux dans le corpus. Il en va de même pour la troisième évaluation (C + C ). Cependant, ce n'est pas un problème critique puisque des ontologies adaptées sont également disponibles pour le domaine touristique. Dans tous les cas, la troisième baseline donne des résultats assez stables, toujours meilleurs que ceux de la première baseline et, dans les deuxième et troisième évaluations (pour lesquelles nous n'avons pas utilisé d'ontologie adaptée), ces résultats sont également meilleurs que ceux de la deuxième baseline. Le classifieur donne un meilleur rappel pour la troisième évaluation que pour la deuxième. Cela peut montrer un problème de rareté des données lors de l'entrainement uniquement sur (configuration (C )).  Les évaluations montrent que notre méthode a une tendance similaire sur  et . Nous voyons que les traits locaux au niveau du GN sont pertinents pour obtenir une bonne précision. Les traits au niveau du segment et les traits discursifs améliorent le rappel et la F-mesure dans les trois configurations. L'amélioration est mieux marquée dans les deuxième et troisième évaluations. Peut-être parce que l'ontologie, moins bien adaptée pour ces évaluations, a moins d'impact sur les performances. Finalement, pour , nous obtenons une F-mesure de 86,8 %, i.e. presque 20 % au-dessus de la troisième baseline (classifieur simplifié) et plus de 10 % au-dessus de la deuxième baseline (basée sur l'ontologie). Pour , nous obtenons une F-mesure de 64,8 %, i.e. plus de 10 % au dessus du classifieur simplifié. Pour la troisième évaluation, les résultats ne montrent pas d'amélioration par rapport aux baselines. C'est probablement dû à l'influence de l'ontologie qui adapte mieux les vecteurs de support au corpus d'entrainement ( ), les rendant moins pertinents pour le corpus de test. En désactivant les deux traits basés sur l'ontologie, nous obtenons 50,2 % de précision, 62,9 % de rappel et 55,8 % de F-mesure, soit une amélioration par rapport aux baselines.  Pour les traits discursifs, nous remarquons que, pour  , les relations rhétoriques entre l'UD courante et l'UD précédente apportent plus d'amélioration que les autres informations discursives. Cela peut s'expliquer par la nature du corpus, où le contexte (exprimé dans les tours de dialogues précédents) est important. Pour , le trait qui teste si l'UD courante ou l'UD précédente sont des questions apporte la meilleure amélioration des performances car ce corpus contient principalement des paires question-réponse. Pour la troisième évaluation, les traits discursifs n'apportent pas d'amélioration importante par rapport aux baselines. C'est peut-être causé par l'incapacité des informations discursives à compenser les différences entre les données d'entrainement et de test : en effet, en principe, il y a plus d'instances des traits locaux (au niveau du GN et du segment) associées à des cas positifs, que d'instances des traits discursifs associées à des cas positifs. Et quand le classifieur est entrainé sur des traits extraits d'un domaine de corpus et testé sur un autre domaine, le poids des traits discursifs peut ne pas suffire à compenser les autres traits, locaux.  Dans ces trois configurations, le trait testant la présence d'un GN au moins deux fois dans le  dialogue apporte une amélioration conséquente par rapport aux autres. C'était plutôt attendu puisqu'en principe la fréquence d'un GN apporte de l'information sur le sujet principal, et cela a du sens, puisque les agents ont tendance à exprimer des préférences sur le sujet de la discussion.  Nous avons présenté une méthode linguistique pour l'extraction des expressions de préférence  dans des dialogues de négociation. Nous avons d'abord proposé un schéma d'annotation pour étudier comment les préférences sont exprimées dans des dialogues dans deux domaines différents. Nous avons ensuite proposé une méthode d'apprentissage qui extrait les expressions de préférence des dialogues en utilisant une combinaison de traits locaux et discursifs. Les résultats montrent que la structure discursive couplée avec une ontologie est utile pour extraire les expressions de préférence de manière efficace. Dans nos futurs travaux, nous voulons évaluer la méthode sur des corpus plus grands et variés, pour vérifier sa pertinence et sa robustesse sur différents domaines de conversation et registres de discours. Pour le moment, la méthode de classification traite uniquement des GN. Ceci est justifié pour les corpus sur lesquels nous avons travaillé mais nous devons étudier s'il est toujours pertinent d'utiliser uniquement des GN pour d'autres corpus et, si nécessaire, étendre la méthode à d'autres types de syntagmes. Ce travail d'extraction des expressions de préférence est, nous le rappelons, la première étape d'un processus plus complexe d'élicitation des préférences (Cadilhac et al., 2011) qui sera complètement automatisé afin de l'appliquer à des cas pratiques de négociation et marchandage.  Les auteurs remercient le projet STAC ERC Grant n269427.   
