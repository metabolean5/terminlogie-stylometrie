L'extraction d'information subjective (Pang et Lee, 2008) est depuis une dizaine d'années   un vaste domaine d'applications en croissance régulière. Malgré quelques travaux (par  exemple Vernier, 2009 ; Béchet et al., 2008) le savoir-faire linguistique y est peu sollicité.  La subjectivité a pourtant fait l'objet de nombreux travaux linguistiques, dans di#érents  courants théoriques - linguistique de l'énonciation, analyse de discours, sémantique des  textes. La textométrie, aux con!ns de la linguistique générale et du TAL, propose par  ailleurs   une   archive   intéressante   de   travaux   sur   corpus   susceptibles   d'intéresser   les  applications d'analyse des sentiments  (AS). On songe, dans le discours politique, aux  travaux de (Salem, 1993), dans les sondages d'opinion, à (Lebart et Salem, 1988) ou dans  la littérature, à (Brunet, 2009).  On souhaiterait ici susciter une rencontre entre d'une part le TAL ingénierique et ses   applications   et,   d'autre   part,   la   textométrie,   à   partir   des   constats   suivants :   (1)  l'évaluation des méthodes en TAL repose sur un ensemble restreint de mesures (telles que  précision, rappel, f-mesure) qui ont pour but de véri!er la qualité des méthodes plus que  de   valider   des   hypothèses   et   des   méthodologies   linguistiques.   Leurs   résultats   ne  nécessitent pas d'interprétation pour être valides ; (2) la textométrie relève, au contraire,  d'une   tradition   descriptive.   Elle   se   focalise   sur   l'interprétation   des   résultats   de  traitements   statistiques,   davantage   que   sur   l'amélioration   desdits   traitements.   À   la  di#érence du TAL, l'évaluation n'est pas un enjeu en textométrie .   Notre projet repose sur l'hypothèse que la textométrie, discipline descriptive, est à même   d'apporter des solutions méthodologiques pour les applications généralement dévolues  au TAL. Nous tenterons d'évaluer l'apport potentiel de la conjonction d'une analyse  textométrique et de méthodes d'apprentissage pour une application d'AS.  La   catégorisation   des   textes,   qu'elle   soit   bipolaire   (positif/négatif)   ou   multiclasse   (mauvais/bon/excellent),   est   l'application   principale   en   extraction   d'information  subjective. Elle peut être réalisée au moyen d'algorithmes ad hoc (Turney, 2002 ; Snyder  et Barzilay, 2007) ou des méthodes d'apprentissage comme Naive Bayes, Support Vector  Machines, etc. (Pang  et al., 2002 ; Mihalcea et Liu, 2006), en utilisant des attributs  di#érents pour caractériser les documents. Même si perdurent d'autres méthodes - ayant  principalement recours à l'utilisation de ressources lexicales, construites (Kim et Hovy,  2004)  ou   automatiquement   acquises   (Turney,  2002 ;   Rilo#  et   al.,   2003),   avec   la  banalisation   des   corpus   annotés,   les   méthodes   de   catégorisation   basées   sur  l'apprentissage   supervisé   sont   de   plus   en   plus   utilisées.   Elles   utilisent   diverses  caractéristiques textuelles : (i) tous les mots du texte (sac de mots, unigrammes ou ngrammes)  (Pang  et al., 2002 ; Dave  et al.  2003) ; (ii) la présence ou l'absence d'un  ensemble   de   mots  déterminés ;  (iii)  l'emplacement   de   certains   mots   (Kim   et   Hovy,  2006) ;   (iv)   certaines   parties   du   discours   seules :   adjectifs   (Kamps   et   Marx,   2002),  collocations adverbe-adjectif (Turney,  2002) ; substantifs ;  en!n (v)  les  dépendances  syntaxiques (Nakagawa et al., 2010 ; Wi et al., 2009 ; Wiegand et Klakow, 2010). Nous  nous inscrivons donc pleinement dans cette démarche  en proposant des critères  de  classi!cation issus d'analyses textométriques pour servir de base aux divers algorithmes  d'apprentissage supervisé. Le corpus est constitué de 300 textes courts réunis par SAMESTORY (http://www.samestory.com),   un   service   d'agrégation   d'ego-documents.   Il   s'agit,   en   l'occurrence,   de  témoignages et récits d'histoires vécues postés par les internautes sur di#érents forums  de discussion (aufeminin.com, doctissimo.fr, etc.). Les catégorisations sont multicritères :  thématiques, tonalité, conseil  vs  demande, sexe de l'émetteur, situation familiale, etc.  Nous traitons, dans des textes portant sur la santé, la tonalité « gai/triste ». De prime  abord, elle s'apparente à une analyse thymique, mais il s'agit de catégories complexes où  les phénomènes discursifs (ex : structure du récit) interviennent dans la classi!cation  autant que l'expression linguistique des sentiments. Ainsi, notre tâche est de modéliser  l'art de témoigner d'une histoire vécue.   L'annotation tonale du corpus a été e#ectuée par SAMESTORY. Nous en avons analysé   un échantillon pour en déduire la stratégie d'annotation de façon à caractériser plus  !nement l'opposition binaire gai/triste. Un témoignage « triste » est (i) une histoire qui  !nit mal, (ii) un témoignage exprimant des doutes, des interrogations, ou sollicitant de  l'aide. Un témoignage « gai » est (i) une histoire triste qui !nit bien, (ii) un témoignage  modulant la gravité de la situation et soulignant les points positifs (iii) un conseil.   Nous   tentons   de   mettre   en   évidence   les   phénomènes   textuels   qui   di#érencient   les   témoignages de nos deux catégories. Nous avons une double ambition : trouver des  critères  de   classi!cation  linguistiquement   explicables   et   su&#34;samment   robustes  pour  servir de critères aux méthodes d'apprentissage supervisé. Nous faisons l'hypothèse que  les critères de classi!cation interprétables sont plus performants que les critères trouvés  par des méthodes d'apprentissage, souvent non signi!ants d'un point de vue textuel et  incidents   au   corpus   d'apprentissage   (ex :   présence   de   fautes   d'orthographe   non  pertinentes   par   rapport   aux   catégories   de   classi!cation).   Ainsi,   lors   de   l'étape   de  sélection de critères, l'analyste écarte les critères liés à l'échantillon du corpus et choisit  les critères textuels cohérents avec les composantes textuelles (thématique, dialogique,  etc. cf. § 5) actualisées dans le corpus. Pour l'expérience, nous avons utilisé trois types de  critères :   (i)   critères   unitaires :   un   choix   de   formes,   lemmes   ou   catégories  morphosyntaxiques ; (ii) critères composites adjacents (n-grammes) ; (iii) cooccurrences  multiniveaux (combinant les éléments de di#érents niveaux de description linguistique :  formes, lemmes ou catégories morphosyntaxiques). Tous les critères sont sélectionnés  selon 4 principes : leur caractère spéci!que à un sous-corpus, leur répartition uniforme  dans le sous-corpus, leur fréquence et leur pertinence linguistique.   L'analyse du corpus et l'extraction des critères ont été e#ectuées avec deux logiciels   textométriques   -   Lexico3   (Salem  et   al.  2003)   et   TXM   (Heiden  et   al.  2010)   -   qui  implémentent les algorithmes de spéci!cités (Lafon, 1980) et de cooccurrences (Lafon,  1981). Nous avons choisi les deux premiers types de critères selon le procédé suivant :  1. calcul   des   spéci!cités   des   items   isolés   (formes,   lemmes   et   catégories   morphosyntaxiques) et de leur n-grammes (fonction « Segments Répétés » de  Lexico 3) pour chaque sous-corpus (gai/triste) ;  2. analyse   des   contextes   d'apparition   des   items   spéci!ques   (au   moyen   de   concordances  textuelles)  a!n  de  s'assurer  de  leur   pertinence   textuelle  et  de  l'unicité de leur fonction (les critères ayant une seule fonction et signi!cation ont  été privilégiés) ;  3. véri!cation   de   la   répartition   uniforme   des   items   dans   le   sous-corpus   (fonctionnalité « Carte de Sections » du Lexico 3) ;  La sélection des cooccurrences s'est fait comme suit :   1. calcul   des   cooccurrences   (fonction   « Cooccurrences »   de   TXM)   des   items   spéci!ques fréquents et uniformément repartis sur la totalité du corpus ;  2. analyse des contextes d'apparition de ces cooccurrences ;   3. sélection des cooccurrences spéci!ques à un sous-corpus ;   Dans les deux cas, les critères de classi!cation pour chaque texte sont des fréquences ou   des valeurs booléennes (présence/absence) des items sélectionnés.  La deuxième étape consiste à utiliser des algorithmes d'apprentissage supervisé pour   classer les textes.  En utilisant Weka , nous en avons expérimenté trois, chacun d'une  famille di#érente : les arbres de décision (J48 ;  Quinlan, 1993), Naive Bayes (John et  Langley, 1995) et les Machines à Vecteurs de Support (SMO ; Platt, 1998). L'objectif est  d'observer les di#érences et similitudes au niveau des performances en changeant la  nature et la quantité des critères.  Le corpus contient 300 textes équitablement répartis entres les deux catégories (147   « gaies » et 153 « tristes »). L'évaluation a été e#ectuée avec la méthode de validation  croisée sur cinq parties.    Expérimentation   1.1 :  première   expérimentation   avec   des   mots   simples   sans  aucune   modi!cation   (avec   pour   valeur   leur   fréquence   dans   un   texte) ;   on  considère ces résultats comme la base de comparaison  (baseline)  pour d'autres  expérimentations.  La   base   de   comparaison   est  donc  l'expérimentation   qui  nécessite   l'e#ort  computationnel  minimal  sur   les   textes   en   considérant  ces  derniers  comme   un   matériau   brut,   directement   accessible   (au   moyen   d'une  segmentation   en   mots).   Toutes   les   autres   expérimentations   e#ectuent   des  traitements   supplémentaires   sur   les   textes  visant  à   améliorer   les   résultats.  L'évaluation a été e#ectuée avec la validation croisée sur 5 parties du corpus.  Expérimentation 1.2 : A la place des mots, nous avons utilisés leurs lemmes (casse  normalisée).    Expérimentation 1.3 : Utilisation des n-grammes de mots (longueur maximale 3).  Dans la série des expérimentations 2, nous avons utilisé les critères élaborés selon la   méthodologie décrite dans la partie précédente.     Expérimentation 2.1 :  Utilisation  de  critères unitaires et  de  critères composites  adjacents pour un total de 30 critères.    Expérimentation   2.2 :  Ajout   de  critères   cooccurrentiels   et   augmentation  du  nombre (total : 46 critères).     Expérimentation 2.3 : Augmentation du nombre de critères (total : 61 critères).   Type d'attributs  Algorithme de  classi!cation % des textes  bien catégorisés  1.1. Mots simples (1200 critères)  J48 53  Naive Bayes  63  SMO  70  1.2. Lemmes (370 critères)  J48 55  Naive Bayes  63  SMO  64  1.3 N-grammes de mots (1357 critères)  J48 56  Naive Bayes  64  SMO  74  2.1. Critères textométriques (30 critères)  J48 67  Naive Bayes   64  SMO  65  2.2. Critères textométriques (43 critères)  J48 62  Naive Bayes   72  SMO  72  2.3. Critères textométriques (61 critères)  J48 70  Naive Bayes  74  SMO  77  T   1 - Résultat des expérimentations  Comme   dans   des   expériences   similaires   (Pang  et   al.,  2002),   on   constate   que   la   classi!cation   sur   les   mots   simples   et   les   n-grammes   permet   d'obtenir   des   résultats  convenables compte tenu de la di&#34;culté de la tâche. Néanmoins, cela constitue un  plafond   que   l'on   ne   peut   dépasser.   La   généralisation   des   critères   apportée   par   la  lemmatisation ne permet pas d'améliorer les résultats. Ce phénomène a fait l'objet de  nombreux débats dans la communauté textométrique (par exemple Mellet, 2003).  A la di#érence de la première série d'expérimentations, nos critères textométriques sont   peu nombreux mais ils constituent une base facilement extensible. L'ajout des critères  augmente   systématiquement   les   performances   de   Naive   Bayes   et   SMO.   Ainsi,   nous  observons   une   progression   sensible   sur   l'ensemble   des   algorithmes.   Notre   meilleur  résultat (avec SMO) dépasse de 7 points celui obtenu avec des mots simples et de 3  points celui des n-grammes. Par ailleurs, l'amélioration des résultats pour J48 et Naive  Bayes est systématique.  L'interprétation des résultats chi#rés et des critères obtenus participe selon nous de la   validation de l'expérimentation  et en constitue une valeur ajoutée. Ainsi, nous avons  organisé nos critères selon une typologie inspirée de travaux sémiotiques. Les critères  thymiques   (Courtès,   1991),   qui   relèvent   d'une   lecture   axiologique   des   textes,   sont  essentiellement dysphoriques et concernent donc les textes tristes :  « avoir peur »,  « je  sou&#34;re », « douleur », « stress ». Le seul critère thymique retenu pour la classi!cation des  textes gai est  « heureux »  (euphorique). Au-delà des critères thymiques courants, nous  nous sommes intéressés à ceux relatifs à des composantes textuelles (Rastier, 2001) parce  que, ne relevant pas de typologies axiologiques classiques (positif/négatif) (Charaudeau,  1992), ils sont rarement pris en compte en AS. La  composante  dialectique  concerne  l'organisation linéaire et temporelle du récit. Ces critères, dans les textes « gais », sont  di#érents marqueurs de structuration argumentative (« par contre », « car ») et temporelle  (« après »,  « puis »)   absents   des   textes   « tristes ».   Dans   ceux-ci,   la   structuration   est  cumulative (« en plus », « de nouveau ») ou indice d'incertitude (« ne pas arriver à », « avoir  l'impression de »). La composante  dialogique  est relative au positionnement des acteurs.  Elle   met   en   oeuvre   un   fort   contraste   entre   les   textes   « gais »,   où   le   destinateurénonciateur s'adresse explicitement à un « tu » destinataire actualisé par des pronoms de  2ème personne (pronoms personnel, possessifs, etc.), relate une expérience édi!ante  (« mon expérience »,  « pour ma part ») et prodigue des conseils (présence d'hyperliens  « www ») et des encouragements (« bon courage ») sans pour autant mettre en avant un je.  Les  témoignages   « tristes »   mettent   en   texte   un  « je »  massif.   En!n,   la   composante  thématique n'a pas été négligée mais nous nous sommes e#orcés de ne sélectionner que  des critères d'un grand niveau de généralité relatifs au domaine de la santé. Ainsi, aux  noms de symptômes, maladies, traitements ou médicaments, nous avons préféré, pour les  textes « tristes » : « urgences », « hôpital », « rendez-vous », « analyses », « médecins », ou la  locution  « être   atteint   de ».   Pour   les   textes   « gais » :  « rémission »,  « produit   naturel »,  « homéopathie » permettent d'obtenir des résultats convaincants.  Il   est   admis   que   les   méthodes   e&#34;caces   en   classi!cation   thématique   (par   exemple,   l'apprentissage   supervisé   sur   mots   simples)   sont   peu   performantes   pour   les   tâches  d'analyse de la subjectivité. La di&#34;culté réside dans le fait que la subjectivité ne relève  pas seulement du lexique, mais d'autres niveaux de description : organisation temporelle  du   récit,   structure   argumentative,   etc.   Nous   avons   proposé   ici   quelques   éléments  d'analyse pour la prise en compte de ces niveaux de description et leur implémentation  pour la classi!cation. Le coût en temps de notre méthode d'élaboration de critères n'a  pas été quanti!é mais nous estimons qu'il est comparable à d'autres méthodes semiautomatiques. Le domaine manquant de méthodes éprouvées, notre expérience nous a  permis de mieux comprendre la tâche et sa complexité et d'esquisser une proposition  méthodologique tenant compte d'une caractérisation textuelle de la subjectivité.  
