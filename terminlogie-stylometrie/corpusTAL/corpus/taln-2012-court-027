. Ces travaux se focalisent sur l'estimation de paramètres  contenus dans une table de traduction. L'approche classique consiste à estimer ces paramètres à partir de fréquences relatives d'éléments de traduction. Dans notre approche, nous proposons d'utiliser le concept de masses de croyance afin d'estimer ces paramètres. La théorie des fonctions de croyances est une théorie très adaptée à la gestion des incertitudes dans de nombreux domaines. Les expériences basées sur notre approche s'appliquent sur la traduction de la paire de langue français-anglais dans les deux sens de traduction. Feature calculation for Statistical Machine Translation by using belief functions  In this paper, we consider the translation of texts within the framework of the 7th Workshop  of Machine Translation evaluation task and the COSMAT corpus using a statistical machine translation approach. This work is focused on the translation features calculation of the phrase contained in a phrase table. The classical way to estimate these features are based on the direct computation counts or frequencies. In our approach, we propose to use the concept of belief masses to estimate the phrase probabilities. The Belief Function theory has proven to be suitable and adapted for the management of uncertainties in many domains. The experiments based on our approach are focused on the language pair English-French. Traduction automatique statistique, fonctions de croyance, apprentissage automatique, estimation de paramètres. Statistical machine Translation, belief function, machine learning, feature estimation.  Il est classique d'utiliser une table de traduction comme élément d'un modèle de traduction  automatique statistique (TAS). Dans un système de traduction automatique fondé sur des segments (ou séquences de mots), une table de traduction contient les traductions alternatives et ses probabilités pour un segment en une langue source donnée. Chaque ligne ou événement d'une table de traduction comprend deux segments, l'un en langue source et l'autre en langue cible. On suppose que les événements sont indépendants les uns des autres. Les tables de traduction peuvent contenir beaucoup de paramètres comme les probabilités de traduction des segments ou les probabilités lexicales. Afin d'estimer ces paramètres, les systèmes de TAS utilisent de grands corpus appelés bitextes, qui sont composés de phrases en langue source et en langue cible qui sont la traduction l'une de l'autre. Pour chaque phrase, les mots des deux langues sont alignés en fonction de la traduction.  Dans l'approche classique, l'estimation des probabilités est faite par l'utilisation des fonctions de  compte simples, sur la base de fréquences relatives. Dans de nombreux travaux, la théorie des fonctions de croyance (initialement théorie de Dempster-Shafer) permet une représentation à la fois plus souple et plus précise de différents types d'incertitude que les modèles probabilistes ( Smets , 1988 ; Cobb et Shenoy , 2006 ). Par exemple, les modèles probabilistes peuvent difficilement prendre en compte le conflit entre deux hypothèses différentes de traduction, en particulier dans le cas des exemples rares. Il est également délicat d'estimer le degré de confiance global que l'on a sur l'ensemble des éléments de traduction pour une source donnée.  La théorie des fonctions de croyance est capable de traiter ce genre de situations en fournissant  des degrés de conflit quand il y a des hypothèses contradictoires, ainsi que des mesures de confiance globale. Dans cet article, nous proposons une méthode originale pour estimer les paramètres associés aux événements constitués de paires de segments à l'aide des fonctions de croyance.  Cet article présente nos premiers travaux et leurs résultats réalisés avec cette nouvelle approche.  Il est organisé comme suit : tout d'abord, nous rappelons brièvement la théorie de la traduction automatique statistique. Dans la section 3 , nous détaillons notre approche basée sur les fonctions de croyance. Ensuite, nous présentons des expériences sur différents corpus de traduction français-anglais. Enfin, nous concluons cet article et proposons quelques perspectives.  Soit une phrase source s traduite en un certain nombre de phrases cibles t  T  , où T est l'ensemble de toutes les traductions observées de s dans la table de traduction. Le modèle de traduction automatique statistique (TAS) utilise un ensemble de n fonctions f , i = 1 . . . , n, qui dépendent des séquences de mots sources et cibles, afin de déterminer la meilleure traduction. Les fonctions que l'on considère habituellement comprennent le modèle de traduction, le modèle de distorsion, le modèle de langage cible et différentes pénalités. Parmi toutes les traductions possibles, celle qui sera choisie maximise la probabilité a posteriori, et peut s'exprimer de la façon suivante :  t  = arg max log f (t, s) , (1)  où chaque paramètre   est un coefficient de pondération pour chaque fonction f ( Och , 2003 ). Ces poids sont généralement optimisés de façon à maximiser la performance de traduction sur  Tableau 1 - Exemple de paires de segments extraits d'un bitexte   des ensembles de données de développement. Le travail présenté dans cet article se focalise sur  les caractéristiques utilisées pour estimer le modèle de traduction.  Dans l'outil de traduction classique « Moses » (  Koehn et al. , 2007 ), la table de traduction contient cinq caractéristiques ( Koehn , 2010 ) : les paramètres de traduction des segments, la pondération lexicale des traductions et la pénalité des segments. Les paramètres de traduction des segments sont estimés à l'aide de la règle de décision de Bayes dans les deux sens de traduction. Les poids lexicaux sont estimés à partir du modèle IBM 1 basés sur les mots de chaque paire de segment. Enfin, la pénalité d'apparition du segment est définie par l'utilisateur. Cette fonction permet de privilégier les segments en fonction de leur longueur et prend une valeur constante  pour tous les segments. Si  > e, on préférera des segments longs aux segments courts. Inversement, si  < e, les segments courts seront privilégiés. Une fois que ces paramètres sont définis, les poids de l'ensemble de ces caractéristiques sont optimisés au cours du processus d'entraînement par le taux d'erreur minimum (MERT) ( Och , 2003 ).  Dans cet article, nous nous concentrons sur l'estimation des paramètres associés aux segments de  traduction dans les deux sens de traduction, nous estimons les probabilités lexicales de manière classique et, enfin, nous fixons la pénalité d'apparition  à la valeur e.  Le tableau  1 donne un exemple de paires de segments extraits d'un bitexte. A partir de cet exemple, nous obtenons la table de traduction présenté dans le tableau 2 contenant l'estimation des différentes probabilités. Ainsi, la probabilité de traduction de « starting » sachant « étant donné » est une simple fréquence conditionnelle égale à 0,25 et la probabilité de « given » sachant « étant donné » est égale à 0,5. La probabilité conditionnelle inverse du segment de traduction est estimée de la même manière. Cette façon d'estimer les paramètres a quelques inconvénients. Lorsque certaines paires de segments apparaissent plusieurs fois, comme la paire « la maison blanche|the white house », et n'ont pas d'occurrences concurrentes, l'estimation de la probabilité du segment est égale à 1, mais dans d'autres situations, des événements peuvent survenir très rarement et être ambigus. Par exemple, supposons que pour le mot français « chien » (qui devrait se traduire par « dog » en anglais),  Tableau 2 - Exemple de table de traduction avec les différents paramètres  deux occurrences contradictoires soient disponibles dans la table de traduction : « chien|cat » et « chien|dog ». Pour chacun de ces deux événements, l'estimation de la probabilité peut être égale à 1, car ils n'ont été observés qu'une seule fois. Par exemple, dans le cadre de notre expérience sur le corpus COSMAT, il existe 13 480 cas correspondant à 33 900 entrées sur les 363 324 que compte la table de traduction, soit un peu moins de 10%, dans le sens de traduction français-anglais.  Même si l'estimation de la probabilité de la traduction des paires inversées « cat|chien » et  « dog|chien » peut équilibrer ce problème, si l'événement n'est observé qu'une seule fois dans les deux sens de traduction, l'estimation des probabilités conditionnelles inversées est inutile. Il existe la possibilité de lisser les probabilités de l'ensemble des événements ( Foster et al. , 2006 ). Cependant, les approches de lissage optent pour une redistribution des estimations afin de donner, notamment, une probabilité non nulle aux événements non observés ( Chen et Goodman , 1996 ; Goodman , 2001 ). Notre but n'est pas celui-ci, mais plutôt de proposer une approche différente de l'estimation des paramètres des événements observés.  L'utilisation de théories alternatives à la théorie des probabilités permet de mieux ajuster ces  estimations. L'une d'elles est particulièrement adaptée à la gestion de différents types d'incertitudes : la théorie des fonctions de croyance, qui a été proposée puis développée depuis une trentaine d'années. Cette théorie a été appliquée avec succès à de nombreux domaines tels que l'identification du locuteur ( Petitrenaud et al. , 2010 ) ou la classification en général ( Elouedi et al. , 2000 ). Dans nos travaux, nous nous utilisons certains concepts fondamentaux de cette théorie pour notre problème d'estimation de paramètres.  Dans cette section, nous présentons brièvement quelques notions de la théorie des fonctions de  croyance ( Shafer , 1976 ; Smets et Kennes , 1994 ) et nous l'appliquons au problème d'estimation de paramètres de modèles de traduction. Dans cet article, nous adoptons le point de vue proposé par Smets : le modèle de croyances transférables (MCT) ( Smets et Kennes , 1994 ). L'objectif de ce modèle est de déterminer la croyance concernant différentes propositions, à partir d'informations disponibles.  Soit  un ensemble fini, appelé cadre de discernement de l'expérience. La représentation de  l'incertitude est faite par le biais de la notion de fonction de croyance, définie comme une fonction m de 2 sur [0, 1] telle que m(A) = 1. La quantité m(A) représente la croyance allouée à la  proposition A, et à aucune proposition plus restrictive. Une des opérations les plus importantes  dans le MCT est la procédure d'agrégation des informations, c'est-à-dire la combinaison de plusieurs fonctions de croyance définies dans un même cadre de discernement ( Smets et Kennes , 1994 ). En particulier, la combinaison de deux fonctions de croyance m et m indépendantes définies sur  est faite en utilisant l'opérateur binaire conjonctif , tel que m = m  m ( Smets et Kennes , 1994 ) :  A  , m (A) =  m (B)m (C) (2) Cet opérateur est associatif et commutatif, il est alors possible de définir la combinaison de n fonctions m , . . . , m sur  par la fonction de croyance m = m . . . m . Cette dernière fonction m capture l'information globale sur l'ensemble des expériences connues.  Ici, nous proposons d'utiliser le MCT pour estimer les paramètres de traduction des segments.  Tout d'abord, pour une source s, chaque cible t  T donne une information particulière pour la traduction qui peut être décrite par une fonction de croyance m , telle que :  m  ({t }) = p(t |s) m (T ) = p(t |s) , (3)  où p(t  |s) = 1  p(t |s). Si nous combinons les informations définies par toutes les hypothèses disponibles dans la table concernant la traduction de s, à partir de l'opérateur conjonctif défini dans l'équation 2 , nous obtenons alors une fonction de croyance m =  m . La masse de t est obtenue par la formule suivante :  m  ({t }) = p(t |s). p(t |s). (4)  Notons que généralement  m ({t }) = 1  m(T )  m( ) < 1. Les masses m(T ) et m( ) peuvent être respectivement interprétées comme le degré d'ignorance et le degré de conflit d'informations concernant la traduction de s. Même si m( ) n'entre pas directement dans notre modèle de traduction, quand il y a un conflit important entre plusieurs hypothèses de traduction, les masses de croyance sur chacun des singletons t  T s'affaiblissent. Nous obtenons alors une estimation de la fonction définie dans l'équation 2 par : f (t , s ) = m ({t }). De la même manière, l'estimation de la fonction inverse est obtenue par l'équation suivante :  m  ({s }) = p(s |t). p(s |t) , (5)  où S  est l'ensemble des sources possibles de la cible t. Si nous appliquons ces formules à l'exemple du tableau 1 , une nouvelle estimation des paramètres associés aux différentes paires de segments est calculée dans le tableau 3 .  Tableau 3 - Exemple d'estimation de paramètres de paires de segments à l'aide du MCT (s =  « étant donné »)  Notons que si p(t  |s) = 1, les masses de croyance pour les autres hypothèses deviennent nulles (cf. équation 4 ). La masse de croyance indiquée dans cette équation peut alors être modifiée de  Tableau 4 - Description des bitextes.   façon suivante :   m  ({t }) = 1  1 +  , (6)  où |s| désigne le nombre d'occurrences de s. Ainsi, m  ({t }) < 1 mais plus on a d'information sur s, plus m ({t }) tendra vers 1. Enfin, les phrases cibles choisies sont obtenues par le processus de décision défini par l'équation 2 .  Tableau 5 - Résultats obtenus suivant les métriques BLEU et TER avec deux systèmes entraînés  sur les corpus : News-Commentary 7 (nc7) ; Europarl 7 - News-Commentary 7 (eparl7-nc7).  Afin de valider notre méthode, plusieurs expériences ont été réalisées. Tout d'abord, nous avons  utilisé le corpus COSMAT, qui est un ensemble de bitextes de résumés de thèses de doctorat en français et en anglais. Puis, nos expériences ont été placées dans le contexte de l'évaluation du septième atelier sur la traduction automatique statistique (WMT12).  Le projet ANR COSMAT est composé de nombreux résumés de thèse de doctorat en français et  en anglais. Ces résumés ont été classés en fonction de plusieurs thèmes. Dans nos expériences, nous n'avons retenu que le domaine associé à l'informatique. Les corpus d'apprentissage, de développement et de tests sont décrits dans le tableau 4 .  Sur le corpus de développement, la perplexité des modèles de langage cible est de 122 pour  le français et de 196 pour l'anglais. Les modèles sont adaptés à la tâche grâce à l'utilisation du corpus d'entraînement (AbsTrain) et des modèles de langage.  Tableau 6 - Résultats obtenus avec le corpus COSMAT suivant les métriques BLEU et TER.   Le cadre utilisé pour l'évaluation de WMT12 contient plusieurs corpus. Ceux que nous avons  utilisés dans nos expériences sont décrits dans le tableau 4 . Les corpus d'apprentissage sont Europarl 7 (eparl7) et News-Commentary 7 (nc7). Les modèles employés quand la langue cible est le français et l'anglais ont respectivement une perplexité de 123 et de 169.  Les tableaux  6 et 5 contiennent les résultats obtenus avec l'approche classique et avec notre approche basée sur les fonctions de croyance. Les métriques utilisées sont le score BLEU ( Papineni et al. , 2002 ) et la métrique TER ( Snover et al. , 2005 ). Afin de garantir une certaine robustesse des résultats, trois optimisations de MERT ont été faites. Le résultat présenté correspond à une moyenne de ces trois optimisations et la valeur indiquée entre parenthèses est l'écart-type. La pénalité de brièveté (ou de longueur de phrase) associée au score BLEU est d'environ 0,99 (0,01) pour les deux approches, dans les deux sens de traductions et pour chacune des expériences.  Les expériences menées sur COSMAT et sur WMT12 montrent que notre nouvelle approche  semble avoir des résultats similaires à ceux de l'approche classique. Toutefois, le score BLEU a tendance à être plus faible dans notre approche lorsque le sens de la traduction est de l'anglais vers le français dans l'expérience avec le corpus WMT12 mais à l'inverse, dans l'expérience COSMAT, notre nouvelle approche est légèrement moins performante dans le sens français vers anglais. Malgré ce constat, ces premiers résultats sont encourageants et nous poussent à poursuivre dans cette direction. Cet article présente les premiers résultats sur l'utilisation du Modèle des Croyances Transférables (MCT) en traduction automatique statistique. Cette théorie a été utilisée pour estimer différemment les paramètres des paires de segments de traduction. Les résultats obtenus dans la traduction français-anglais, dans les deux directions, sur les corpus COSMAT et WMT12 sont encourageants. Prochainement, nous prévoyons d'appliquer le MCT en traduction de manière plus approfondie. D'abord, nous allons étendre cette approche à l'estimation des paramètres de pondération lexicale. Nous allons également orienter nos recherches vers une stratégie de prise en compte de la proximité linguistique des différentes hypothèses de traduction pour une phrase donnée. Pour reprendre l'exemple du tableau 1 , « star ting » serait notamment plus proche de « star ting f rom » que de « given ». Le MCT permet d'intégrer ce genre de situations avec une certaine souplesse.  Ce travail a été financé par l'Agence Nationale de la Recherche dans le cadre du projet COSMAT  et par la Commission Européenne à travers le projet E M P .  
