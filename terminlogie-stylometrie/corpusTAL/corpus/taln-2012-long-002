L'extraction d'information vise à extraire automatiquement à partir de textes des informations  structurées pertinentes pour une tâche particulière (Poibeau, 2003). Il y a essentiellement deux types de méthodes utilisées en extraction d'information : les méthodes où une personne (un « expert ») fournit des connaissances (linguistiques ou sur le domaine) , et les méthodes dirigées par les données, où ces connaissances sont construites par apprentissage supervisé. Il existe également des méthodes hybrides combinant ces deux techniques. Ces deux types de méthodes ont certaines limitations ((Bach et Badaskar, 2007), (Nadeau et Sekine, 2007), (Ben Abacha et Zweigenbaum, 2011c)) : - Les méthodes à base de connaissances expertes sont simples à mettre en place mais coûteuses en temps pour ce qui est de la construction des connaissances. Elles ont aussi un potentiel de couverture réduit comparé aux méthodes statistiques. - Les méthodes par apprentissage peuvent être très robustes si (i) on dispose d'un bon nombre d'exemples d'entraînement et si (ii) le corpus de test est du même type que le corpus d'entraînement. Ces méthodes sont de fait dépendantes des données et des corpus annotés, ressources qui ne sont pas disponibles pour toutes les langues (par exemple, il n'existe pas de corpus médicaux annotés en français) ni pour toutes les tâches (par exemple, reconnaissance des entités médicales, extraction de relations sémantiques, etc.). Cette observation s'applique aussi au domaine médical : pour l'anglais, plusieurs outils spécialisés d'extraction d'information existent (tels que MetaMap (Aronson, 2001), cTAKES (Guergana K Savova et Chute, 2010)), ainsi que des corpus annotés en entités nommées (tels que i2b2 (Uzuner et al., 2011), Berkeley (Rosario et Hearst, 2004)). En revanche, peu de ressources sont disponibles en français : on ne trouve pas d'outils spécialisés pour l'extraction d'information, ni de corpus médicaux annotés.  L'annotation manuelle d'exemples pour l'entraînement peut être une solution pour les méthodes  par apprentissage supervisé ou semi-supervisé. Cependant, cette tâche nécessite des experts du domaine ciblé, au moins pour la validation. D'après nos expériences précédentes portant sur l'annotation manuelle de corpus médicaux en français constitués (i) de résumés d'articles scientifiques et (ii) de textes extraits du corpus EQueR (Ayache, 2005), plusieurs obstacles ont été mis en évidence. Dans une première phase, nous avons annoté manuellement des textes médicaux avec le concours de deux médecins. L'obstacle principal était le fait que la tâche est longue et fastidieuse. Ensuite, et pour accéler la tâche d'annotation, nous avons développé une interface pour l'annotation de phrases (et non pas de textes entiers) permettant à davantage de médecins de prendre part à l'annotation. Le premier inconvénient de cette méthode est la perte du contexte des phrases. Un deuxième inconvénient réside dans le fait que, même si le guide d'annotation est très détaillé, les divergences dans les avis des médecins augmentent avec le nombre de médecins intervenant (par exemple dans l'annotation des symptômes et des relations dans des textes dans le domaine psychiatrique). Ces divergences, portant par exemple sur les types d'entités médicales et les relations à annoter, peuvent ralentir le processus d'annotation manuelle et le rendre moins fiable.  Dans cet article, nous exploitons un autre type de méthode, la projection d'annotations d'une  langue à une autre (Yarowsky et Ngai, 2001), et testons son application au domaine médical. L'idée générale consiste à transférer des annotations d'une langue L1 (pour laquelle plus de ressources sont disponibles) à une langue L2 en utilisant des corpus parallèles et leur alignement au niveau des mots. Cette approche devrait nous permettre d'exploiter, pour l'annotation automatique de textes en français, les ressources disponibles en anglais ainsi que les méthodes d'extraction d'information développées pour cette même langue. Notre premier objectif, présenté à travers cet article, consiste à annoter automatiquement les entités médicales de textes en français par transfert d'entités détectées dans les textes anglais correspondants par des outils existants de reconnaissance d'entités médicales. La table 1 présente un exemple de ce que nous cherchons à obtenir.  Phrase en anglais  The role of carotid endarterectomy in the management of asymptomatic carotid stenosis is much less clear. Phrase équivalente en français Le rôle de l'endartériectomie carotidienne dans le traitement d'une sténose carotidienne asymptomatique est beaucoup moins clairement défini. Alignement au niveau des mots 0-0 1-1 2-2 3 3 3 4 4 3 5-5 6-6 7-7 8-8 9 11 10 8 11 9 11 10 12-12 13-13 14-14 15-15 15-16 Entités médicales (en anglais) &#34;carotid endarterectomy&#34; 3-4 [treatment] &#34;asymptomatic carotid stenosis&#34; 9-11 [problem] Résultat final (annotations en français) &#34;l'endartériectomie carotidienne &#34; 3-4 [treatment] &#34;une sténose carotidienne asymptomatique&#34; 8-11 [problem]  T  1 - Exemple illustratif de l'approche proposée  Après un rappel des travaux similaires (section 2), nous présentons les deux étapes principales  de l'approche que nous proposons ici (telle qu'illustrée sur la figure 1) :  1. L'extraction d'information à partir de la partie L1 du corpus parallèle, en utilisant des  méthodes déjà développées ou des outils disponibles (section 3). Pour ce faire, nous utilisons une méthode à base de connaissances expertes, MetaMapPlus (section 3.2) que nous adaptons pour traiter des corpus hétérogènes (section 3.3). 2. L'alignement des mots des parties L1 et L2 du corpus (section 4.1) et la projection des entités repérées sur L1 vers la partie L2 en utilisant ces alignements (section 4.2). Nous mettons en place quelques heuristiques pour réparer certaines erreurs et améliorer la précision de la projection en diminuant le bruit des alignements.  Nous évaluons notre approche (section 5) sur une partie du corpus Santé Canada  et discutons ses résultats, puis concluons (section 6) sur des perspectives de travaux futurs .  Des travaux sur la projection d'analyses linguistiques ou d'annotations d'une langue à l'autre se  sont développés essentiellement à partir des années 2000. Yarowsky et Ngai (2001) ont proposé F 1 - Approche proposée pour l'annotation automatique d'un corpus médical français, utilisant un corpus parallèle et des méthodes d'extraction d'information à partir de textes anglais  d'utiliser des corpus parallèles alignés au niveau des mots pour transférer de façon robuste de  l'anglais au français ou au chinois des étiquettes morphosyntaxiques et des frontières de syntagmes nominaux. Lopez et al. (2002) ont étudié comment transférer un arbre de dépendances de l'anglais vers le chinois. Lü et al. (2002) se sont également intéressés au transfert d'analyses syntaxiques de l'anglais vers le chinois Padó et Pitel (2007) ont traité le problème de l'annotation automatique de rôles sémantiques dans une langue ne disposant pas de lexique FrameNet , en s'intéressant au couple de langue (anglais-français).  Dans le domaine médical, plusieurs travaux ont attaqué le transfert de connaissances d'une  langue à une autre (Névéol et al., 2005; Deléger et al., 2006). En particulier, Deléger et al. (2009) se sont intéressés à l'acquisition de nouvelles traductions de termes issues de trois terminologies différentes («MeSH», «SNOMED CT» et «the MedlinePlus Health Topics»). Ces auteurs se sont basés sur l'alignement des mots à partir d'un corpus parallèle anglais-français.  Dans cette section, nous présentons la tâche de Reconnaissance des Entités Médicales (REM)  (section 3.1). Ensuite, nous décrivons notre méthode à base de connaissances expertes pour la REM à partir de textes anglais (section 3.2). L'application de cette méthode sur des grands volumes de données hétérogènes a révélé certains problèmes liés à l'ambiguité de certains termes. Nous proposons dans la section 3.3 une solution pour pallier cette ambiguité : un filtre statistique utilisé en amont pour améliorer la précision des entités extraites. En effet, en vue de la projection vers un autre corpus à des fins de détection d'entités correctes dans la langue cible, il est fortement souhaitable que les entités du corpus source soient correctes : c'est ce que vise à obtenir le filtrage mis en place, qui privilégie la précision par rapport au rappel.  La REM est la tâche de base de l'extraction d'information à partir de textes médicaux. Nous  désignons par « entité médicale » une instance d'un concept médical ou une catégorie générique (par exemple, l'Alzheimer est une instance de la catégorie « Maladie », la laryngoscopie est une instance de « Examen »). Cette définition soulève deux questions : (i) quelle est la liste des catégories médicales traitées (Problème médical, Examen, Traitement, etc.) et (ii) quelle est la définition exacte de chaque catégorie (par exemple, les plantes peuvent-elles être considérées comme des traitements ?). Dans cet article nous travaillons sur les trois grandes catégories les plus importantes dans le domaine médical, à savoir : « Problème », « Traitement » et « Examen ». Nous utilisons les types sémantiques de l'UMLS pour définir chaque catégorie (cf. la table 2), en suivant le guide d'annotation i2b2/VA 2010 (Uzuner et al., 2011).  T  2 - Les catégories médicales traitées  La reconnaissance des entités médicales consiste en (i) le repérage des termes médicaux dans  les textes (tels que beta cell replacement, pyogenic liver abscess, infection of biliary system, etc.) et (ii) l'identification de la catégorie sémantique des termes repérés (telles que Maladie, Médica- ment, Examen, etc.). L'exemple suivant illustre les résultats de la REM pour une phrase extraite d'un résumé MEDLINE. Les termes médicaux sont annotés par des étiquettes <Treatment> et <Disease>.  <Treatment> Adrenal-sparing surgery </Treatment> is safe and effective , and may become  the treatment of choice in patients with <Disease> hereditary phaeochromocytoma </Disease>. [PMID : 10027369]  Ces deux étapes amènent à effectuer des choix dans les catégories médicales à traiter, mais  également dans les règles de délimitation des frontières des entités médicales dans le texte. Dans ce travail, nous avons effectué les choix suivants pour la délimitation des frontières : (i) inclure les possessifs, adjectifs, adverbes et chiffres dans les entités nommées (ii) annoter les abréviations séparément et (iii) ne pas annoter une entité médicale incluse dans une autre.  Le domaine médical dispose de grandes bases terminologiques telles que l'UMLS (McCray et  Nelson, 1995) ainsi que d'outils qui permettent de détecter les termes médicaux. Un des outils les plus largement utilisés est MetaMap (Aronson, 2001), un système à base de connaissances qui se fonde sur l'UMLS. MetaMap permet de segmenter les textes médicaux en phrases et syntagmes nominaux qui correspondent à des termes médicaux. L'outil identifie les entités médicales et leurs catégories (concepts et types sémantiques du réseau sémantique UMLS). Cependant l'étude de l'utilisation simple de MetaMap a révélé qu'il présente certains problèmes. Afin d'améliorer la précision des résultats de MetaMap, nous avons proposé la méthode MetaMapPlus (Ben Abacha et Zweigenbaum, 2011a), qui comporte les quatre étapes suivantes : - Extraire les syntagmes nominaux à l'aide d'un segmenteur (chunker). Nous utilisons TreeTagger-chunker qui offre une bonne segmentation et permet de diminuer le bruit de la REM (voir (Ben Abacha et Zweigenbaum, 2011c) pour une comparaison de trois segmenteurs). - Filtrer les syntagmes candidats avec une liste de mots vides en amont de MetaMap. - Rechercher les termes candidats dans des listes d'entités médicales construites à partir du Web. - Pour le reste des termes candidats, déterminer leurs catégories avec MetaMap, après un filtrage par une liste des erreurs les plus fréquentes de MetaMap et en contraignant les types sémantiques utilisés par ce dernier. Les résultats de MetaMapPlus, mesurés sur le corpus i2b2 (rappel de 48,68 %, précision de 56,46 % et F-mesure de 52,28 %), sont significativement meilleurs que ceux de MetaMap (Fmesure de 15,80 %) mais restent limités à cause de la performance du procédé de segmentation. L'approche a cependant permis d'identifier le type correct pour 52,28 % des entités, sachant que seules 60,76 % des entités ont été extraites correctement par le segmenteur (i.e. avec des frontières correctes).  En appliquant la méthode MetaMapPlus sur un grand corpus médical extrait du web, nous  avons constaté que des ambiguïtés lexicales apparaissaient plus souvent. En effet, plusieurs termes généraux sont considérés par MetaMap comme des entités médicales. Cette ambiguïté peut être divisée en deux catégories principales : (i) les homonymes (e.g. ten, qui désigne dix en domaine ouvert et la maladie « Toxic Epidermal Necrolysis » en domaine médical) et (ii) les termes généraux ayant un sens qui se spécialise dans le domaine médical (e.g. case, form). Ces ambiguïtés causent du bruit dans la reconnaissance d'entités médicales. Pour résoudre le problème d'ambiguïté lexicale, nous proposons une étape supplémentaire intégrée à la méthode MetaMapPlus. Cette étape (appelée Maxent_SNG) consiste à utiliser un classifieur pour distinguer les termes médicaux et les termes généraux, avant d'appliquer MetaMap. Le but de ce module est de : 1. Réduire le bruit lié à l'ambiguïté lexicale, en éliminant les syntagmes nominaux (SN) « généraux » fréquents en domaine ouvert même lorsqu'ils sont utilisés dans le domaine médical (par exemple « table »). 2. Réduire le volume à traiter par la catégorisation via MetaMap en éliminant une bonne partie des syntagmes nominaux à classifier, ce qui devrait réduire le temps d'exécution. Les méthodes statistiques à base d'apprentissage supervisé peuvent être très robustes. Cependant, ces méthodes présentent deux inconvénients importants :  1. La dépendance aux données annotées disponibles (cf. (Ben Abacha et Zweigenbaum,  2011c)), ce qui constitue un obstacle à l'utilisation de ce type de méthodes pour des tâches et domaines pour lesquels on ne dispose pas de corpus annotés, considérant en outre que la constitution de ces corpus est une tâche coûteuse.  2. Le problème de portabilité sur des corpus différents de ceux utilisés en entraînement  (cf. (Ben Abacha et Zweigenbaum, 2011c)), la dégradation des performances une fois appliquées sur des corpus ayant des caractéristiques différentes de ceux utilisés pour l'entraînement constitue un obstacle pour le passage à l'échelle de ces méthodes.  Ces deux inconvénients constituent un important défi pour la mise en place d'une méthode  statistique efficace et portable. Pour différencier les données d'entraînement (ce qui offrira une meilleur adaptabilité) et éviter le sur-apprentissage (en apprenant correctement et non pas « par coeur »), nous traitons deux problèmes : (i) comment choisir les exemples d'entraînement ? (ii) et quels sont les attributs à utiliser ?  3.3.1 Sélection des données d'apprentissage   À l'instar des travaux sur l'apprentissage actif (Active Learning) (Thompson et al., 1999;  Tomanek et Olsson, 2009) qui sélectionnent des exemples diversifiés et représentatifs à annoter manuellement, nous avons trouvé utile de sélectionner les exemples à utiliser pour « bien » apprendre. Deux questions clés se posent alors : - le nombre des exemples positifs et négatifs à utiliser ; - le choix de ces exemples qui doivent être représentatifs. Pour choisir ces exemples, nous proposons d'utiliser :  1. la fréquence des mots/syntagmes nominaux (positifs et négatifs) dans un même corpus ;   2. la présence des mots/syntagmes nominaux (positifs et négatifs) dans des corpus textuels  médicaux de genres différents ;  3. le Web pour collecter des données (des exemples positifs et négatifs).   Plus précisément, pour la construction des données d'apprentissage pour le module qui permet  de classifier les syntagmes nominaux (SN) en entités médicales (EM) ou termes généraux (SNG), nous utilisons les exemples positifs et négatifs suivants :  1. Exemples positifs : entités médicales  - les EM les plus fréquentes dans le corpus i2b2 de textes cliniques ; - les EM les plus fréquentes dans le corpus Berkeley d'articles scientifiques (Rosario et Hearst, 2004) ; - les EM communes aux deux corpus ; - des EM extraites du Web (notamment de Wikipedia , HON ) ; 2. Exemples négatifs : SN « généraux » (SNG) qui ne correspondent pas à des entités médicales : - les SNG les plus fréquents dans le corpus i2b2 ; - les SNG les plus fréquents dans le corpus de Berkeley ; - les SNG les plus fréquents qui existent dans ces deux corpus ; - des SNG extraits du Web, à partir de sites thématiquement distant du domaine médical. Nous avons choisi des sites d'histoires pour enfants ). Notre motivation est d'utiliser des corpus ne contenant pas ou peu d'entités médicales.  La table 3 décrit les types d'exemples positifs et négatifs que nous avons utilisés, selon trois  critères : corpus, nombre d'exemples et nombre d'occurrences de chaque exemple.  T  3 - Classification des syntagmes nominaux en termes médicaux et termes généraux, et sélection des exemples positifs et négatifs selon trois critères : corpus, nombre d'exemples et nombre d'occurrences de chaque exemple.  3.3.2 Attributs utilisés par le classifieur   Pour cette tâche, nous utilisons un classifieur à maximum d'entropie  . Pour chaque syntagme nominal (médical ou général), les attributs utilisés par le classifieur sont : - la longueur du SN, son nombre de tokens ; - le SN est un mot en majuscules / le SN est en majuscules / le SN contient un mot en majuscules ; - les mots / lemmes / catégories syntaxiques du SN ; - la présence et la fréquence des mots du SN dans la liste des mots du corpus général BNC ; - la présence des mots du SN dans un dictionnaire général (nous avons utilisé le dictionnaire standard du système d'exploitation Linux).  La projection que nous réalisons se fonde sur des alignements calculés au niveau des mots. Pour  les obtenir, nous avons utilisé les programmes d'alignement de corpus parallèles du système de traduction statistique M (Koehn et al., 2007), en utilisant le paramétrage par défaut. Celuici utilise l'outil G ++ (Och et Ney, 2004), qui calcule des modèles statistiques d'alignement de mots de complexité croissante. L'alignement est réalisé dans les deux directions puis ses résultats sont symétrisés. Finalement, des tables de traduction, qui regroupent l'ensemble des bi-segments pouvant être extraits du corpus, sont construites par application d'heuristiques d'extraction de bi-segments cohérents, qui imposent que tout mot d'un segment dans un langue doit être aligné avec au moins un mot du segment dans l'autre langue, mais avec aucun mot en dehors de celui-ci.  La figure 2 présente quelques exemples de bi-phrases alignées au niveau des mots.   F  2 - Exemples : trois bi-phrases alignées au niveau des mots  Pour projeter les annotations, nous utilisons le principe suivant :   Soit E  = {m , . . . , m } l'ensemble des mots constituant une entité médicale dans le corpus anglais et E = {m , . . . , m } l'ensemble des mots constituant la projection de E (i.e. l'union des projections de chaque mot dans E ). En notant position(m ) la fonction retournant la position d'un mot dans sa phrase, nous considérons que la projection de l'entité médicale anglaise est la séquence ordonnée de mots E = {m , . . . , m } telle que : - position(m ) = M in (position(m )) - position(m ) = M ax (position(m ))  Le bruit produit par l'alignement et les annotations affecte la qualité des annotations projetées.  Pour diminuer ce bruit et améliorer la phase de projection, (i) nous définissons des heuristiques (telles que la longueur de l'entité trouvée en français par rapport à l'entité originale en anglais) et (ii) nous utilisons un antidictionnaire pour filtrer les entités médicales obtenues et supprimer les « mots vides ».  Le corpus utilisé pour les expérimentations a été construit à partir du site bilingue « Santé  Canada » aligné au niveau des phrases (Deléger et al., 2009). La table 4 présente le corpus parallèle (anglais-français) Santé Canada.  T  4 - Le corpus parallèle Santé Canada Pour évaluer notre approche, nous avons besoin d'un bi-corpus de référence annoté. Deux éléments sont à déterminer : (i) la taille du corpus de référence et (ii) la manière de choisir ce corpus à partir du corpus initial Santé Canada. Nous nous sommes pour cela basés sur des travaux en statistiques.  Taille du corpus. Pour déterminer la taille (acceptable) du corpus de référence à sélectionner,  nous utilisons la formule utilisée en statistiques (Sim et Wright, 2005) pour déterminer la taille d'un échantillon : N = T P(1  P) E  Sélection du corpus. Différentes méthodes sont possibles, telles que l'échantillonnage aléatoire  simple (simple random sampling) ou l'échantillonnage stratifié (stratified sampling). Nous avons choisi d'utiliser l'échantillonnage aléatoire simple et sélectionné aléatoirement 385 phrases, contenant 4 613 mots.  Annotation manuelle du corpus de référence. Nous avons annoté manuellement les 385  phrases sélectionnées avec trois types de catégories médicales : Traitement, Problème et Maladie. Nous avons annoté les deux parties françaises et anglaises du corpus de référence en utilisant le guide d'annotation de i2b2 2010 (tâche 1), en respectant les règles de délimitation des frontières décrites dans la section 3.1.  Dans cette section, nous évaluons la REM à partir du corpus anglais. Nous différencions le cas  où les entités médicales ont été reconnues avec des frontières précises ou exactes et le cas où les frontières ne sont pas précises (par exemple, «as antimicrobial resistance» au lieu de «antimicrobial resistance», «Pap smear» au lieu de «a Pap smear» ou «the Pap smear» dans le texte). Nous utilisons les mesures standard de rappel, de précision et de F-mesure. Nous avons entraîné le module Maxent_SNG de classification des syntagmes nominaux en entités médicales et entités générales sur le corpus d'entraînement i2b2 et nous l'avons testé sur le corpus de test i2b2. Nous avons obtenu une correction (proportion d'exemple de test correctement classés) de 90,99 % (16 169/17 769). La table 5 présente la contribution à la méthode MetaMapPlus de ce module (Maxent_SNG), entraîné sur le corpus d'entraînement décrit dans la section 3.3.  T  5 - Résultats de la méthode MetaMapPlus sans et avec le module Maxent_SNG sur le corpus Santé Canada (partie anglaise).  Comme attendu, ce filtrage améliore sensiblement la précision des entités médicales détectées,  et en dépit d'une baisse importante de la valeur de rappel, la F-mesure connaît une nette augmentation.  Dans cette section, nous évaluons la qualité de la projection des entités médicales extraites du  corpus anglais par notre méthode (i.e. Maxent_SNG+MetaMapPlus). Dans un premier temps, nous évaluons uniquement la qualité de la projection (indépendamment des erreurs d'extraction). Pour ce faire, nous étudions la qualité de la projection des entités de référence (i.e. annotées manuellement). Dans un second temps, nous évaluons l'ensemble du processus pour la REM en français (comprenant l'extraction automatique des entités médicales en anglais et leur projection). Le tableau 6 présente les résultats de la projection des entités de référence et les résultats de la projection des entités extraites avec la méthode Maxent_SNG+MetaMapPlus. Nous avons pu améliorer les résultats de la méthode MetaMapPlus en intégrant le module MaxEnt entraîné sur trois types différents de corpus. Notons que les résultats obtenus en exploitant ces trois types de corpus sont meilleurs que ceux obtenus en entraînant le classifieur sur un ou deux corpus uniquement (ce que nous avons testé mais ne pouvons pas détailler dans cet  T  6 - Évaluation de la projection des entités médicales extraites avec la méthode Maxent_SNG+MetaMapPlus et les entités de référence sur le corpus Santé Canada (partie française). article). Les résultats sont relativement acceptables (51,78 % de F-mesure) étant donné la complexité de la tâche sur un corpus hétérogène extrait du Web.  Pour la projection, nous avons utilisé les alignements au niveau des mots avec une approche  simple qui consiste à prendre l'entité correspondante (projetée) la plus large. Nous avons essayé d'améliorer cette projection en utilisant un antidictionnaire pour filtrer les entités obtenues et quelques heuristiques telles qu'une différence maximale entre la longueur de l'entité initiale et celle de l'entité projetée (cf. table 7).  T  7 - F-mesure de la projection des entités de référence sans et avec filtrage  Les résultats de la projection des entités médicales extraites sont relativement faibles, mais ceci  dépend directement de la performance de la méthode d'extraction d'information (51,78 % de F-mesure, avec frontières larges), qui fixe le plafond de performance atteignable en projetant ses résultats sur le corpus français. Par projection, nous perdons tout de même près de 50 % des extractions correctes dans le corpus anglais. Ceci résulte principalement de la qualité des alignements au niveau des phrases puis des mots. L'alignement au niveau des mots est influencé par la qualité de l'alignement des phrases (cf. les exemples 1 et 2 ci-dessous). En effet, dans certains cas, la phrase correspondante en français n'est pas équivalente à celle en anglais (soit elle est beaucoup plus courte et contient moins d'information, soit elle est beaucoup plus longue), dans d'autres cas elle a un contenu complètement différent ou reste formulée en anglais : cela reflète un problème d'alignement de phrases qu'il nous faudra corriger dans la suite de nos travaux.  Exemple 1 :  Exemple 2 : Il semble que ces deux phrases ne soient pas en relation de traduction, qui peut résulter d'un mauvais appariemment de documents ou entre phrases.  Nous avons proposé dans cet article une approche pour l'annotation automatique de textes  médicaux en français par projection depuis l'anglais, et présenté nos premières expérimentations en REM. L'approche présentée utilise un corpus parallèle aligné au niveau des mots pour projeter les annotations obtenues sur la partie anglaise vers la partie française. L'application de notre méthode de REM sur un grand corpus de données hétérogènes extrait du Web a posé une problématique de passage à l'échelle pour laquelle nous avons proposé une solution qui consiste à intégrer un module de filtrage statistique en amont des entités candidates pour améliorer la précision des entités extraites.  Nous envisageons principalement quatre perspectives à ce travail :  - L'annotation automatique des relations sémantiques dans des textes français en reprenant la méthode présentée. Nous avons déjà développé des méthodes à base de patrons et des méthodes statistiques pour l'extraction de relations sémantiques à partir de textes médicaux en anglais (Ben Abacha et Zweigenbaum, 2011b). - L'utilisation ou la construction d'autres corpus médicaux parallèles de meilleur qualité. - L'exploitation de corpus français annotés pour la mise en place de méthodes statistiques pour l'extraction d'information à partir de textes en français. - L'intégration de ces méthodes d'extraction d'information dans un système de questionsréponses translingue.  
