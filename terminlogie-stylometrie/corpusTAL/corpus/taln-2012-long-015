Il existe plusieurs scénarios dans lesquels il est souhaitable de pouvoir faire produire du texte par  la machine. Ce problème a traditionnellement été abordé comme une tâche de génération de texte à partir de concepts. Toutefois, ces besoins s'appliquent parfois à des cas où un nouveau texte devrait être dérivé de certains textes existants, par exemple lorsqu'il s'agit de transformer un texte afin qu'ils aient certaines propriétés souhaitables pour un usage particulier (Zhao et al., 2009). Par exemple, on peut souhaiter qu'un texte soit condensé (Cohn et Lapata, 2008), adapté à certains profils de lecteur (Zhu et al., 2010), conforme à certaines normes spécifiques (Max, 2004), voire même simplement plus adapté pour des tâches de traitement automatique ultérieures.  Le mécanisme de réécriture de texte doit donc produire un texte dont le sens est compatible  avec la définition de la tâche à accomplir, tout en garantissant que celui-ci demeure grammatical. La complexité de la génération texte-à-texte, par opposition à la génération concepts-à-texte, provient essentiellement du fait que la correspondance sémantique entre deux textes est difficile à contrôler, car les réécritures mises en jeu sont très dépendantes du contexte. En effet, la grande diversité des techniques d'acquisition de paraphrases sous-phrastiques (Madnani et Dorr, 2010), la polysémie de ces unités linguistiques ainsi que les contraintes pragmatiques associées à leur substitution font qu'il est impossible de garantir que des paires de paraphrases candidates seront substituables quel que soit le contexte de réécriture. Ce problème a été déjà décrit au niveau lexical (Zhao et al., 2007; McCarthy et Navigli, 2009) ; la validation automatique en contexte de reformulations de segments demeure une question fondamentale pour la réécriture de texte.  Dans ce travail, nous abordons le problème sous l'angle d'un paraphrasage ciblé  , défini comme la réécriture d'un segment d'un énoncé. Bien que ce problème soit plus simple que la réécriture d'une phrase complète, son étude se justifie par la nécessite de bien comprendre ce niveau moins complexe avant d'aborder la réécriture d'unités plus étendues, ce qui en outre facilite la tâche complexe de l'évaluation. Nous présentons ici un scénario en révision interactive de textes dans lequel des paraphrases sousphrastiques doivent être proposées en tenant compte du contexte. Les paraphrases candidates considérées sont obtenues à partir d'un répertoire existant, et sont validées en contexte à l'aide d'informations obtenues sur le Web. Les expériences que nous avons menées ciblent plus particulièrement les contributeurs de l'encyclopédie Wikipédia dans leurs tâches de révision des articles. Nous avons pour cela utilisé un ensemble de segments ayant fait l'objet de réécritures dans l'historique des articles de Wikipédia, que nous substituons par des paraphrases connues à l'avance. Étant donné la grande variété de segments possibles et de leurs paraphrases, nous ne nous appuyons pas sur des modèles de substituabilité préétablis, mais nous les construisons à la volée à partir du Web.  Dans cet article, nous allons tout d'abord décrire la tâche de révision de texte sous forme de  paraphrasage ciblé (section 2). Nous passerons ensuite en revue les principaux travaux précédents portant sur l'acquisition de paraphrases sous-phrastiques et décrirons les sources de connaissances que nous avons utilisées dans ce travail (section 3). Nous détaillerons ensuite notre méthode de calcul des modèles de substitution de segments en contexte exploitant des informations issues du Web (section 4). Les expériences menées pour valider les paraphrases contenues dans le répertoire existant et leurs résultats seront finalement présentés (section 5). Notre article se conclura par une discussion de ces résultats et une présentation des principales voies de recherche ( 6).  La reformulation d'un énoncé, ou d'un segment plus précis, est une activité importante en révision  de texte. Certaines modifications locales ont ainsi vocation à améliorer sa qualité générale, en le rendant par exemple plus facile d'accès (Zhu et al., 2010) ou en l'adaptant au niveau d'expertise de ses lecteurs (Deléger et Zweigenbaum, 2009). Les modifications de ce type, qui n'altèrent pas le sens des textes, incluent non seulement la synonymie lexicale mais également des transformations lexico-syntaxiques plus complexes. On trouve notamment de telles reformulations dans les historiques de révision de textes, qui sont désormais disponibles en grandes quantités avec l'émergence de ressources collaboratives sur le Web telles que l'encyclopédie Wikipédia. L'historique des révisions des articles de cette ressource constitue en effet une source importante de phénomènes de réécriture naturelle. L'étude de Dutrey et al. (2011) a notamment montré que cet historique contient une variété importante de phénomènes de reformulation, dont de nombreuses paraphrases. Cette étude a également montré, au travers d'une tentative d'identification automatique à base de règles, les difficultés pour parvenir à une bonne couverture de l'ensemble des phénomènes paraphrastiques présents.  Peu de travaux, ont, à notre connaissance, porté sur l'utilisation du paraphrasage contextuel  dans le cadre de l'aide à la rédaction. Max et Zock (2008) présentent une méthode proposant aux rédacteurs des paraphrases sous-phrastiques candidates pour les segments qu'ils souhaitent reformuler. L'approche utilisée pour la génération des paraphrases est fondée sur l'équivalence de traduction (Bannard et Callison-Burch, 2005). Les travaux de Bernstein et al. (2010) portent eux sur l'externalisation de diverses tâches d'édition de texte, dont la révision, via le crowdsourcing.  Par ailleurs, la réécriture d'un texte peut être destinée plus spécifiquement à une application  automatique. Dans (Resnik et al., 2010), des reformulations pour des segments jugés difficiles à traduire sont acquises via le crowdsourcing : des contributeurs monolingues de la langue source proposent ainsi des reformulations en contexte pour ces unités . Les reformulations collectées sont ensuite utilisées en entrée dans un système de traduction automatique, qui peut ainsi bénéficier de la variété d'expressions pour produire de meilleures traductions (Schroeder et al., 2009). Par exemple, le segment une optique festive dans L'usage intervient alors dans une optique festive peut être réécrit en : 1) un cadre festif, 2) une perspective de fête. Ces réécritures sont grammaticalement correctes et ont des significations raisonnablement proches de la formulation d'origine.  Outre la reformulation des segments de texte, la réécriture d'énoncés a aussi été à l'origine de  plusieurs travaux (Barzilay et Lee, 2003; Quirk et al., 2004; Zhao et al., 2010; Ganitkevitch et al., 2011). Cependant, celle-ci pose de nombreux autres défis, notamment au niveau de l'évaluation des reformulations produites. Le jugement par des humains devient alors encore plus complexe et n'autorise pas des distinctions fines ni des accords inter-annotateurs satisfaisants. La génération de paraphrases d'énoncés peut toutefois être évaluée indirectement dans le cadre de leur utilisation dans une application plus complexe. Par exemple, Madnani et al. (2008) parviennent à améliorer les performances d'un système de traduction automatique statistique en fournissant des paraphrases automatiques des traductions de référence lors de l'apprentissage des paramètres du système. Cependant, les améliorations observées n'indiquent pas clairement les liens avec la qualité des paraphrases utilisées.  Nous abordons dans ce travail la tâche plus modeste de paraphrasage sous-phrastique appliqué  à la révision de texte. Afin d'éviter tout biais, nous utilisons des réécritures écologiques (que nous entendons ici comme : produites naturellement) extraites d'une mémoire de rédaction des articles de Wikipédia. Nous utilisons pour cela le corpus W C P C (Max et Wisniewski, 2010), qui contient de nombreux phénomènes de réécriture, dont de nombreuses instances de reformulations lexicales, syntaxiques et sémantiques (Dutrey et al., 2011). Ce dernier type de reformulation est illustré dans l'exemple suivant, où le remplacement du segment un mode d'expression par sa paraphrase possible une figure de rhétorique permet de préciser et d'affiner le sens voulu par le contributeur initial :  L'antiphrase est [un mode d'expression  une figure de rhétorique] consistant à dire le contraire  de ce que l'on pense.  Ce corpus est pertinent à plusieurs titres pour la tâche que nous visons. Tout d'abord, le fait  qu'il contienne des réécritures obtenues hors du cadre d'expériences offre une source riche et intéressante d'unités textuelles réécrites en contexte. De plus, les instances de réécriture où le sens n'a pas été modifié offrent directement une paraphrase candidate qui peut être considérée comme correcte, donnée pouvant s'avérer utile pour l'apprentissage automatique du processus de validation en contexte. La disponibilité grandissante de masses de données textuelles a rendu possible un grand nombre de travaux en acquisition et en génération de paraphrases (Madnani et Dorr, 2010). Les techniques proposées apparaissent néanmoins assez fortement liées aux types de ressources auxquelles elles s'appliquent. Les types de corpus utilisés pour sont principalement :   des paires de paraphrases d'énoncés (corpus monolingues parallèles), qui permettent  d'obtenir des paraphrases précises, mais en faible quantité (Barzilay et McKeown, 2001; Pang et al., 2003; Cohn et al., 2008; Bouamor et al., 2011) ;  des paires d'énoncés en relation de traduction (corpus multilingues parallèles), qui permettent de générer de nombreuses paraphrases candidates (Bannard et Callison-Burch, 2005; Kok et Brockett, 2010) ;  des paires d'énoncés en relation partielle (corpus monolingues parallèles), qui permettent sur le principe d'acquérir de nombreuses paraphrases (Barzilay et Lee, 2003; Pasça et Dienes, 2005; Bhagat et Ravichandran, 2008; Deléger et Zweigenbaum, 2009).  Bien que la précision de ces techniques d'acquisition peut se mesurer sur la base d'une référence  attendue portant sur une collection de paires d'énoncés (Cohn et al., 2008), il est plus utile de pouvoir la mesurer au travers de la question de substituabilité en contexte, laquelle a déjà été abordée au niveau lexical (Connor et Roth, 2007; Zhao et al., 2007) où elle a fait l'objet de campagnes d'évaluation (McCarthy et Navigli, 2009). Celle-ci pose des défis supplémentaires, dûs au fait que les segments sont plus rares que les mots en corpus.  Le présent travail porte sur la tâche de validation automatique de paraphrases sous-phrastiques  en contexte. Pour cela, nous avons eu recours à un répertoire existant de paires de paraphrases. Comme décrit plus haut, nous avons utilisé le corpus W C P C comme corpus de reformulations sous-phrastiques naturelles. La réécriture contenue dans cette ressource peut être utilisée comme paraphrase potentielle. Afin d'obtenir d'autres paraphrases candidates de différentes qualités, nous avons utilisé deux autres méthodes d'acquisition, qui fourniront des paraphrases aux instances extraites de W C P C qui ne seront pas nécessairement substituables en contexte : a) une traduction automatique par pivot, et b) une acquisition manuelle de paraphrases. La génération de paraphrases par traduction s'effectue simplement en traduisant automatiquement un segment dans une langue pivot, puis en le rétrotraduisant dans la langue d'origine, et en retenant la première hypothèse différente du segment d'origine. Si cette technique n'offre aucune garantie sur la qualité des résultats, elle est aisée à mettre en oeuvre et produit des résultats variés. En outre, l'utilisation d'une langue pivot proche de la langue d'origine augmente la probabilité d'obtenir de bonnes paraphrases (ceci sera étudié lors de nos expériences, décrites dans la section 5).  Nous avons défini l'acquisition manuelle de paraphrases de la façon suivante : un corpus d'extraits  de documents du Web contenant les segments à réécrire est tout d'abord constitué, en s'assurant que ce corpus ne contient pas de données provenant de Wikipédia. Pour chaque segment à réécrire dans ce corpus, des locuteurs natifs du français proposent via une interface web une réécriture possible. Ainsi, les contextes utilisés pour faire l'acquisition de paraphrases des segments sont possiblement différents de ceux, extraits de W C P C , sur lesquels portera l'évaluation : notre système de validation en contexte aura donc à considérer des paraphrases potentiellement valides mais qui ne le sont pas dans le contexte d'une réécriture particulière.  Ces deux méthodes, dont la mise en oeuvre est aisée, nous permettent de simuler la disponibilité  d'un répertoire existant de paraphrases sous-phrastiques, qui nous servira pour l'évaluation de la performance de notre technique de validation en contexte.  Nous décrivons maintenant l'approche que nous proposons pour réaliser une validation de  réécritures en contexte, fondée sur une classification binaire exploitant des modèles calculés à partir d'informations du Web. Le recours au Web semble indispensable : seule une telle échelle nous permet d'accéder à des exemple en nombre suffisants pour certains segments. En outre, il a été montré qu'un certain nombre d'applications de Traitement Automatique des Langues peuvent être améliorées grâce à l'exploitation de fréquences de n-grammes sur le Web (Lapata et Keller, 2005). Considérant un ensemble de contextes de réécritures pour des segments ainsi qu'un répertoire existant contenant des paraphrases pour ces segments, notre tâche consiste à classer (i.e. paraphrase vs. pas paraphrase) chaque paraphrase possible pour chaque contexte original. Une instanciation concrète possible de cette tâche est la proposition de Max et Zock (2008), où de telles reformulations candidates sont présentées dans un ordre décroissant de pertinence à un utilisateur d'un éditeur de texte, et donc éventuellement lors de la révision d'un article de Wikipédia.  La tâche d'identification automatique de paraphrases a été déjà abordée par classification  automatique dans des travaux précédents, en utilisant des modèles calculés sur des corpus collectés (Brockett et Dolan, 2005) et sur des documents issus du Web (Zhao et al., 2007). Cependant, ces travaux se sont limités à l'identification de paraphrases lexicales (McCarthy et Navigli, 2009). Une difficulté importante est que certains mots sont absents ou très peu fréquents dans les index des moteurs de recherche, et a fortiori dans des corpus spécialisés, difficulté qui s'amplifie lorsque l'on considère des segments.  De façon analogue aux travaux de Brockett et Dolan (2005), nous considérons l'identification  de paraphrases comme une tâche de classification : étant donné un segment d'origine s dans le contexte d'une phrase p, nous cherchons à déterminer si une paraphrase candidate s' serait une paraphrase grammaticale de s dans le contexte de p. Nous avons abordé ce problème avec un classifieur de type séparateur à vaste marge (SVM) exploitant les traits décrits ci-dessous.  Distance d'édition Les approches les plus répandues en calcul de pertinence d'un document  relativement à une requête exploitent des mesures de similarité de surface, qui peuvent dans certains cas être de bons indicateurs de proximité sémantique. Un coût de transformation entre chaînes de caractères peut par exemple être celui donné par la mesure TER (Snover et al., 2010), initialement développée pour mesurer la similarité entre une hypothèse de traduction et une traduction de référence. Cette mesure se base sur des opérations d'édition (substitution, déplacement, insertion, suppression) plus informatives que les méthodes basées sur des intersections lexicales . Nous effectuons en outre ce calcul sur les lemmes plutôt que sur les formes de surface, que nous avons obtenus à l'aide du T T (Schmid, 1994) . Nous retenons donc le score suivant, calculé entre un segment d'origine seg et une paraphrase seg , où la fonction Lem produit une forme lemmatisée de son argument :  h  = TER(Lem(seg ), Lem(seg )) (1)  Il convient de noter que, contrairement aux autres modèles, celui-ci ne dépend pas d'informations  provenant du Web.  Score de modèle de langue La vraisemblance d'une phrase peut être un relativement bon  indicateur de sa grammaticalité locale (Mutton, 2006). Les probabilités données par un modèle de langue peuvent désormais être obtenues à l'aide de comptes provenant du Web. Nous avons pour cela utilisé le Service Web N-gram de Microsoft (Wang et al., 2010) dans sa déclinaison à des fins de recherche . Afin de pouvoir utiliser correctement ce service sur des textes français, nous avons dû supprimer tous les diacritiques : un examen précis des paraphrases candidates classées a montré que cette transformation, bien qu'abérante, nous a permis d'obtenir des résultats cohérents. Un simple score de modèle de langue pour un énoncé après réécriture n'est toutefois pas suffisant, car il ne tient pas compte de l'énoncé d'origine. Nous avons donc utilisé le rapport entre le score de modèle de langue de l'énoncé paraphrasé phr et le score de modèle de langue de l'énoncé d'origine phr , normalisé par la longueur des énoncés (Onishi et al., 2010) :  h  = M L(phr )  M L(phr  ) (2)  Scores de similarité thématique hors contexte Les techniques mises en oeuvre pour calculer  une notion de similarité entre unités textuelles sont fréquemment fondées sur le calcul de représentations des contextes d'occurrences de ces unités sur lesquelles sont calculées des mesures de similarité. Nous avons suivi ce type d'approche pour mesurer une similarité thématique entre paraphrases entre profils de mots cooccurrents. Nous construisons tout d'abord des profils hors contexte de la manière suivante : un moteur de recherche est interrogé afin de récupérer les N premiers extraits de documents (snippets) pertinents pour le segment seg . La fréquence des mots pleins présents dans ces extraits est alors calculée et est utilisée pour obtenir les valeurs de chaque dimension d'un vecteur de profil lexical T , dont la valeur pour un mot m est définie ainsi :  T  [m] = f req(seg , m) f req(seg ) (3)  Pour le calcul des fréquences, f req(u) correspond au nombre d'extraits de documents retournés  contenant l'unité u, et f req(u, v) au nombre d'extraits de documents rapportés contenant les deux simultanément. Nous construisons de façon analogue un profil thématique pour chaque paraphrase possible seg , en se limitant aux dimensions du vecteur pour le segment d'origine :  T  [m] = f req(seg , m) f req(seg ) (4)  Enfin, nous mesurons la similarité entre le profil du segment d'origine et de chacune de ses  paraphrases possibles à l'aide du cosinus entre les vecteurs de leur profil thématique :  h  = T · T ||T ||  ||T || (5)  Pour l'ensemble de nos expériences, nous avons utilisé le service Web Yahoo ! Search BOSS  pour obtenir le nombre de documents du Web indexés contenant une expression littérale (typiquement, un segment d'intérêt) ainsi que les extraits de documents à partir desquels nous construisons les vecteurs de profils thématiques. En supposant que la distribution des mots pleins cooccurrents n'est pas biaisée par l'ordre des résultats du moteur de recherche, notre modèle mesure donc un certain type de similarité thématique entre seg et seg . Scores d'un modèle thématique contextuel Nous définissons également un modèle thématique contextuel de la façon suivante : considérant cont , constituée des deux sous-chaînes de phr privée de seg , nous construisons un vecteur de profil T ayant pour dimension uniquement pour les mots pleins du contexte de la phrase où a lieu la réécriture. Les valeurs associées à chaque dimension correspondent à des rapports de fréquence obtenus comme précédemment par interrogation du moteur de recherche. La similarité thématique contextuelle utilisée est finalement définie par :  h  = T · T ||T ||  ||T || (6)  Dans cette section, nous détaillons les expériences que nous avons menées afin d'évaluer les  performances de l'approche de validation automatique de paraphrases en contexte.  Nous avons extrait aléatoirement 150 énoncés en français du corpus W  C P C et leur réécriture pour des exemples annotés comme "paraphrases" lors d'une annotation manuelle réalisée par une étudiante en linguistique francophone. Un sous-ensemble de 100 énoncés a été utilisé comme corpus d'apprentissage, les 50 énoncés restants ayant servi pour l'évaluation. Les segments originaux ainsi que leur paraphrase dans le corpus d'évaluation sont décrits dans la figure 1.  F  1 - Répartition du nombre de segments par taille (nombre de tokens) dans le corpus d'évaluation  Nous disposons finalement de 5 paraphrases par segment d'origine :    W  : la paraphrase associée au segment dans le corpus W C P C ;  H : deux paraphrases candidates proposées par des contributeurs humains pour d'autres contextes issus du Web ;  P and P : deux paraphrases candidates obtenues par traduction par pivot. Nous avons utilisé le système de traduction automatique sur le Web G T , avec une langue proche du français comme pivot (l'espagnol), et une autre plus distante (chinois).  La partie évaluation de nos expériences a impliqué 4 évaluateurs humains  , tous francophones. Ceux-ci ont participé à la collecte manuelle des paraphrases (H ) pour la moitié du corpus d'apprentissage et d'évaluation. Afin d'évaluer le caractère approprié de l'utilisation des paraphrases issues des paraphrases collectées dans les contextes de réécriture sélectionnés, les phrases d'origine et leurs différentes paraphrases ont été présentées dans un ordre aléatoire aux deux évaluateurs ayant initialement travaillé sur l'autre moitié des corpus. Une interface sur le Web, illustrée sur la figure 2, permet alors aux évaluateurs d'indiquer quelles substitutions sont acceptables, à la fois au niveau de la conservation du sens et de la grammaticalité du nouvel énoncé.  F  2 - Exemple d'une phrase d'origine (sur fond vert) et de ses 5 paraphrases candidates (présentées dans un ordre aléatoire). Le segment en gras dans la phrase d'origine, est à l'origine, est ici paraphrasé par est le promoteur , a popularisé , origine , est à la source et l'origine.  La valeur d'accord inter-annotateur  sur l'ensemble des énoncés annotés est de  = 0, 65, ce qui correspond à un accord fort selon les grilles de Landis et Koch (1977). Nous pensons que le fait d'aborder tout d'abord des tâches relativement certaines du point de vue de l'accord entre humains comme celle-ci est nécessaire avant de s'attaquer à des problèmes plus complexes, tels que l'identification de paraphrases d'énoncés ou encore l'identification d'implications textuelles.  Notre technique de validation étant très dépendante de la fréquence des segments considérés  sur le Web, nous avons décidé dans ces premières expériences de ne conserver que les segments ayant une fréquence minimale de 10 occurrences pour le moteur de recherche utilisé. Le nombre d'exemples du corpus d'apprentissage a ainsi été réduit de 750(=150*5) à 434, et celui du corpus d'évaluation de 250(=50*5) à 215. L'atténuation de cette limitation devra bien évidemment faire partie de la suite de nos travaux.  Nous détaillerons nos résultats pour les 3 conditions suivantes :    Possibles : les exemples annotés comme &#34;paraphrases&#34; par au moins l'un des juges sont utilisés :  l'ensemble d'évaluation correspondant comprend 116 cas positifs et 99 cas négatifs.  Sûres : les exemples que les deux juges n'ont pas annotés comme "paraphrases" ou "non paraphrases" ne sont pas retenus : l'ensemble d'évaluation correspondant comprend 76 cas positifs et 139 cas négatifs.  Sûres++ : seuls les exemples pour lesquels les deux juges proposent la même annotation sont retenus. Ceci réduit nos ensembles d'apprentissage et d'évaluation à respectivement 287 et 175 exemples, ce qui ne permet pas une comparaison directe avec les deux autres conditions. L'ensemble d'évaluation correspondant comprend 76 cas positifs et 99 cas négatifs.  Nous présentons ici brièvement les techniques de référence auxquelles nous comparerons notre  système.  Fréquence sur le Web Les deux premières techniques sont fondées sur des calculs de fréquences  sur le Web. La première, ML_W considère un énoncé comme paraphrase d'un énoncé d'origine si son score de modèle de langue issu du Web est plus élevé que celui de l'énoncé d'origine. La deuxième technique, ML_F , considère qu'un énoncé est paraphrase d'un énoncé d'origine si la fréquence sur le Web des bigrammes traversant les frontières gauche et droite après substitution est supérieure à 10.  Conservation de dépendances syntaxiques Lors de la réécriture d'une partie d'un énoncé, la  conservation des dépendances syntaxiques entre un segment d'origine et son contexte d'une part, et sa paraphrase avec le même contexte d'autre part, peut renseigner sur la substituabilité grammaticale des deux segments (Zhao et al., 2007; Max et Zock, 2008). Nous avons calculé les dépendances syntaxiques pour les deux segments à l'aide de la version française (Candito et al., 2010) de l'analyseur probabiliste de Berkeley (Petrov et Klein, 2007). Nous considérons donc le sous-ensemble des dépendances qui existent entre les mots du segment d'origine et son contexte (Dep ) et entre les mots de la paraphrase et ce contexte (Dep ). Cette technique, D C , retient la paraphrase candidate si et seulement si Dep = Dep .  Nous avons utilisé un séparateur à vastes marges (SVM) avec les traits décrits dans la section 4  Les performances des différentes techniques sur les 3 conditions décrites précédemment sont données dans la figure 3.  ML_W  LM_F D C C P 62,79 54,88 48,53 57,67 S 68,37 36,27 51,90 70,69 S ++ 56,79 51,41 42,69 62,85  F  3 - Résultats de la performance de la classification (exactitude) pour les 3 techniques de référence et notre classifieur sur le corpus d'évaluation et les 3 conditions. Il convient de noter que la condition S ++ n'est pas directement comparable aux autres conditions puisque les tailles des corpus d'apprentissage et d'évaluation sont différentes à celles des deux autres conditions.  La première observation que nous pouvons faire est que la tâche de classification de paraphrases  est une tâche difficile : la meilleure performance (exactitude) obtenue par l'un des systèmes est de 70,69 pour la condition S . En outre, il existe une variation importante entre les différentes conditions testées avec un résultat faible pour notre classifieur de 57,67 dans la condition P (cas de désaccord entre annotateurs, où un seul reconnaît le statut de paraphrase).  D'une manière plus générale, la technique ML_W  et notre classifieur sont plus performants que les autres techniques de références. ML_F et D C ne modélisent que des contraintes grammaticales locales, ce qui fait qu'il n'est pas surprenant que ces informations ne permettent pas la reconnaissance de variations sémantiques licites entre paraphrases candidates. W LM, qui se limite à la comparaison de scores de modèles de langue dérivé du Web, apparaît donc comme une technique relativement compétitive , mais sa performance est peu élevée (56,79) pour la condition S ++. Puisque cette condition ne prend en compte que les annotations consensuelles pour l'apprentissage et l'évaluation, nous considérons cette condition comme la plus utile pour l'interprétation des résultats de ces travaux préliminaires. Ici, notre système obtient la meilleur performance, avec un avantage de 6,06 points par rapport à W LM. Ceci montre que la seule utilisation d'un modèle de langue, aussi bien estimé soit-il, est trop limitée pour rendre compte correctement de l'ensemble des phénomènes de paraphrases présents dans notre corpus d'évaluation, ce qui confirme des résultats précédents où les modèles de langue n'étaient pas issus de comptes du Web (Bannard et Callison-Burch, 2005).  Finalement, la figure 4 détaille les performances atteintes par chacune des méthodes d'acquisition  de paraphrases pour chacune des 3 conditions. Il n'est tout d'abord pas surprenant que les reformulations extraites de W C P C soient largement identifiées comme de bonnes paraphrases en contexte, en particulier dans les conditions P et S ++. Ces paraphrases sont le résultat de reformulations par des contributeurs de Wikipédia dans le contexte d'évaluation, et avaient déjà été reconnues comme telles par une première annotatrice.  W  C P C H P P P 89,33 67,00 47,33 20,66 S 64,00 44,50 31,33 10,66 S ++ 86,03 57,34 37,71 12,60  F  4 - Performance (valeurs d'exactitude) de nos différentes méthodes d'acquisition pour nos trois conditions d'évaluation. Les paraphrases obtenues par collecte manuelle sur des contextes issus du Web, donc d'un contexte possiblement différent de celui de l'évaluation, obtiennent une performance relativement acceptable. Les résultats confirment cependant le fait attendu que la substituabilité des paraphrases dépend fortement du contexte. Par exemple, la substitution du segment de l'éditeur par publiée par les éditions dans le contexte de l'énoncé &#34;Neopolis est une collection de bandes dessinées de l'éditeur Delcourt. &#34; permet de conserver le sens d'origine ainsi que la grammaticalité de l'énoncé. A contrario, la substitution par le segment du logiciel n'est pas adaptée à ce contexte.  Finalement, les paraphrases obtenues automatiquement par traduction par pivot ne sont pas  de bonne qualité. Nous notons cependant que la proximité de la langue pivot avec la langue de réécriture joue un rôle important : l'utilisation de l'espagnol mène ainsi à de bien meilleurs résultats que l'utilisation du chinois .  Nous avons présenté dans cet article une approche de paraphrasage en contexte appliqué à  la révision de texte, un scénario soutenu par les données extraites des réécritures contenues dans la Wikipédia francophone. La méthode d'identification que nous avons proposée prend en entrée un répertoire existant de paraphrases sous-phrastiques, et détermine par classification automatique exploitant des données issues du Web si les paraphrases connues peuvent se substituer à un segment dans un contexte particulier. Nous avons simulé différents niveaux de qualité pour les paraphrases existantes, en exploitant des paraphrases provenant de Wikipédia, des contributions humaines acquises dans d'autres contextes, et des paraphrases obtenues par traduction automatique par pivot.  Nos expériences ont montré que la version actuelle de notre classifieur est plus performante que  les différentes techniques de référence utilisées lorsque l'on ne considère que les paraphrases obtenant des jugements consensuels dans la référence utilisée. Bien que ces premières expériences soient positives, nous sommes conscients que leurs résultats peuvent être améliorés sur différents aspects. Tout d'abord, il est possible d'élargir l'exploration des différentes caractéristiques que nous mettons en jeu dans le classifieur. Nous comptons intégrer d'autres traits, dont des modèles mettant en jeu des dépendances syntaxiques calculées sur des données du Web. Nous allons également analyser plus finement nos résultats afin d'identifier les cas problématiques, dont certains ne peuvent pas être modélisés sans avoir recours à des connaissances du monde, ce qui suggérera notamment l'intégration de connaissances du domaine, éventuellement dérivées de méta-informations provenant des articles Wikipédia concernés. L'ensemble de ces expériences pourra être conduit en plusieurs langues, les données utilisées et les méthodes employées pouvant facilement être transposées. Finalement, nous sommes également intéressés par le fait d'utiliser l'approche décrite ici comme un cadre pour l'évaluation des systèmes d'acquisition de paraphrases.  
