La résolution de coréférence a pour objet de déterminer si deux séquences textuelles (par  exemple une entité nommée, un pronom, un syntagme nominal) font référence à une même entité sémantique (par exemple une personne ou un évènement). Le principe de résolution consiste à détecter au sein d'un texte des séquences intitulées mentions coréférentes et à les regrouper au sein de chaînes de coréférences. Cette tâche du TAL fait l'objet d'un ensemble de propositions algorithmiques récemment revisitées par deux campagnes d'évaluation CoNLL Shared Tasks proposées en 2011 et 2012. Ces campagnes ont démontré la prédominance des systèmes de résolution de co-référence par apprentissage automatique appliqués sur des paires candidates. Le système présenté dans cet article est une évolution de celui que nous avons présenté dans le cadre de notre participation à l'édition 2011 de cette campagne (Pradhan et al., 2011). Notre approche tente de définir un vecteur de traits d'apprentissage original reposant sur des informations issues d'un processus d'extraction d'information et d'analyse linguistique. Dans cette communication, nous complétons ces travaux antérieurs en intégrant un trait sémantique dans le vecteur d'apprentissage.  Cet article est organisé comme suit. Nous commentons l'état de l'art établi par les campagnes  CoNLL en section 2. Puis nous présentons notre système de détection de coréférences en section 3. Nous décrivons comment nous proposons d'enrichir son vecteur en lui adjoignant un trait de nature sémantique, c'est à dire définissant précisément l'identité de certaines des mentions candidates utilisées dans le processus de classification par paires. Cette amélioration induit une progression intéressante du système tel qu'évalué lors de la campagne CoNLL. Nous commentons les résultats de ce système modifié en section 4.1 puis nous concluons.  De nombreux systèmes fondés sur l'apprentissage automatique ont été proposés pour traiter  la résolution de coréférences. Les approches les plus récentes à base de réseaux logiques de Markov (MLNs) (Poon et Domingos, 2008), ou fondées sur une approche de partitionnement de graphe (Sapena et al., 2010) sont prometteuses et demeurent peu explorées. Le modèle de classification proposé par Soon (Soon et al., 2001) est prédominant et très largement implémenté. Dans cette approche, les mentions coréférentes potentielles, contenues dans un document d'entraînement, sont localisées via différents modules dits de détection de mentions. Les exemples d'entrainements sont ensuite générés sous la forme de vecteurs de traits qui représentent une paire de mentions potentiellement coréférentes.  En mode applicatif toutes les paires de mentions potentiellement coréférentes d'un document  sont soumises sous forme d'un vecteur au classifieur, qui valide ou non leur relation en donnant une réponse binaire ou probabilisée. Un processus d'assemblage, postérieur à la classification, regroupe ensuite au sein de chaînes toutes les mentions coréférentes. L'atout principal de la méthode de Soon est sa grande flexibilité : la réduction du problème de construction de chaînes de coréférences à la reconnaissance préalable de paires coréférentes laisse une grande latitude de conception de système. Cette approche rend aussi la méthode de Soon compatible avec des familles de classifieurs très variées : (Versley et al., 2008) a montré qu'un modèle de type SVM permet d'obtenir un système efficace et lors de la campagne CoNLL 2012, (Fernandes et al., 2012) a montré le potentiel d'un perceptron multicouche pour cette tâche.  Le contenu du vecteur de trait utilisé dans l'architecture de Soon offre également un champ  de recherche fertile : on a pu ainsi voir dans la proposition de (Stamborg et Medved, 2012) que des dépendances syntaxiques utilisées en tant que traits pouvaient offrir un bon niveau de performance. Certains travaux soulignent la souplesse de l'approche de Soon en ne retenant que le principe de ses paires et vecteurs de traits qu'ils associent non plus à des classifieurs, mais à des méthodes heuristiques. C'est le cas de la proposition de (Lee et al., 2011) qui a obtenu les meilleures performances lors de la campagne CoNLL 2011. Le principe est de remplacer l'apprentissage automatique et la classification par une approche incrémentale à base de règles pré-établies dites tamis. Au cours de 13 étapes successives, ces tamis trient les différentes paires de coréférences candidates et les assemblent au sein de chaînes. On notera que (Huang et al.,  F  1 - Architecture du système Poly-co.  2009) propose aussi de ne conserver que les paires de vecteurs de traits de l'architecture de Soon,  mais utilise un modèle MLN pour assembler les chaînes.  La qualité des détecteurs de mentions potentielles jouant un rôle essentiel dans le processus  de détection de coréférence (Lee et al., 2011), des efforts d'ingénierie importants sont nécessaires pour élaborer les composants d'un système complet. Notre système n'échappe pas a cette contrainte et une part importante de son implémentation concerne la détection des éléments textuels utilisés pour produire les vecteurs de traits. Nous avons choisi ici de conserver l'architecture de (Soon et al., 2001), alimentée par des vecteurs contenant de nombreux traits de degrés supérieurs. Le corpus Ontonotes (Pradhan et al., 2007) proposé pour entrainer et évaluer les systèmes de détection de coréférences contenant déjà de nombreuses informations telles que la relation syntaxique, la nature syntagmatique, les entités nommées (voir figure 2), nos efforts se sont concentrés sur l'ajout de propriétés évoluées (par exemple les similarités lexicales entre mentions ou les genres des mentions). L'architecture globale présentée dans la figure 1 contient deux parties, la première est dédiée à l'entrainement du système, la seconde à la résolution de coréférence avec un système entrainé.  Les traits des vecteurs de notre système reprennent directement depuis le corpus Ontonotes  les catégories morpho-syntaxiques, les syntagmes nominaux et les types d'entités nommées. Nous complétons ces traits en utilisant des modules supplémentaires pour la détection des genres et des nombres, évaluons la détection des alias entre mentions, les similarités entre mentions et introduisons une annotation sémantique. Cinq modules de préparation de vecteurs d'apprentissage sont intégrés à notre système : F 2 - Exemple de corpus Ontonotes avec en dernière colonne l'annotation sémantique.  1. Module de détection des mentions candidates, fondé sur des règles d'extraction utilisant  les annotations issues de Ontonotes. Il exploite ces annotations pour remplir certains traits (notamment syntaxiques).  2. Module de détection des alias entre entités nommées, qui fait intervenir une version  précédente du système Poly-co présentée dans (Charton et al., 2010). L'objectif de ce module est d'identifier les différentes variations lexicales d'une même entité en comparant des formes de surface.  3. Module de calcul de similarité, qui sert à mesurer la similarité de deux mentions en  comparant les chaînes de caractères qui leur sont associées.  4. Module de détection en genre et en nombre, détermine le genre et le nombre pour  toutes les mentions candidates à l'aide de la ressource fournie par (Bergsma, 2005).  5. Module de détection sémantique, détermine par un identifiant unique l'identité de l'objet  annoté. Nous évaluons l'influence de ce paramètre dans cette communication.  Lors de la phase d'entrainement, les modules de détection des mentions candidates et de  détection des alias sont remplacés par un seul module d'extraction des mentions candidates qui s'appuie directement sur les mentions coréférentes déjà annotées dans le corpus d'entrainement. On obtient ainsi pour entrainer le classifieur un ensemble de paires de mentions candidates positives dont on est certain de la qualité et que l'on complète par un ensemble de paires négatives sélectionnées aléatoirement (cet aspect est détaillé en section 3.3). On se reportera à (Charton et Gagnon, 2011) pour une définition plus précise des modules 1 à 4. Nous décrivons ci-dessous le paramètre sémantique que nous introduisons dans le système Poly-co.  3.1.1 Module de détection sémantique   Nous ajoutons au système Poly-co un trait dit sémantique. Ce trait consiste en une annotation  composée d'une URI vers DBPedia. Ce trait vient en complément des annotations fournies sur le corpus Ontonotes , tel que présenté dans la figure 2. Le protocole utilisé pour attribuer ces annotations consiste, pour chaque entité nommée candidate, à rechercher son lien correspondant en utilisant un annotateur sémantique . Les corpus d'apprentissage et de test sont traités avec cette méthode. Une correction des erreurs après étiquetage est réalisée visuellement sur le seul corpus d'apprentissage pour limiter l'influence des erreurs d'annotation sur le processus d'entrainement.  Ce lien unique attribué aux entités nommées (GPE, ORG, PERS,LOC, PROD) définit précisément  leur identité. Pour l'introduire dans le vecteur de trait sous forme de valeur numérique, nous  T  1 - Paramètres des vecteurs d'apprentissage. Les propriétés communes aux mentions A et B sont détaillées dans la section Propriétés de (A,B). Les traits de la mention A sont détaillés dans la section Référence A. Les traits de la mention B sont identiques à ceux de la mention A.  établissons un index de tous les liens sémantiques contenus dans le document dans lequel nous  cherchons les chaînes de coréférences et lui attribuons un numéro d'ordre (dans l'exemple de la figure 2, par exemple, le numéro 1 est attribué à Iraq et 2 à Georges Bush. La valeur 0 est attribuée en l'absence de liens.  Le vecteur d'entrainement du système Poly-co (voir tableau 1) est constitué de 24 traits qui  décrivent, conformément à l'architecture de Soon, une paire de mentions, (A,B), dans laquelle B est l'antécédent potentiel et A est l'anaphore. Les paramètres sont extraits en utilisant les différents modules de détection. Le rôle du classifieur est ici de fournir une réponse binaire ou probabilisée : A et B co-réfèrent ou non. Quatre paramètres définissent la paire (A,B) (section Propriétés de (A,B) du tableau 1) :  - IsAlias : il s'agit d'une variable binaire retournée par le module alias. La variable prend la  valeur vrai lorsque A et B sont identifiés comme décrivant la même entité. - IsSimilar : il s'agit du score de similarité calculée par le module de calcul de similarité. - Distance : cette valeur représente la distance, c'est-à-dire la différence entre les deux rangs occupées par A et B dans la liste des mentions candidates. - Sent : indique le nombre de marqueurs de fin de phrases (ex : « . ! ? ») qui séparent les mentions A et B.  Pour chacun des candidats A et B, un ensemble de neuf traits est ajouté au vecteur. Dans un  premier temps, trois variables binaires déterminent si la mention est une entité nommée (IsNE), s'il s'agit d'un pronom personnel (IsPRP) ou d'un syntagme nominal (IsNP). Ensuite, les variables ci-dessous définissent les caractéristiques d'une mention : - NE_S T est un des 18 types d'entité nommée prédéfini (P , O , T , etc). - P _ s'applique aux pronoms et correspond à une valeur numérique attribuée à chacun des 30 pronoms prédéterminés (ex. : my, she, it, etc). - NP_ est une valeur qui indique quel déterminant accompagne un syntagme nominal (par exemple, the, this, these, etc). - NP_ précise si un syntagme nominal est démonstratif, définitif ou quantificateur. - G et N indiquent, lorsque les valeurs sont connues, le genre de la mention parmi Masculin, Féminin ou Neutre et son nombre (Singulier or Pluriel). Lorsque les valeurs sont inconnues les variables prennent la valeur U. - S : la valeur du trait est définie selon les modalités présentées en section 3.1.1.  Une valeur null (ou 0) est utilisée lorsqu'il n'est pas nécessaire de définir une variable : par  exemple, la variable P _ est positionnée sur 0 lorsque la mention est une entité nommée. Pour entrainer le classifieur, nous utilisons l'algorithme suivant pour préparer les paires. Supposons que la liste des mentions candidates contient k mentions M , M , . . . , M , apparaissant dans cet ordre dans le document. L'algorithme commence par la dernière mention du document, c'est-à-dire M . Il compare de façon séquentielle M avec les mentions précédentes en remontant la liste et s'arrête lorsque (i) une mention en situation de coréférence M est trouvée (ii) il a traité un nombre maximum de n mentions (ici n est fixé à 10). Lorsqu'une mention coréférente M a été détectée, un vecteur est construit pour toutes les paires de mentions M , M  où M est une mention qui a été traitée. Ces vecteurs sont ajoutés à l'ensemble d'entraînement : M est considéré comme exemple positif et tous les autres sont considérés comme négatifs. Le processus est répété avec M , et ainsi de suite, jusqu'à ce que chaque mention soit traitée. Si aucune des n mentions précédentes n'a de lien de coréférence avec M , l'ensemble des n paires est écarté et n'est pas utilisé pour les données d'entraînement.  Pour l'application, le processus de détection de coréférence s'appuie sur un algorithme similaire.  La mention M est comparée aux n mentions précédentes jusqu'à ce que l'on en trouve une pour laquelle le modèle perceptron multi-couches retourne une probabilité supérieure au seuil de 0,5 (ou une valeur binaire dans le cas du classifieur SVM). Si aucun référent n'est trouvé dans la limite des n mentions, M est considérée comme une mention non coréférente. Une fois cette procédure appliquée à toutes les mentions d'un document, les coréférences détectées sont utilisées pour construire les chaînes de coréférences.  Le système complet d'annotation de coréférences Poly-Co  est entrainé sur le corpus d'entrainement Ontonotes sur lequel les annotations sémantiques complémentaires ont été apposées. Il est ensuite testé sur le corpus de développement gold dev-set. Le tableau 2 présente les résultats obtenus lors de ConLL 2011, sans que le classifieur n'exploite les traits sémantiques, le tableau 3 présente les résultats en intégrant les traits sémantiques. Notre système est entrainé avec  T  2 - Résultats du système, obtenus en appliquant différents classifieurs utilisant les mêmes vecteurs de paramètres sur les données « gold dev-set » du corpus Ontonotes.  T  3 - Résultats du système avec les traits sémantiques, obtenus en appliquant différents classifieurs sur les données « gold dev-set » du corpus Ontonotes.  trois types de classifieurs : perceptron multi-couches (MLP), SVM, arbres de décision (J48). Les  métriques d'évaluation retenues sont celles adoptées par la campagne ConLL 2011-12, à savoir une mesure de la capacité des systèmes à détecter des mentions d'une part (une simple F-Mesure est retenue), et une moyenne non pondérée des métriques B3, CEAF, et MUC.  Pour la phase d'évaluation de la campagne CoNLL ST 2011, nous avons retenu le modèle MLP qui  obtient les meilleures performances sur l'ensemble de données sans annotation sémantique. En raison des faibles différences entre les modèles MLP et J48 il était difficile de définir clairement lequel était le plus adapté avec le modèle de classification retenu. L'introduction de traits sémantiques améliore les performances du modèle Perceptron en regard des deux autres modèles de classification. On observe que l'utilisation d'un identifiant sémantique pour les entités nommées permet d'améliorer d'un point les capacités de détection de mentions du système : ceci s'explique par le fait que l'introduction de cet identifiant améliore la robustesse de classification lorsque les paires sont constituées d'entités nommées. Il en résulte moins de paires mal sélectionnées et donc une augmentation du nombre de mentions correctement détectées. De manière globale, l'introduction de traits sémantiques améliore les performances du classifieur.  Cet article présente Poly-co, un système de résolution de coréférence pour l'anglais, facile à  adapter à d'autres langues. La version initiale de Poly-co a été construite dans le cadre de la campagne d'évaluation CoNLL ST 2011. Le corpus d'évaluation proposé, Ontonotes, d'un haut niveau de complexité, nous a donné l'opportunité d'évaluer nos algorithmes de détection de mentions dans le cadre d'une tâche complète, regroupant des coréférences entre des entités nommées, des syntagmes nominaux et des pronoms. En introduisant de nouveaux traits sémantiques dans les vecteurs d'apprentissage, nous observons un gain global de performance et soulignons que notre approche à base perceptron multi-couches est une solution intéressante pour la reconnaissance de chaînes de coréférence.  
