En s'appuyant sur une expérience d'enrichissement terminologique, cet article montre comment  assister le travail d'acquisition terminologique et surmonter concrètement les deux difficultés qu'il présente : la masse de candidats-termes à considérer et la subjectivité des jugements terminologiques qui varient notamment en fonction du type de terminologie à produire. Nous proposons des stratégies simples pour filtrer a priori une partie du bruit des résultats des extracteurs et rendre ainsi la validation praticable pour des terminologues et nous démontrons leur efficacité sur un échantillon de candidats-termes proposés à la validation de deux spécialistes du domaine. Nous montrons également qu'en appliquant à une campagne de validation terminologique les mêmes principes méthodologiques que pour une campagne d'annotation, on peut contrôler la qualité des jugements de validation posés et de la terminologie qui en résulte. Help enrich a terminological repository : proposals and experiments  Based on an experience of terminological enrichment, this paper shows how to support the  work of terminological acquisition and overcome practical difficulties it presents, i.e. the mass of candidate terms to consider and the subjectivity of terminological judgments which depends on the type of terminology to produce. We propose simple strategies to filter a priori part of the noise from the results of term extractors so as to make the validation practicable for terminologists. We demonstrate their effectiveness on a sample of candidate terms proposed for the validation of two experts. We also show that by applying to term validation campaigns the methodological principles that have been proposed for corpus annotation campaigns, we can control the quality of validation judgments and of the resulting terminologies. Acquisition terminologique, validation de candidats-termes, filtrage de termes, distance terminologique, vote, accord inter-juges. Terminology acquisition, term candidate validation, term filtering, terminological distance, vote, inter-judge agreement.  Les ressources terminologiques, qu'elles soient monolingues, bilingues ou autres, sont utilisées  dans de nombreux outils de gestion de contenus spécialisés mais leur élaboration présente souvent un coût rédhibitoire. La mise à disposition de ressources ne résout que partiellement le problème car l'évolution des domaines et des besoins applicatifs rend nécessaires de fréquentes mises à jour. Des outils d'extraction terminologiques ont été développés depuis une vingtaine d'années (Jacquemin et Bourigault, 2003) pour automatiser les processus d'acquisition terminologique mais on sait que les extracteurs de termes ne peuvent fournir au mieux que des « candidats termes », que des mots ou groupes de mots qui, sur la base de propriétés syntaxiques, lexicales et statistiques, semblent avoir un comportement terminologique, c'est-à-dire avoir un sens précis et relativement stable au sein d'un domaine de spécialité. L'acquisition d'une terminologie pour un domaine particulier à l'aide d'outils d'analyse terminologique se heurte en fait à une double difficulté. La première concerne le filtrage et le retraitement des sorties d'analyseurs qui demandent à être validées par un terminologue si on vise une terminologie de qualité et consultable . Ce travail de validation peut s'avérer très fastidieux quand on utilise de gros corpus d'acquisition et que les extracteurs utilisés sont prolixes. La seconde difficulté est liée à la diversité des styles terminologiques : il existe des terminologies de taille très variable, même pour un même domaine ; la granularité de la description terminologique varie ; certaines terminologies recensent toutes les variantes des termes alors que d'autres ne listent que les termes canoniques ou « recommandés » ; dans une perspective d'annotation sémantique, on privilégie les termes longs, alors qu'on préférera des termes plus courts pour les tâches d'indexation. Le choix d'un style de terminologie n'est généralement pas guidé par les outils d'extraction terminologique mais il faut néanmoins en tenir compte dans le travail de validation.  En s'appuyant sur une expérience d'enrichissement terminologique menée en collaboration entre  l'INIST et le LIPN , cet article montre comment on peut concrètement surmonter ces deux difficultés et assister le travail d'acquisition terminologique. La section 2 présente le contexte dans lequel cette expérience a été menée puis nous montrons comment on peut filtrer a priori une partie du bruit des résultats des extracteurs pour rendre la tâche de validation accessible à des spécialistes du domaine (section 3) tout en contrôlant la qualité, ou du moins l'homogénéité, de ce travail (section 4).  La question de l'évolution des référentiels d'indexation est une question importante pour tout  organisme qui gère et maintient de tels référentiels. C'est en particulier le cas de l'INIST. A partir d'un thésaurus de pharmacologie utilisé comme référentiel d'indexation, deux questions se sont  F  1 - Extrait du référentiel terminologique  posées. Est-il possible d'assister la mise à jour de ce référentiel qui se faisait jusque là de manière  purement manuelle ? Est-il possible de construire à partir de ce thésaurus une terminologie adaptée à des tâches d'annotation sémantique ? Avec ces objectifs en tête, nous avons cherché à définir un protocole d'enrichissement terminologique qui tire le meilleur parti de l'expertise des terminologues et assure un travail de qualité.  Le référentiel terminologique Le référentiel est un thésaurus construit par l'INIST à des fins  d'indexation de la partie pharmacologique de la base de données bibliographiques PASCAL . Il contient 76 466 termes en anglais avec certaines variations et certaines relations hiérarchiques, et est accessible via TermSciences , le portail terminologique multidisciplinaire mis en place par l'INIST. Nous l'utilisons ici comme simple terminologie, sans tenir compte des relations terminologiques qu'il comporte. Un extrait est présenté sur la figure 1. Ce référentiel d'indexation privilégie les termes généraux du domaine de la pharmacologie au détriment des termes très spécifiques.  Les corpus d'acquisition Le processus d'extraction de termes repose sur l'existence de corpus  d'acquisition. Dans le cadre de cette expérience, deux corpus anglais ont été utilisés. Le premier (corpus CR) est constitué de résumés d'articles de pharmacologie de la base PASCAL, le genre de textes couramment utilisé par l'INIST pour l'indexation des articles scientifiques. Il comporte 1 500 000 mots. Le second corpus (CB) porte aussi sur la pharmacologie mais il est composé de textes différents. Il s'agit de brevets européens qu'il est prévu d'annoter sémantiquement dans le cadre du programme Quaero. Il comporte 2 500 000 mots.  Les extracteurs de termes Les extracteurs de termes utilisent différentes stratégies pour  extraire des candidats-termes. Certains comme YaTeA (Aubin et Hamon, 2006) ou Acabit (Daille, 2003) utilisent des patrons linguistiques, tandis que d'autres comme Termostat (Drouin, 2006) reposent sur l'analyse des contrastes entre un corpus de domaine général et un corpus de spécialité. Quasiment tous utilisent des filtrages statistiques avec des seuils plus ou moins tolérants afin de filtrer le bruit en fonction de l'objectif visé par l'extracteur (par exemple un petit nombre de candidats-termes potentiellement représentatifs, ou alors une couverture maximale). Nous avons observé une grande hétérogénéité dans le nombre de termes extraits sur un même corpus, certains extracteurs produisant 200 fois plus de termes que d'autres.  Dans cette expérience, nous avons utilisé les sorties des extracteurs testés lors de la campagne  Quæro (Mondary et al., 2012) . Les différentes stratégies d'extraction sont représentées. Dans l'ensemble, les extracteurs sont verbeux. Les corpus de résumés (CR) et de brevets (CB) ont permis respectivement d'extraire 321 124 et 303 648 candidats-termes. L'union des sorties des extracteurs sur les deux corpus donne un total de 570 608 candidats-termes différents. Certains de ces candidats-termes existaient déjà dans le référentiel de l'INIST mais un nombre significatif de nouveaux termes ont été proposés : 298 593 et 271 472 candidats-termes resp. pour CR et CB.  L'interface de validation L'objectif étant de valider les nouveaux termes extraits, une interface  de validation a été fournie aux experts de l'INIST. C'est une application web, qui est disponible sur Sourceforge. ValiTerms permet aux terminologues de visualiser les occurrences des candidatstermes à valider dans leur contexte (les phrases du corpus) et offre la possibilité de choisir pour chaque terme s'il est correct, incorrect ou douteux . Une zone de texte en face de chaque terme permet éventuellement d'indiquer la forme correcte attendue.  Il n'est pas raisonnable de demander à des experts de valider plusieurs centaines de milliers  de candidats-termes. Nous devons trouver des stratégies pour proposer à l'expert les candidatstermes les plus à même de l'intéresser.  Filtrer par le vote des systèmes Dans la mesure où nous disposions des sorties de plusieurs  extracteurs, nous avons proposé une première stratégie de filtrage consistant à donner en priorité à valider aux terminologues les termes retrouvés par plus de systèmes. C'est une technique de vote classique (Choi, 1999). L'intuition est que les candidats-termes retrouvés par plusieurs systèmes ont plus de chance d'être représentatifs que les candidats-termes retournés par un seul extracteur, même si un biais de cette approche conduit à éliminer les propositions faites par un extracteur qui serait plus original que les autres.  Nous avons récupéré la liste des candidats-termes absents de la référence et retrouvés sur chaque  corpus par exactement n extracteurs (n varie de 2 à 7 pour le corpus de brevets et de 2 à 4 pour le corpus des résumés qui n'a été traité que par quatre extracteurs). La distribution est présentée dans le tableau 1. Filtrer par la distance au référentiel Nous faisons également l'hypothèse que les candidatstermes proposés ont plus de chance d'être valides s'ils sont proches des termes du référentiel source. Nous avons testé cette hypothèse en utilisant la distance terminologique présentée dans (Zargayouna et Nazarenko, 2010) et implémentée dans l'outil Termometer . C'est une distance indépendante de la langue, qui se mesure sans faire appel à une quelconque ressource Retrouvés par exactement CB CR 7 systèmes 89 6 systèmes 363 5 systèmes 1 700 4 systèmes 12 164 3 439 3 systèmes 42 296 25 445 2 systèmes 137 114 74 576  T  1 - Distribution des candidats termes absents de la référence  linguistique et qui prend en compte la compositionnalité des termes en combinant une distance  sur les chaînes de caractères et une distance sur les mots.  Pour valider ces hypothèses, nous avons constitué un jeu de test de 3 000 candidats-termes à  valider (1 500 par corpus), en équilibrant les termes retrouvés par n systèmes exactement (avec n  2), en assurant la représentation des différents extracteurs et prenant des termes à la fois proches et éloignés de la référence selon la mesure de distance utilisée.  Nous avons donné ces 3 000 candidats-termes à valider à deux experts de l'INIST  . Les résultats globaux sont présentés dans le tableau 2. La première partie de ce tableau présente la proportion de termes jugés pertinents par les experts parmi les termes qu'ils ont eu à valider. La deuxième partie étudie les commentaires. Il a été demandé aux experts d'indiquer en commentaire la forme correcte des termes rejetés comme non pertinents. Les termes rejetés peuvent être mal formés ou mal orthographiés. D'autres sont des termes longs qui coordonnent plusieurs notions, dans ce cas l'expert devait indiquer le ou les sous-termes à retenir. Enfin, certains n'appartiennent pas au domaine. On constate qu'un terme, même s'il est jugé « non-pertinent », peut être intéressant à proposer à la validation parce qu'il suggère d'autres termes aux spécialistes du domaine. La dernière partie du tableau présente les termes à ajouter dans la terminologie destinée à l'annotation sémantique , cela correspond à l'union des termes pertinents et des termes des commentaires ne figurant pas dans le référentiel de départ.  L'analyse de ces résultats permet de confirmer nos deux hypothèse initiales.   Le vote des systèmes et le jugement des experts sont corrélés. L'histogramme de gauche sur la  figure 2 présente la proportion de termes pertinents parmi ceux qui sont retrouvés par exactement n systèmes pour les corpus de brevets (en bleu) et de résumés (en rouge). On observe que cette proportion décroît avec le nombre de systèmes . CB CR Termes à valider 1 500 1 500 Termes pertinents 263 (17,5%) 312 (20,8%) Termes non pertinents 1 237 (82,5%) 1 188 (79,2%) Termes avec un commentaire 664 (53,7%) 829 (69,8%) Termes proposés dans les commentaires 706 941 -> qui existent déjà dans la référence 422 547 -> qui n'existent pas dans la référence 284 394 Termes à ajouter au référentiel 547 (36,5%) 706 (47,1%)  T  2 - Résultats de la campagne d'enrichissement  F  2 - Corrélation du nombre de systèmes (à gauche) ou de la distance (à droite) avec les jugements de pertinence  La distance terminologique et le jugement des experts sont également corrélés. Le graphique  de droite sur la figure 2 montre que la proportion de termes pertinents (en ordonnée) décroît également quand la distance des termes avec ceux de la référence (abscisse) augmente. Plus les termes sont proches du référentiel (au sens de la distance terminologique), plus ils tendent à être jugés pertinents par les experts. Sur cet échantillon, si on n'avait retenu que les candidats-termes dont la distance est inférieure à 0,4, nous aurions retrouvé près de 75% de l'ensemble des termes pertinents et les experts auraient retenu près de la moitié des termes à valider comme pertinents. Les observations faites dans le cadre de cette expérience montrent que l'on peut filtrer efficacement les candidats-termes qui sont donnés à valider à des terminologues en exploitant les sorties de différents extracteurs et/ou en s'appuyant sur une terminologie source. Le but est de donner des listes suffisamment filtrées pour que le travail de validation ne soit pas trop fastidieux et que les termes pertinents ne soient pas noyés sous le bruit. Nous considérons que juger 1 terme pertinent sur 3 constitue une tâche de validation raisonnable, d'autant que les termes rejetés en suggèrent souvent d'autres plus pertinents. Phase 1 Phase 2 Phase 1 Phase 2 Percent Agreement 80% 88,4% N Accords 200 221 Pi de Scott 0,531 0,751 N Désaccords 50 29 Kappa de Cohen 0,532 0,752  T  3 - Évolution des accords inter-annotateurs  Une fois que la liste de candidats-termes à valider par les experts est constituée (à l'aide des  stratégies de filtrage présentées dans la section précédente) peut débuter la phase de validation manuelle. La principale difficulté que soulève cette phase tient à la subjectivité des jugements de pertinence des experts du domaine qui est elle-même liée à leur compréhension de l'application visée et du type de terminologie que l'on cherche à construire. Par exemple un terme long comme aerosol of stable radioactive nanoparticle semble bien formé mais est-il pertinent pour enrichir le référentiel d'indexation, et si ce n'est pas le cas quel sous-terme privilégier ? aerosol, radioactive nanoparticle ou stable nanoparticle ? Pour contrôler la subjectivité des jugements, nous proposons, en nous inspirant de la méthodologie proposée par (Fort, 2012) pour l'annotation de corpus, de mettre en place une phase de pré-campagne de validation et de calculer les accords inter-juges tout au long du processus de validation. La phase de pré-campagne permet de mettre à jour un guide de validation qui fixe les consignes de validation et l'esprit dans lequel cette validation doit être faite, jusqu'à ce que les accords deviennent satisfaisants. Une fois le niveau de qualité requis atteint, la validation à grande échelle peut se faire. Pour les campagnes de grande envergure, il est probablement souhaitable de re-mesurer également à intervalle régulier les accords intra et inter-juges pour s'assurer que le processus de validation ne dévie pas. Nous avons proposé aux deux experts de l'INIST de valider en double aveugle 250 candidatstermes choisis aléatoirement dans notre échantillon de 3 000. Nous avons ensuite calculé les accords entre leurs jugements (première colonne du tableau 3). Comme ces valeurs étaient basses, nous avons analysé en détail les cas de désaccords dans les jugements et les commentaires. Les problèmes rencontrés étaient majoritairement dus à des questions de découpage des termes longs (par exemple corosolic acid content of banaba extract doit être découpé en corosolic acid, banaba et extract), mais aussi de généricité des termes (review paper est incorrect car trop générique tandis que retrospective study est correct car important en épidémiologie) et de termes hors du domaine du référentiel (hydroxyglitazone). Certains cas étaient vraiment problématiques comme streptozotocin qui est non pertinent (composé chimique servant à induire une pathologie expérimentale), tandis que streptozotocin induced diabetes est pertinent (pathologie expérimentale induite par le composé chimique). Cette analyse a permis de spécifier clairement les consignes dans le guide de validation, en dissociant notamment les objectifs d'enrichissement du référentiel d'indexation et de création d'une terminologie pour l'annotation de corpus. Cette clarification a permis d'améliorer les accords sur un nouveau jeu de 250 termes validés en double aveugle (deuxième colonne du tableau 3). A partir de là, les experts ont pu valider des 2 500 candidats termes restants. Cette expérience montre qu'en procédant avec méthode, on peut contrôler la subjectivité des jugements de validation et ainsi obtenir une terminologie de bonne qualité à partir des extracteurs de termes.  Cet article propose une méthodologie permettant d'exploiter les sorties d'extracteurs de termes  pour construire ou enrichir des terminologies à un coût et avec une qualité raisonnables. On ne peut pas se contenter de donner des listes de candidats-termes à valider aux terminologues. Cela s'apparente à chercher un terme pertinent un peu à l'aveuglette dans un amas de termes bruités : le travail de validation ne peut être de bonne qualité, l'attention se relâche, les critères deviennent flous, les objectifs sont perdus de vue.  Nous avons montré qu'on peut cependant adopter des stratégies simples pour filtrer a priori le  gros du bruit dans les listes de candidats-termes en faisant voter plusieurs extracteurs de termes et/ou en mesurant la distance des termes proposés à ceux d'une terminologie de référence prise comme point de départ. Il reste à voir comment ces deux critères peuvent être combinés pour exploiter au mieux l'expertise humaine lors de la validation.  Nous avons montré par ailleurs qu'un protocole de validation clair, avec un guide de validation  et le contrôle des accords inter-juges, permet d'atteindre une bonne stabilité de validation, seule garantie de la qualité des jugements humains qui sont ainsi posés.  
