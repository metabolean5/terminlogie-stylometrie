Pour être complet, il aurait fallu indiquer dans le nom de notre lexique qu'il est issu du Wiktionnaire, un très gros dictionnaire en ligne qui comporte plus de 2 millions d'entrées. À titre de comparaison, la nomenclature du Trésor de la Langue Française (TLF) contient environ 65 000 vedettes et 100 000 entrées (principales ou secondaires). À la taille du Wiktionnaire s'ajoute la grande variété de ses descriptions avec, outre les définitions, des informations relatives à la prononciation, aux formes fléchies, aux dérivés et aux membres de la famille morphologique, aux traductions, aux synonymes, antonymes, hyponymes, hyperonymes, etc. Ces informations paraissent répondre à une grande variété de besoins et être d'une qualité notable pour l'édition française. Notre projet est de permettre au TAL et plus généralement aux linguistes expérimentaux d'exploiter facilement cette ressource multi-usages, d'une richesse remarquable. Une première exploitation du Wiktionnaire avait conduit à WiktionaryX (Sajous et al., 2010, 2011), un lexique structuré donnant accès, pour chaque entrée, à des informations de nature sémantique : définitions, synonymes, hyponymes, traductions dans d'autres langues, etc. Avec GLÀFF , nous proposons une étape supplémentaire dont le but est de permettre l'exploitation des informations phonologiques et morphosyntaxiques. Outre sa taille et sa polyvalence, GLÀFF se caractérise par sa licence libre (Creative Commons By-SA). L'un des objectifs de ce travail est d'estimer la qualité de la ressource, sa couverture et son adéquation aux besoins des linguistes qui réalisent des expérimentations et/ou des modélisations, mais aussi des chercheurs et des développeurs de systèmes de TAL.  La suite de l'article s'organise comme suit : nous présentons dans la section 2 quelques-unes  des ressources auxquelles GLÀFF peut être comparé. La section 3 présente le Wiktionnaire et différents travaux visant à construire à partir de ce dictionnaire des ressources pour le TAL. La construction de GLÀFF proprement dite fait l'objet de la section 4. Nous présentons en section 5 une série de comparaisons de GLÀFF avec des ressources de référence afin de quantifier les points forts et les apports de ce lexique. Plus précisément, nous nous intéressons à la couverture de GLÀFF en le comparant d'une part à quatre autres lexiques morphosyntaxiques disponibles du français, et en le projetant d'autre part sur différents corpus afin, notamment, de déterminer la proportion d'entrées attestées et non attestées. Nous comparons ensuite les descriptions phonémiques de GLÀFF avec celles de deux ressources qui en fournissent. Enfin, la section 6 conclut l'article et présente les étapes à venir dans le développement et l'exploitation de GLÀFF.  Des ressources lexicales pour le français commencent à être disponibles, même s'il reste beaucoup  à faire pour nous rapprocher de la situation de l'anglais, tant en volume qu'en qualité. Le constat est similaire pour les outils généralistes comme les analyseurs morphosyntaxiques, syntaxiques, morphologiques et les outils de phonétisation, qui dépendent directement de ces ressources. Depuis la fin des années 1990, quelques ressources destinées au traitement automatique du français sont distribuées gratuitement : le lexique de l'ABU date de 1999, la première version de Lefff (Clément et al., 2004) de 2003 et Morphalou (Romary et al., 2004) de 2004. Auparavant, seules des ressources payantes, principalement distribuées par ELRA, étaient disponibles.  La constitution de lexiques pour le TAL et pour l'étude outillée du français trouve son origine  dans les travaux menés au LADL autour de Maurice Gross (Courtois, 1990; Silberztein, 1990). Les premiers étaient destinés à l'exploration de corpus et l'annotation lexicale. Les lexiques morphosyntaxiques du français fournissent tous un ensemble d'informations communes : la forme orthographique du mot, son lemme, la partie du discours et les propriétés morphosyntaxiques (traits flexionnels). Notons que si ces ressources ont été d'abord utilisées pour le TAL, elles le sont aussi pour la description linguistique, notamment en morphologie (Hathout et al., 2009).  ABU, le plus ancien des lexiques morphosyntaxiques distribué librement sur le Web, comporte  environ 60 000 lemmes et 300 000 formes. Les tailles de Lefff et de Morphalou sont plus importantes : respectivement 500 000 et 525 000 entrées. Notons que Lefff fournit également une description des cadres de sous-catégorisation des lexèmes. À côté des ressources développées par des linguistes informaticiens (Lefff sert notamment à la mise au point d'analyseurs syntaxiques basés sur la théorie LFG) et des lexicographes (Morphalou est la version XML du lexique TLFnome, issu de la nomenclature du TLF), on trouve Lexique (New, 2006), qui s'inscrit dans la lignée de Brulex, une ressource développée à la fin des années 1980 (Content et al., 1990). Comme Brulex, Lexique a été créé par et pour les psycholinguistes. Ces ressources se distinguent des lexiques morphosyntaxiques généralistes par la plus grande richesse des informations fournies : outre la morphosyntaxe, leur description lexicale comporte une transcription phonémique, une segmentation en syllabes, des informations sur les homophones, les homographes, les voisins phonologiques et orthographiques, la fréquence des formes dans des corpus écrits, etc. En contrepartie, l'absence d'un grand nombre des formes fléchies de Lexique, tout comme Brulex (seules les formes les plus usuelles y sont décrites) et les fréquences fournies, calculées à partir des graphies (qui ne tiennent donc pas compte des attributs morphosyntaxiques) constituent une limite à leur utilisation dans des outils de TAL. Lexique et Brulex sont actuellement les seules ressources gratuites qui fournissent des transcriptions phonémiques et un découpage syllabique. Il existe d'autres ressources plus complètes qui contiennent ces informations, créées dans des laboratoires de recherche publique. . . mais elles sont payantes . L'une des plus anciennes et la plus connue est BDLex (Pérennou et de Calmès, 1987), dont la taille est similaire à celle de Lefff. Citons également ILPho (Boula De Mareuil et al., 2000), plus récente, créée en complétant les entrées du lexique morphosyntaxique Multext (Ide et Véronis, 1994) par des transcriptions phonémiques. Dans tous ces lexiques, les transcriptions phonémiques sont codées au moyen de caractères ASCII, en SAMPA ou dans un format similaire. Wiktionary, le « compagnon lexical de Wikipédia », est un dictionnaire multilingue libre et accessible en ligne. Lancé en 2003, ce projet lexicographique fait état, 10 ans plus tard, de plus de deux millions d'articles pour son édition française, le Wiktionnaire. Si son remplissage a bénéficié de l'import d'articles du Dictionnaire de l'Académie Française et, dans une moindre mesure, du Littré, le Wiktionnaire connaît aujourd'hui une croissance constante grâce à l'édition manuelle des contributeurs. Chaque article peut contenir des informations étymologiques, définitions, exemples, relations sémantiques, traductions, transcriptions phonémiques, etc. Si l'on considère la couverture moindre des ressources lexicales existantes et les licences contraignantes sous lesquelles sont placées certaines d'entre elles, la variété des informations contenues dans le Wiktionnaire, la taille de sa nomenclature et sa mise à disposition sous licence libre en font un candidat extrêmement prometteur pour la construction d'un lexique électronique du français. Néanmoins, depuis l'émergence du crowdsourcing, se pose la question de la qualité des informations contenues dans les wikis. L'absence de comité éditorial et le fait que les modifications de tout contributeur, quelle que soit sa compétence, soient publiées immédiatement génèrent une certaine méfiance. À l'opposé, l'effet de mode lié à la naissance de nouveaux paradigmes peut générer un enthousiasme par trop optimiste (cf. la polémique portant sur la qualité de Wikipédia, opposant (Giles, 2005) à l'encyclopédie Britannica (Encyclopaedia Britannica, 2006)).  Si Wikipédia a fait l'objet d'analyses dans plusieurs disciplines et a servi en TAL de source de  données pour constituer notamment des corpus et des listes d'entités nommées, ainsi que de base de calcul de similarité sémantique entre documents (Gabrilovich et Markovitch, 2007), Wiktionary n'a commencé à retenir l'attention des chercheurs, à notre connaissance, qu'en 2008. Il a d'abord été utilisé par (Zesch et al., 2008), comme Wikipédia, comme point de départ pour effectuer des calculs de similarité sémantique. La qualité des ressources construites collaborativement « par les foules » et celles construites par les experts a été comparée par (Zesch et Gurevych, 2010), toujours à travers une tâche de mesure de similarité sémantique fondée sur Wikipédia et Wiktionary. Cette étude, plus modérée que celle de Giles, a montré que les ressources fondées sur « la sagesse des foules » ne sont pas meilleures que celles fondées sur « la sagesse des linguistes », mais sont sérieusement compétitives. Elles dépassent même les ressources construites par les experts dans certains cas, notamment en terme de couverture. Cependant, l'étude portait sur l'utilisation de données dérivées de Wiktionary et non sur son contenu primaire.  Le potentiel du Wiktionnaire en tant que lexique électronique n'a été étudié qu'à partir de 2009  par (Navarro et al., 2009) pour le français et l'anglais.L'intégration de l'édition portugaise de Wiktionary dans l'ontologie Onto.PT (Gonçalo Oliveira et Gomes, 2010) est décrite dans (Anton Pérez et al., 2011). Citons également Dbnary (Sérasset, 2012), une ressource et un extracteur open source visant à extraire de Wiktionary un réseau multilingue. L'auteur précise que ce travail ne vise pas l'exhaustivité mais la conception d'un modèle simple permettant de représenter autant de données qu'il est possible d'extraire correctement, laissant de côté certaines structures pour faciliter cette extraction. Le graphe extrait possède 260 467 entrées pour le français. Le laboratoire UKP distribue deux ressources issues de Wiktionary : OntoWiktionary (Meyer et Gurevych, 2012), une ontologie construite semi-automatiquement et UBY (Gurevych et al., 2012), un alignement de 7 ressources lexicales incluant notamment WordNet, disponible pour l'allemand et l'anglais. Si la version allemande de Wiktionary semble être celle qui bénéficie de l'encodage le plus rigoureux et le plus systématique (par exemple, l'alignement avec d'autres ressources est permis par l'ancrage des relations sémantiques au niveau des sens, ce qui n'est pas le cas dans les éditions française et anglaise), la version française, moins aisément exploitable, se distingue par une plus grande nomenclature, ainsi que la présence quasi-systématique d'informations flexionnelles et phonémiques. Nous avons mis à disposition pour le français et l'anglais une version structurée au format XML de ce lexique. Nous présentons dans la section suivante l'extraction des informations phonémiques et morphosyntaxiques absentes de cette première version.  Pour chaque édition de langue, une mise à disposition régulière de l'ensemble des articles de  Wiktionary est effectuée dans des fichiers appelés XML dumps . Il ne faut pas interpréter la mention « XML » comme la structuration du contenu des articles par des balises qui délimiteraient les sections relatives aux catégories syntaxiques, relations sémantiques, traductions, etc. Les balises XML ne servent qu'à délimiter les articles et leur titre. Le reste du contenu est encodé dans un format appelé wikicode, inhérent au système de gestion de contenu MediaWiki. La syntaxe de ce format n'a jamais été définie formellement et, de plus, évolue dans le temps, avec coexistence de plusieurs conventions d'encodage pour un même type d'information. Il faut également mentionner que ni les conventions d'organisation des articles, ni leur encodage en wikicode n'est stable d'une édition de langue à l'autre. Nous montrons dans (Navarro et al., 2009; Sajous et al., 2010, 2011) comment ce format lâche rend ardue et constamment inachevée l'écriture d'un parseur pour extraire de manière automatique et exhaustive les informations de Wiktionary : entre la mise à disposition de deux dumps, le wikicode évolue sans que le changement ne soit nécessairement documenté et seule l'observation (semi-)manuelle du format d'encodage permet d'adapter le parseur en conséquence. Nous avons concentré notre effort dans le travail présenté ici sur l'extraction des informations absentes de WiktionaryX : les informations flexionnelles et les transcriptions phonémiques. La figure 1 montre un extrait de l'article « affluent », tel qu'on peut le consulter dans le Wiktionnaire, deux de ses formes fléchies et le wikicode correspondant . Le tableau qui recense les formes fléchies de l'adjectif, par exemple (en haut à droite de la figure 1a), n'est pas explicitement présent dans le wikicode, mais il est généré par le patron . Il existe ainsi des dizaines de patrons similaires dans le wikicode. L'extraction des formes fléchies et des prononciations correspondantes se fait soit par recensement et « émulation » de ces patrons (ici, génération des formes fléchies à partir d'un schéma spécifié), soit par l'analyse des articles des formes fléchies lorsqu'ils existent (cf. fig. 1c et 1d). Là encore, aucun formatage n'est systématique : le patron (fig. 1c) indique que la forme est de genre féminin ; le nombre doit être extrait du texte de la ligne suivante « Féminin singulier ». Si la prononciation de affluente est donnée dans la « ligne de forme », celle de affluentes est donnée dans une section Prononciation dédiée. Des erreurs induites par l'hétérogénéité du wikicode peuvent de ce fait s'ajouter aux erreurs contenues dans les articles du Wiktionnaire et ainsi impacter la ressource finale.  Notre parseur extrait du dump du Wiktionnaire les formes graphiques et leurs lemmes, convertit  leurs catégories morphosyntaxiques au format GRACE (Rajman et al., 1997) et extrait leurs transcriptions phonémiques, déjà en API. Notons qu'une même entrée peut avoir plusieurs transcriptions, comme abricots, dont on trouve une prononciation avec un « o » ouvert et une autre avec un « o » fermé : /a.bKi.kO/ et /a.bKi.ko/ . Dans ce cas, toutes sont conservées. Les informations flexionnelles présentes dans le Wiktionnaire sont parfois partielles. Il est en effet courant que seul le genre ou le nombre soit indiqué pour les noms et les adjectifs. De même, le temps ou le mode d'une forme verbale fléchie peut être omis. Nous appliquons des règles pour tenter de compléter ces informations : une forme nominale ou adjectivale ne portant pas de terminaison -s ou -x, par exemple, sera considérée comme étant au singulier ; le genre et le nombre d'un participe passé peuvent être inférés par sa terminaison ; une forme fléchie nominale ou adjectivale masculine, dont on a déjà rencontré le lemme masculin singulier, est plurielle ; etc. Les 9,5% d'entrées dont l'information flexionnelle reste partielle sont écartées de la ressource. Dans cette première version de GLÀFF, dont un extrait est donné figure 2, ne sont inclus que les noms communs, verbes, adjectifs et adverbes (lemmes et formes fléchies). Les mots grammaticaux et locutions y seront intégrés dans les versions ultérieures. En complément du dump dont elles sont absentes, nous avons « aspiré » du site du Wiktionnaire, puis analysé, les tables de conjugaison de 18 076 verbes. Ces tables générées à partir d'un simple modèle (e.g. pour le verbe marcher ) permettent d'obtenir les 48 flexions d'un verbe (nous n'intégrons pas les temps composés dans GLÀFF).  La suite de l'article est consacrée à la caractérisation essentiellement quantitative de GLÀFF. Elle  vise à apporter des éléments de réponse aux questions suivantes : que contient GLÀFF ? Quel est l'apport de GLÀFF relativement aux ressources similaires existantes ? GLÀFF est-il une ressource susceptible de remplacer les lexiques morphosyntaxiques et phonologiques courants ? Cette caractérisation porte sur différents attributs : nombre de lemmes et de formes, couverture relativement à différents corpus et transcriptions phonémiques. Nous comparons GLÀFF à quatre  F  1 - Article « affluent » et formes fléchies dans le Wiktionnaire. F 2 - Extraits de GLÀFF lexiques utilisés dans de nombreuses recherches : Lexique, BDLex, Morphalou et Lefff. Tous fournissent des descriptions morphosyntaxiques complètes pour leurs entrées, les deux premiers fournissant en plus des transcriptions phonémiques et une segmentation en syllabes. Couverture. GLÀFF se distingue des lexiques actuellement utilisés en TAL et en psycholinguistique par sa taille exceptionnelle. La table 1 présente le nombre de lemmes et de formes fléchies, simples (séquence de lettres exclusivement) et non simples (i.e. comprenant espace, tiret et/ou chiffre). On peut y observer que GLÀFF contient 3 à 4 fois plus de lexèmes (2 fois plus pour les lemmes qui comportent une transcription phonémique) et 3 à 9 fois plus de formes (2 à 8 fois pour les formes transcrites). Cette taille est un atout important dans le cas d'une utilisation, par exemple, pour des recherches en morphologie flexionnelle ou dérivationnelle. Elle est également intéressante pour le développement d'outils de TAL comme des étiqueteurs morphosyntaxiques ou des analyseurs syntaxiques. On observe également que GLÀFF comporte un nombre élevé de formes composées. Ces dernières servent essentiellement à la segmentation des textes en « tokens » dont la qualité impacte l'ensemble des annotations catégorielles et syntaxiques ultérieures.  T  1 - Taille des lexiques (restreints aux catégories : nom commun, verbe, adjectif, adverbe).  Les comparaisons ci-après concernent uniquement les catégories majeures nom commun, verbe,  adjectif et adverbe. Elles ont été réalisées sur les formes graphiques ou lemmes « simples » afin de nous affranchir des différents choix de graphie des unités polylexicales dans les lexiques et de segmentation des corpus. Nous étudions tout d'abord l'intersection de GLÀFF avec les autres lexiques. La table 2 présente pour chacun des cinq lexiques testés la proportion d'entrées (i.e. de triplets ) que l'on retrouve à l'identique dans les autres. On observe que la taille des intersections est directement liée à celle des lexiques : plus un lexique est gros, plus son intersection avec les autres l'est. On observe ensuite une répartition des cinq lexiques en trois groupes : Lexique a une couverture moindre, avec 9% de GLÀFF et 22 à 26% des lexiques BDLex, Lefff et Morphalou. Ces trois derniers couvrent 76% à 80% de Lexique et 30% de GLÀFF en moyenne, tout en ayant un couverture commune de 70% à 86%. GLÀFF est nettement au-dessus avec un couverture de 85% à 93%. Sa couverture est supérieure de 5% à 13% à celle des autres lexiques. De plus, le fait qu'il n'inclue que partiellement les autres lexiques est normal au vu des intersections de ces derniers.  T  2 - Couverture inter-lexiques (en % de formes fléchies catégorisées). GLÀFF a donc une taille nettement supérieure à celle des autres lexiques, ce qui constitue un atout potentiel. Afin de s'assurer que cet avantage est effectif (i.e. que le plus grand nombre de lexèmes et de formes peut réellement s'avérer utile), nous avons comparé les cinq lexiques au vocabulaire de quatre corpus de nature différente (genre, taille, époque, etc.). Le premier, composé de 515 romans du siècle issus de la base Frantext , contient 30 millions de mots. LM10, corpus journalistique qui rassemble les archives de 1991 à 2000 du quotidien Le Monde, contient 200 millions de mots. Le troisième corpus composé des 664 982 articles de la Wikipédia française , contient 260 millions de mots. Enfin, FrWaC (Baroni et al., 2009) est un corpus de pages Web en français contenant 1,6 milliard de mots. Ces quatre corpus ont été étiquetés par la version standard de TreeTagger , qui nous sert ici à segmenter les corpus et filtrer leur vocabulaire sur la base des catégories syntaxiques (qui sont ensuite ignorées). Les mots inconnus de TreeTagger (dont la catégorie est pertinente) sont conservés. La table 3 présente la couverture des cinq lexiques par rapport à ces quatre corpus, en distinguant au sein de leur vocabulaire les formes de fréquence supérieure ou égale à 1 (i.e. tout le vocabulaire), 2, 5, 10, 100 et 1000.  T  3 - Couverture lexiques/corpus (en % de formes fléchies non catégorisées).  Le classement des corpus par couverture décroissante est le même pour les cinq lexiques. Bien  que la taille des corpus influe sur cet ordre (plus un corpus est étendu, plus le nombre potentiel de formes différentes est grand), leur nature est également déterminante : FrWaC, par exemple, est une collection de pages web et (donc) contient nombre de formes « bruitées » (mots étrangers, espaces manquants ou excédentaires, orthographe aléatoire, absence de diacritiques, etc.). On retrouve la répartition des lexiques en trois groupes : BDLex, Lefff et Morphalou présentent une couverture assez proche. Hormis pour Frantext, Lexique affiche une couverture moindre jusqu'au seuil 100, où il rejoint Morphalou. GLÀFF a une couverture supérieure pour les trois plus gros corpus, sauf pour LM10 au seuil 1000 où il est dépassé par Lefff de 0,2%. La meilleure couverture de Lexique pour Frantext, alors qu'elle est inférieure de 10 à 15% à celle de GLÀFF pour les trois autre corpus, s'explique probablement par le fait que son vocabulaire a été constitué à partir d'oeuvres de cette même base. Pour les autres corpus et jusqu'au seuil 100, la taille de GLÀFF lui permet d'avoir une couverture du vocabulaire bien supérieure à celle des autres lexiques (au seuil 1, de 14% à 53% de plus pour LM10 et de 30% à 125% pour FrWaC ; au seuil 10, de 4% à 16% pour LM10 et de 15% à 47% pour FrWaC). Des outils de TAL qui intégreraient GLÀFF devraient donc améliorer leurs performances dans le traitement de ces corpus.  La figure 3 compare la couverture des cinq lexiques sous un autre éclairage : elle représente pour  chaque lexique le nombre de formes dont la fréquence en corpus appartient à un intervalle donné. On y voit clairement que les différences sont plus marquées pour le corpus FrWaC qu'elle ne le sont pour Frantext, probablement du fait des différences liées à la nature des corpus, comme expliqué plus haut. La répartition des lexiques en trois groupes apparaît clairement dans le diagramme de droite (FrWaC). On voit également sur ce dernier que même pour les mots très fréquents et donc très bien attestés, qui ont par exemple une fréquence comprise entre 101 et 1000, la couverture de GLÀFF reste meilleure. La table 3 et la figure 3 montrent que la supériorité de GLÀFF est plus marquée lorsque l'on travaille sur des corpus hétérogènes et pour des mots de faibles et moyennes fréquences. F 3 - Répartition des formes des lexiques relativement à leur fréquence en corpus.  Pour conclure notre caractérisation de la couverture de GLÀFF, nous nous sommes intéressés à la  partie du vocabulaire spécifique à ce dernier, i.e. aux formes appartenant à GLÀFF et absentes des quatre autres lexiques. Ce sous-ensemble de 665 290 formes représente 47% de la ressource. Nous avons également considéré le vocabulaire spécifique de chaque autre lexique. La table 4 montre pour chaque sous-vocabulaire le nombre de formes attestées en corpus. Conformément à l'intuition, le nombre de formes attestées est d'autant plus grand que les corpus sont gros. La taille des corpus n'explique cependant pas tout : si une large part du vocabulaire spécifique à GLÀFF n'est attestée dans aucun corpus (il s'agit majoritairement de verbes pour lesquelles toutes les flexions possibles sont générées), sa taille permet une meilleure couverture de corpus hétérogènes tel que FrWaC incluant un français potentiellement moins normé et plus récent. Même pour un corpus journalistique dont l'année la plus récente est 2000, la jeunesse, mais également la mise à jour constante du Wiktionnaire permettent à GLÀFF de couvrir des mots tout à fait usuels comme : transversalité, attractivité, brevetabilité, diabolisation, employabilité, anticorruption, homophobie, institutionnellement, hébergeur, fatwa, indétrônable, etc., toujours absents des autres lexiques après 13 années.  T  4 - Attestation en corpus du vocabulaire spécifique de chaque lexique  Transcriptions phonémiques. GLÀFF contient, pour 90% de ses entrées, une transcription  phonémique. Ces transcriptions contiennent parfois (8% des cas) plusieurs variantes. Afin d'évaluer leur qualité, nous les avons comparées à celles de BDLex et Lexique, que nous avons converties en API. Nous avons comparé d'une part les transcriptions sans tenir compte de la syllabation, puis nous avons comparé la syllabation pour les transcriptions dont les suites de phonèmes sont strictement identiques. Nous avons relevé, pour les transcriptions qui ne diffèrent que par un phonème, les oppositions en cause. La table 5 montre pour chaque couple de lexiques les 10 oppositions les plus fréquentes et la table 6 donne des exemples illustrant ces oppositions. Cette table est complétée, dans la dernière colonne, par les transcriptions du Dictionnaire de la Prononciation Française dans son Usage Réel (Martinet et Walter, 1973), noté DPF ci-après. Les auteurs de ce dictionnaire papier élaboré entre 1968 et 1973, partant du principe que « l'unité de la prononciation française est une vue de l'esprit et ne correspond à rien de réel » ont mené, avec leurs collaborateurs, un travail de recensement auprès de 17 informateurs pour collecter les différentes variantes de prononciation d'un même mot (20% des prononciations divergent). Les différences de transcription entre GLÀFF et chacun des deux autres lexiques sont comparables aux différences que l'on trouve entre BDlex et Lexique. Elles sont principalement dues à l'opposition entre les voyelles moyennes, comme les antérieures : [e] (mi-fermée) vs. [E] (mi-ouverte), et les postérieures : [o] (mi-fermée) vs. [O] (mi-ouverte). Entre BDLex et Lexique, elles sont responsables de 91% des divergences. Ces différences étaient attendues : l'opposition entre voyelles mi-fermeés et mi-ouvertes en français est soumise à des restrictions distributionnelles définies par la loi de position selon laquelle les voyelles mi-ouvertes apparaissent de préférence en syllabe fermée, alors que les voyelles mi-fermées apparaissent de préférence en syllabe ouverte. Bien qu'une investigation détaillée sur les structures syllabiques reste à faire, la variabilité d'application de cette loi n'est pas uniforme en France : elle est plus systématique pour le Midi, moins pour le Nord (Detey et al., 2010). Les autres oppositions relevées dans la table 5, comme l'opposition [s]/[z] , venant principalement du suffixe -isme, sont décrites dans le DPF. Le codage problématique du schwa y est également longuement commenté. La table 7 montre la proportion de transcriptions strictement identiques (hors syllabation), et « comparables » après annulation des différences entre voyelles moyennes. Notre définition de comparable est arbitraire mais montre que la majorité des différences (97 à 98%) sont dues à ces seules oppositions et ne viennent pas de codages aberrants. GLÀFF et Lexique proposent des prononciations strictement identiques pour 79,5% des entrées. Cet accord strict est de 61,7% entre GLÀFF est BDLex. On peut donc estimer que les transcriptions phonémiques de GLÀFF sont de bonne qualité (l'accord entre BDLex et Lexique est de 58,3%). Notons également que les emprunts sont souvent générateurs de divergences (e.g. shaker : /SEi.k@K/ , /SEj.koeK/ , /SE.koeK/ ; chili : /Si.li/ , /tSi.li/ ; ginseng : /Zin.sAg/ , /Zin.sAN/ , /Zin.sEN/ ). Par ailleurs, ni Lexique ni BDLex ne saurait constituer un étalon absolu. Si l'opposition [o]/[O] peut s'expliquer, certaines entrées transcrites avec un [o] (o fermé) dans BDLex sont surprenantes : /po,m/ pour pomme, /poKt/ pour porte, /oK/ pour or et hors, etc. Concernant Lexique, que penser de châtié, transcrit /Sa.sje/ , ou de cambriolé/cambriolés transcrits respectivement /ka.bKi.jo.le/ et /ka.bKi.o.le/ ? On s'étonne également de lire dans sa documentation que le caractère code le « e-ouvert [comme dans] oeuf, peur » et de trouver dans le lexique peur transcrit , étant selon la documentation le code pour le « e-fermé [comme dans] deux ». Une autre curiosité concerne le « schwa non élidable [comme dans] par- venu », codée selon la documentation par le symbole . Or ce symbole est totalement absent de Lexique. Parvenu, utilisé comme exemple, est transcrit , où  code le schwa élidable.  T  5 - Les 10 différences de transcription les plus fréquentes. Opérations (Op.) : r = substitution ; i = insertion ; d = suppression.  T  6 - Exemples de différence de transcription entre lexiques.  La comparaison de la syllabation opérée sur les transcriptions identiques (cf. table 7) montre que  les trois lexiques sont très proches (98%). Notons à ce propos que si la construction « collaborative par les foules » du Wiktionnaire peut dans certains cas, admettons-le, être source d'amateurisme, elle peut également être intéressante car elle reflète une perception non canonique de la langue, selon un point de vue qui est de facto celui du locuteur (en l'occurrence, le contributeur) et non de jure celui du linguiste. À titre d'exemple, on peut citer le cas de la syllabation du groupe consonantique /s/ + C en position interne de mot. Dans GLÀFF ce groupe apparaît alternativement comme hétérosyllabique, i.e. le /s/ et la consonne qui suit appartiennent à deux syllabes différentes (c'est la version canonique en français) comme dans ministère /mi.nis.tEK/ et comme tautosyllabique (les deux phonèmes appartiennent à la même syllabe) comme dans monistique /mO.ni.stik/ . Cette alternance, avec d'autres phénomènes non stables dans le Wiktionnaire, peuvent être perçus comme les signaux du comportement parfois non déterministe de la langue, et, partant, comme des objets potentiels d'investigation linguistique et psycholinguistique.  T  7 - Accord inter-lexiques : transcriptions phonémiques et syllabation .  Nous avons présenté dans cet article la première version d'un nouveau lexique, GLÀFF, construit  de façon automatique à partir du Wiktionnaire. Ce lexique fournit des descriptions morphosyntaxiques détaillées pour 1,4 millions d'entrées et des transcriptions phonémiques pour 1,3 millions d'entre elles. Nous avons apporté dans cet article un certain nombre d'éléments qui indiquent que GLÀFF est un lexique de bonne qualité comparé aux ressources existantes comme Lexique, BDLex, Lefff ou Morphalou. Le fait qu'il dispose d'une taille 3 à 9 fois supérieure à celle des autres lexiques ne s'accompagne pas d'une dégradation des descriptions morphosyntaxiques et des transcriptions phonémiques. GLÀFF devrait s'avérer utile tant pour des recherches en TAL, en psycholinguistique, que pour la description linguistique.  La création de GLÀFF, motivée notamment par les besoins des recherches que nous menons  sur l'organisation morphologique du lexique (Hathout, 2011) et sur la modélisation de la phonotactique et de son acquisition (Calderone et Celata, 2012), se poursuivra par un travail sur la découverte automatique des espaces thématiques utilisés pour la flexion (Boyé, 2011). Les autres perspectives sont nombreuses. À très court terme, nous enrichirons GLÀFF des catégories syntaxiques initialement écartées (mots grammaticaux et locutions). Puis nous intégrerons dans une même ressource les informations contenues dans GLÀFF et WiktionaryX. Cette ressource unifiée pourra dans un second temps recevoir des bases de données de descriptions lexicales provenant par exemple du Dictionnaire des Mots Construits de Michel Roché . Nous prévoyons également la création d'une version révisée de GLÀFF qui constituera un souslexique totalement fiable. Plusieurs stratégies sont envisagées. La première sera de détecter automatiquement les entrées susceptibles de comporter des erreurs dans leur description morphosyntaxique ou leur transcription phonémique et de les éliminer. La seconde sera une révision semi-automatique dans laquelle nous proposerons à des opérateurs humains des corrections possibles qu'ils devront valider. Nous pourrons enfin augmenter ces sous-lexiques par une collection étendue d'informations sur la fréquence des formes et des lexèmes dans différents corpus de référence (Frantext, FrWaC, Wikipédia, LM10, etc.), le nombre de caractères, de phonèmes, de syllabes, la taille de la famille dérivationnelle, le voisinage graphémique, phonologique, etc. Cette version devrait répondre aux besoins des psycholinguistes, et être également utile pour la description linguistique, notamment en morphologie, les études quantitatives en linguistique et la modélisation du lexique et de son acquisition.  
